







var tipuesearch = {"pages": [

  
  
  
  {
    "title": "CAS 6.1.0 RC1 Feature Release",
    "text": "WATCH OUT!This post is not official yet and may be heavily edited as CAS development makes progress. Watch for further updates. CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 6.0.0 GA was released on December 28th, 2018. Since then, the project has been moving forward with development of the next feature release that is tagged as 6.1.0. Please review the release policy to learn more about the scope of the release. This post intends to highlight some of the improvements and enhancements packed into the first release candidate in the 6.1.0 series. Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. Note that CAS releases are strictly time-based releases; they are not scheduled or based on specific benchmarks, statistics or completion of features. To gain confidence in a particular release, it is strongly recommended that you start early by experimenting with release candidates and/or follow-up snapshots. In order to start experimenting with release candidates, at any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Overlay In the gradle.properties of the overlay, adjust the following setting: casVersion=6.1.0-RC1 Changes New &amp; Noteworthy Hazelcast WAN Replication SAML2 Metadata Management via JSON SAML2 Signing Credential Fingerprint Password Synchronization Small Stuff Library Upgrades Resources Get Involved Credits New &amp; Noteworthy Hazelcast WAN Replication Hazelcast WAN replication using static discovery is now supported by CAS. SAML2 Metadata Management via JSON SAML2 service provider integrations that do not necessarily provide metadata may be managed dynamically inside a standalone JSON file. SAML2 Signing Credential Fingerprint SAML services are given the ability to filter the signing credential used in the metadata by its SHA-1 fingerprint. Password Synchronization Support for password synchronization is now available. Small Stuff REST Authentication can now display warnings as part of the authentication flow. REST Password Management may now support endpoints protected via Basic AuthN. Library Upgrades Hibernate Gradle Azure KeyVault OpenSAML Resources Documentation Release Schedule Release Policy Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Credits Big thanks to all who participate in the development of this release to submit patches and contribute improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2019/02/01/610rc1-release/"
  },

  
  
  
  {
    "title": "Apereo CAS - OohLala Mobile SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentPaul Spaude of Unicon, Inc was kind enough to contribute this guide. Ready Communication’s OohLala Mobile provides a mobile community and communication tools for higher education. As a SAML2 service provider, it can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) CAS Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the relying-party registration record in JSON definition files. The JSON file to contain the service provider relying-party record would be as follows: { \"@class\" : \"org.apereo.cas.support.saml.services.SamlRegisteredService\", \"serviceId\" : \"https://integration.oohlalamobile.com/saml/[instance-name]/metadata\", \"name\" : \"OohLaLa\", \"id\" : 1, \"metadataLocation\" : \"https://integration.oohlalamobile.com/saml/[instance-name]/metadata\", \"encryptAssertions\" : false, \"signAssertions\" : false, \"signResponses\" : true, \"attributeReleasePolicy\" : { \"@class\" : \"org.apereo.cas.services.ReturnAllowedAttributeReleasePolicy\", \"allowedAttributes\" : [ \"java.util.ArrayList\", [\"givenName\",\"sn\",\"mail\",\"uid\"]] } } A few things to point out: You will need to adjust the metadataLocation to match your instance. Make sure CAS has retrieved the allowed attributes (i.e. givenName, sn etc) listed in the JSON definition file. Make sure the SP metadata has the correct entity id, matching the instance. Finale Thanks to Paul Spaude of Unicon, Inc who was kind enough to share the above integration notes. If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/12/24/cas53-oohlalamobile-saml2-integration/"
  },

  
  
  
  {
    "title": "Apereo CAS - Cranium Cafe SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentPaul Spaude of Unicon, Inc was kind enough to contribute this guide. Cranium Cafe is a virtual teleconferencing platform that creates a simple, mobile in-office appointment. As a SAML2 service provider, it can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) CAS Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the relying-party registration record in JSON definition files. The JSON file to contain the service provider relying-party record would be as follows: { \"@class\" : \"org.apereo.cas.support.saml.services.SamlRegisteredService\", \"serviceId\" : \"https://my.craniumcafe.com/login/saml2\", \"name\" : \"CraniumCafe\", \"id\" : 1, \"metadataLocation\" : \"https://my.craniumcafe.com/login/saml2_metadata\", \"encryptAssertions\" : false, \"signAssertions\" : false, \"signResponses\" : true, \"attributeReleasePolicy\": { \"@class\": \"org.apereo.cas.services.ReturnMappedAttributeReleasePolicy\", \"allowedAttributes\": { \"@class\": \"java.util.TreeMap\", \"eduPersonScopedAffiliation\": \"groovy { return attributes['eduPersonAffiliation'].get(0) + '@example.org' }\" \"displayName\": \"displayName\", \"mail\": \"mail\", \"eduPersonPrincipalName\": \"groovy { return attributes['eduPersonPrincipalName'].get(0) + '@example.org' }\" } } } A few things to point out: You will need to adjust the metadataLocation to match your instance. Make sure CAS has retrieved the allowed attributes (i.e. eduPersonPrincipalName, mail etc) listed in the JSON definition file. Make sure the SP metadata has the correct entity id, matching the instance. Finale Thanks to Paul Spaude of Unicon, Inc who was kind enough to share the above integration notes. If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/12/24/cas53-oclc-saml2-integration/"
  },

  
  
  
  {
    "title": "Apereo CAS - eLumen SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentPaul Spaude of Unicon, Inc was kind enough to contribute this guide. eLumen is a higher-ed, assessment and curriculum management system that gives real insight into each students’ engagement and progress—while satisfying the growing demands of accreditation and other compliance mandates. As a SAML2 service provider, it can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) CAS Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the relying-party registration record in JSON definition files. The JSON file to contain the service provider relying-party record would be as follows: { \"@class\" : \"org.apereo.cas.support.saml.services.SamlRegisteredService\", \"serviceId\" : \"[entity-id].elumenapp.com\", \"name\" : \"ELumen\", \"id\" : 1, \"evaluationOrder\" : 1, \"metadataLocation\" : \"/path/to/elumen-metadata.xml\", \"encryptAssertions\" : false, \"signAssertions\" : false, \"signResponses\" : true, \"attributeReleasePolicy\": { \"@class\": \"org.apereo.cas.services.ReturnMappedAttributeReleasePolicy\", \"allowedAttributes\": { \"@class\": \"java.util.TreeMap\", \"uid\": \"uid\", \"eduPersonPrincipalName\": \"groovy { return attributes['eduPersonPrincipalName'].get(0) + '@exampl.org' }\" } } } A few things to point out: You will need to adjust the metadataLocation to match your instance. Make sure CAS has retrieved the allowed attributes (i.e. eduPersonPrincipalName, uid etc) listed in the JSON definition file. Make sure the SP metadata has the correct entity id, matching the instance. Finale Thanks to Paul Spaude of Unicon, Inc who was kind enough to share the above integration notes. If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/12/24/cas53-elumen-saml2-integration/"
  },

  
  
  
  {
    "title": "Apereo CAS - Rave SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentPaul Spaude of Unicon, Inc was kind enough to contribute this guide. Rave is a mass notification system designed to deliver fast and effective messaging for routine and emergency communications. As a SAML2 service provider, Rave can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) CAS Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the relying-party registration record in JSON definition files. The JSON file to contain the service provider relying-party record would be as follows: { \"@class\" : \"org.apereo.cas.support.saml.services.SamlRegisteredService\", \"serviceId\" : \"https://www.getrave.com/shibboleth-sp\", \"name\" : \"Rave\", \"id\" : 1, \"metadataLocation\" : \"/path/to/metadata.xml\", \"encryptAssertions\" : false, \"signAssertions\" : false, \"signResponses\" : true, \"requiredNameIdFormat\" : \"urn:oasis:names:tc:SAML:2.0:nameid-format:transient\", \"attributeReleasePolicy\": { \"@class\": \"org.apereo.cas.services.ReturnMappedAttributeReleasePolicy\", \"allowedAttributes\": { \"@class\": \"java.util.TreeMap\", \"employeeNumber\": \"urn:oid:1.2.840.113556.1.2.610\", \"eduPersonPrincipalName\": \"groovy { return attributes['eduPersonPrincipalName'].get(0) + '@example.org' }\" } } } A few things to point out: You will need to adjust the metadataLocation to match your instance. Make sure CAS has retrieved the allowed attributes (i.e. employeeNumber, eduPersonPrincipalName etc) listed in the JSON definition file. Make sure the SP metadata has the correct entity id, matching the Rave instance. Finale Thanks to Paul Spaude of Unicon, Inc who was kind enough to share the above integration notes. If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/12/23/cas53-getrave-saml2-integration/"
  },

  
  
  
  {
    "title": "Apereo CAS - HireTouch SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentPaul Spaude of Unicon, Inc was kind enough to contribute this guide. HireTouch offers talent management solutions and is built specifically for human resources departments and hiring managers. As a SAML2 service provider, HireTouch can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) CAS Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the relying-party registration record in JSON definition files. The JSON file to contain the service provider relying-party record would be as follows: { \"@class\" : \"org.apereo.cas.support.saml.services.SamlRegisteredService\", \"serviceId\" : \"https://[instance].hiretouch.com/admin/saml/consume\", \"name\" : \"HireTouch\", \"id\" : 1, \"metadataLocation\" : \"/path/to/metadata.xml\", \"encryptAssertions\" : false, \"signAssertions\" : false, \"signResponses\" : true, \"attributeReleasePolicy\" : { \"@class\" : \"org.apereo.cas.services.ReturnAllowedAttributeReleasePolicy\", \"allowedAttributes\" : [ \"java.util.ArrayList\", [\"uid\"]] } } A few things to point out: You will need to adjust the metadataLocation to match your instance. Make sure CAS has retrieved the allowed attributes (i.e. uid etc) listed in the JSON definition file. Make sure the SP metadata has the correct entity id, matching the HireTouch instance. Finale Thanks to Paul Spaude of Unicon, Inc who was kind enough to share the above integration notes. If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/12/22/cas53-hiretouch-saml2-integration/"
  },

  
  
  
  {
    "title": "Apereo CAS - Microsoft Office 365 SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentPaul Spaude of Unicon, Inc was kind enough to contribute this guide. Office 365 is a line of subscription services offered by Microsoft, as part of the Microsoft Office product line. As a SAML2 service provider, Office 365 can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) Office 365 Configuration The following resources should come in handy: Azure Active Directory: Single Sign-On SAML protocol Office 365 – Why You Need to Understand ImmutableID Azure Active Directory SAML2 metadata may be found here. CAS Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the relying-party registration record in JSON definition files. The JSON file to contain the service provider relying-party record would be as follows: { \"@class\" : \"org.apereo.cas.support.saml.services.SamlRegisteredService\", \"serviceId\" : \"urn:federation:MicrosoftOnline\", \"name\" : \"Office365_SP\", \"description\" : \"Microsoft Office 365 / Azure AD\", \"id\" : 10, \"metadataLocation\" : \"file:///path/to/WindowsAzureAD-metadata.xml\", \"encryptAssertions\" : false, \"signAssertions\" : true, \"signResponses\" : false, \"requiredNameIdFormat\" : \"urn:oasis:names:tc:SAML:2.0:nameid-format:persistent\", \"usernameAttributeProvider\" : { \"@class\" : \"org.apereo.cas.services.PrincipalAttributeRegisteredServiceUsernameProvider\", \"usernameAttribute\" : \"objectGUID\" }, \"attributeReleasePolicy\" : { \"@class\" : \"org.apereo.cas.services.ReturnMappedAttributeReleasePolicy\", \"allowedAttributes\" : { \"@class\" : \"java.util.TreeMap\", \"userPrincipalName\" : \"IDPEmail\" } } } A few things to point out: You will need to adjust the metadataLocation to match your data and the Office 365 instance. Make sure CAS has retrieved the allowed attributes (i.e. IDPEmail, objectGUID etc) listed in the JSON definition file. This is required in the final generated SAML2 response to create the proper NameIDFormat element. Make sure the SP metadata has the correct entity id, matching your Office 365 instance address. Finale Thanks to Paul Spaude of Unicon, Inc who was kind enough to share the above integration notes. If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/12/06/cas53-office365-saml2-integration/"
  },

  
  
  
  {
    "title": "Apereo CAS - HappyFox SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. HappyFox is an all-in-one help desk ticketing system. As a SAML2 service provider, HappyFox can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) HappyFox Configuration Use these instructions to set up HappyFox as a SAML2 service provider. CAS Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the HappyFox relying-party registration record in JSON definition files. The JSON file to contain the service provider relying-party record would be as follows: { \"@class\" : \"org.apereo.cas.support.saml.services.SamlRegisteredService\", \"serviceId\" : \"https://[name].happyfox.com/saml/metadata/\", \"name\" : \"HappyFox\", \"description\": \"HappyFox\", \"id\" : 1, \"evaluationOrder\" : 1, \"metadataLocation\" : \"file:/etc/cas/config/saml/happyfox-metadata.xml\", \"usernameAttributeProvider\" : { \"@class\" : \"org.apereo.cas.services.PrincipalAttributeRegisteredServiceUsernameProvider\", \"usernameAttribute\" : \"mail\" } } Note that HappyFox does not provide its own SP metadata and you will have to create it youself. The following is example of what that metadata may look like: &lt;?xml version=\"1.0\"?&gt; &lt;md:EntityDescriptor xmlns:md=\"urn:oasis:names:tc:SAML:2.0:metadata\" validUntil=\"2050-12-05T19:27:46Z\" cacheDuration=\"PT604800S\" entityID=\"https://[name].happyfox.com/saml/metadata/\"&gt; &lt;md:SPSSODescriptor AuthnRequestsSigned=\"false\" WantAssertionsSigned=\"false\" protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\"&gt; &lt;md:NameIDFormat&gt;urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress&lt;/md:NameIDFormat&gt; &lt;md:AssertionConsumerService Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"https://[name].happyfox.com/saml/callback/\" index=\"0\" /&gt; &lt;/md:SPSSODescriptor&gt; &lt;/md:EntityDescriptor&gt; A few things to point out: You will need to adjust the serviceId and metadataLocation to match your data and the HappyFox instance. Make sure CAS has retrieved the allowed attributes (i.e. mail etc) listed in the JSON definition file. This is required in the final generated SAML2 response to create the proper NameIDFormat element. Make sure the SP metadata has the correct entity id, matching your HappyFox instance address. Finale If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/12/04/cas53-happyfox-saml2-integration/"
  },

  
  
  
  {
    "title": "Apereo CAS - Cisco Webex SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentKeith Conger of Colorado College, an active member of the CAS community, was kind enough to contribute this guide. Cisco Webex, formerly WebEx Communications Inc., is a company that provides on-demand collaboration, online meeting, web conferencing and videoconferencing applications. As a SAML2 service provider, Cisco Webex can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) Cisco Webex Configuration Download the service provider metadata and upload the CAS identity provider metadata. No other configuration is required. CAS Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the Cisco Webex relying-party registration record in JSON definition files. The JSON file to contain the Cisco Webex record would be as follows: { @class: org.apereo.cas.support.saml.services.SamlRegisteredService serviceId: ^https://idbroker.webex.com/.* name: Cisco Webex id: 1 description: Cisco Webex usernameAttributeProvider: { @class: org.apereo.cas.services.PrincipalAttributeRegisteredServiceUsernameProvider usernameAttribute: mail } attributeReleasePolicy: { @class: org.apereo.cas.services.ReturnMappedAttributeReleasePolicy allowedAttributes: [ @class: java.util.TreeMap givenName: [ java.util.ArrayList [ firstName ] ] mail: [ java.util.ArrayList [ email ] ] sn: [ java.util.ArrayList [ lastName ] ] displayName: [ java.util.ArrayList [ displayName ] ] ] } metadataLocation: /path/to/webex-metadata.xml signAssertions: true skipGeneratingSubjectConfirmationNotBefore: true requiredNameIdFormat: urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress signResponses: true } A few things to point out: You will need to adjust the serviceId and metadataLocation to match your data and the Cisco Webex instance. Make sure CAS has retrieved the allowed attributes (i.e. mail, givenName, etc) listed in the JSON definition file. Finale Thanks to Keith Conger of Colorado College who was kind enough to share the above integration notes. If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/12/04/cas53-cisco-webex-saml2-integration/"
  },

  
  
  
  {
    "title": "Apereo CAS - VMware Identity Manager SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentKeith Conger of Colorado College, an active member of the CAS community, was kind enough to contribute this guide. VMware Identity Manager is identity management for the mobile cloud era that delivers on consumer-simple expectations like one-touch access to nearly any app, from any device, optimized with AirWatch Conditional Access. As a SAML2 service provider, VMware Identity Manager can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) VMware Identity Manager Configuration Register CAS as an identity provider Configure authentication methods CAS Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the VMware Identity Manager relying-party registration record in JSON definition files. The JSON file to contain the VMware Identity Manager registration record would be as follows: { @class: org.apereo.cas.support.saml.services.SamlRegisteredService serviceId: your-vmware-idm-entity-id name: VMware Identity Manager id: 1 description: VMware Identity Manager attributeReleasePolicy: { @class: org.apereo.cas.services.ReturnMappedAttributeReleasePolicy allowedAttributes: [ @class: java.util.TreeMap givenName: [ java.util.ArrayList [ firstName ] ] mail: [ java.util.ArrayList [ email ] ] sAMAccountName: [ java.util.ArrayList [ userName ] ] sn: [ java.util.ArrayList [ lastName ] ] userPrincipalName: [ java.util.ArrayList [ userPrincipalName ] ] ] } metadataLocation: /path/to/vmware-idm.xml signAssertions: true skipGeneratingSubjectConfirmationNotBefore: true signResponses: true } A few things to point out: You will of course need to adjust the serviceId and metadataLocation to match your data and VMware Identity Manager instance. Make sure CAS has retrieved the allowed attributes (i.e. mail, givenName, etc) listed in the JSON definition file. Finale Thanks to Keith Conger of Colorado College who was kind enough to share the above integration notes. If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/12/03/cas53-vmwareidentitymgr-saml2-integration/"
  },

  
  
  
  {
    "title": "CAS 6.0.0 RC4 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.3.0 GA was released on June 29th, 2018. Since then, the project has been moving forward with development of the next feature release that is tagged as 6.0.0. Note that this is a major release of the CAS software which may present significant changes in architecture, configuration or behavior. Please review the release policy to learn more about the scope of the release. This post intends to highlight some of the improvements and enhancements packed into the fourth release candidate in the 6.0.0 series. You can read about the previous release candidate here. Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. Note that CAS releases are strictly time-based releases; they are not scheduled or based on specific benchmarks, statistics or completion of features. To gain confidence in a particular release, it is strongly recommended that you start early by experimenting with release candidates and/or follow-up snapshots. In order to start experimenting with release candidates, at any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Overlay In the gradle.properties of the overlay, adjust the following setting: casVersion=6.0.0-RC4 Changes Known Issues New &amp; Noteworthy Actuator Endpoint Ids SMS via Groovy &amp; REST Dockerized CAS Overlay Command-line Shell Service Environments reCAPTCHA v3 Bucket4j Integration Amazon Cognito Authentication SOAP Authentication JDBC Naming Strategy Consent Review Endpoint Small Stuff Library Upgrades Resources Get Involved Credits Known Issues The cas.admin-pages-security.ip property has been renamed to cas.monitor.endpoints.endpoint.defaults.access[0] but due to an issue, a NullPointerException will occur on startup if you use that property (in canonical form or relaxed, etc) rather than pointing at the new property name. Change the property name or don’t use the property in order to avoid the issue. New &amp; Noteworthy Actuator Endpoint Ids CAS actuator endpoints are named to be more consistent with Spring Boot guidelines, to remove startup warnings and prevents errors in future upgrades to Spring Boot 2.2.x. Previous endpoints that were created using kebab-case identifiers such as spring-webflow are now switched over to use camel-case instead, such as springWebflow. SMS via Groovy &amp; REST Sending SMS messages is now also possible via Groovy scripts or a REST API. Dockerized CAS Overlay The CAS WAR Overlay is equipped to build Docker images using jib. Command-line Shell The CAS Command-line Shell gets a few upgrades to stay compatible with the most recent changes to the build, as well as a few new commands to generate crypto keys or encrypt/sign data, etc. Service Environments Each registered application in the registry may be assigned a set of environment names. reCAPTCHA v3 Support for reCAPTCHA v3 is now added to CAS. Bucket4j Integration Authentication throttling support can now integrate with Bucket4j to handle capacity throttling for authentication requests. Amazon Cognito Authentication CAS is able to leverage Amazon Cognito for authentication. SOAP Authentication CAS is able to leverage SOAP APIs for authentication. JDBC Naming Strategy Additional options are exposed to help remap database virtual table names to logical names either via static settings or Groovy scripts, when database schemas and queries are created. This allows one to translate CAS-provided table names to those that might work better with older or less forgiving database platforms that have restrictions on naming, etc. Consent Review Endpoint Reviewing consent decisions is now possible using the new consentReview endpoint that acts as a Spring Boot actuator endpoint. Small Stuff Small number of bug fixes to handle authorization correctly for delegated authentication. The configuration settings for Spring Cloud configuration modules for MongoDb, DynamoDb, JDBC, etc should properly be recognized by CAS again. The background job to reload CAS registered service is made conditional to only execute in case a reloadable storage option is registered. A number of additional test cases for AWS S3 functionality. Improvements to the crypto algorithm selection used to generate secure random numbers. CAS configuration can now be recognized via Groovy closures. Security response headers can support all CAS registered service definition types. Minor improvements to database attribute fetching and processing of SQL Array objects. CAS configuration watch can operate on both the configuration directory and the standalone direct configuration file. CAS multifactor authentication via RADIUS gains the ability to enforce a limit on the number of allowed authentication attempts. Secret keys used for various signing and encryption operations can now properly be recognized via CAS settings. SAML2 SLO functionality receives a number of improvements to handle various forms of bindings. CAS configuration properties that are renamed or moved to a new location should be reported on startup when used. Most if not all custom shell commands used by the CAS overlay are moved into the Gradle build script. Authentication throttling backed by Hazelcast gains its own independant set of properties. Library Upgrades Spring Boot Spring Gradle Lombok Micrometer Spring Integration Apache Tomcat Person Directory CAS Security Filter Amazon SDK JUnit Nexmo Spring Data Resources Documentation Release Schedule Release Policy Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Credits Big thanks to all who participate in the development of this release to submit patches and contribute improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2018/11/30/600rc4-release/"
  },

  
  
  
  {
    "title": "Apereo CAS - Scripting Multifactor Authentication Triggers",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentKeith Conger of Colorado College, an active member of the CAS community, was kind enough to contribute this guide. If you have configured multifactor authentication with CAS with a provider (i.e. Duo Security), you may find yourself in need of conditionally triggering MFA based on a variety of factors rather dynamically. Here is a possible scenario: Allow internal access to a service without forcing MFA via IP range Rejecting external access to a service unless in MFA LDAP group CAS provides a large number of strategies to trigger multifactor authentication. To deliver the use case, we can take advantage of a Groovy-based trigger to implement said conditions. The script is invoked by CAS globally (regardless of application, user, MFA provider, etc) whose outcome should determine whether an MFA provider can take control of the subsequent step in the authentication flow. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) Configuration With Duo Security configured as our multifactor authentication provider, we can start off with the following settings: cas.audit.alternateClientAddrHeaderName=X-Forwarded-For cas.authn.mfa.groovyScript=file:/path/to/GroovyScript.groovy Here, we are teaching CAS to use the X-Forwarded-For header when fetching client IP addresses, and we are also indicating a reference path to our yet-to-be-written Groovy script. The script itself would have the following structure: import java.util.* import org.apereo.inspektr.common.web.*; class GroovyMfaScript { String privateIPPattern = \"(^127\\\\.0\\\\.0\\\\.1)\"; String mfaGroupPattern = \"CN=MFA-Enabled\"; String servicePattern = \"https://app.example.org\"; def String run(final Object... args) { def service = args[0]; def registeredService = args[1]; def authentication = args[2]; def logger = args[3]; if (service.id.contains(servicePattern)) { def clientInfo = ClientInfoHolder.getClientInfo(); def clientIp = clientInfo.getClientIpAddress(); logger.info(\"Client IP [{}]\", clientIp); if (clientIp.find(privateIPPattern)) { logger.info(\"Internal IP address\"); def memberOf = authentication.principal.attributes['memberOf'] for (String group : memberOf) { if (group.contains(mfaGroupPattern)) { logger.info(\"In MFA group\"); return \"mfa-duo\"; } } return null; } return \"mfa-duo\"; } return null; } } The above script goes through the following conditions: The requesting application is https://app.example.org. The incoming client IP address matches the pattern (^127\\\\.0\\\\.0\\\\.1). The authenticated user carries a memberOf attribute with a value of CN=MFA-Enabled. If all of those conditions are true, then MFA is activated…or else ignored. Note that the function of a Groovy trigger is not specific to a multifactor authentication provider. So long as the conditions execute correctly and the provider is configured properly, it can be used to signal any provider back to the authentication flow. Finale Thanks to Keith Conger of Colorado College who was kind enough to share the above integration notes. Misagh Moayyed",
    "tags": "CAS MFA",
    "url": "/2018/11/22/cas5-groovy-mfa/"
  },

  
  
  
  {
    "title": "Apereo CAS 6.0.x - Building CAS Feature Modules",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Overview This quick walkthrough effectively aims for the following objectives: A quick development environment setup using IntelliJ IDEA. Building and running the CAS web application using Gradle. Changing feature modules and testing out behavior. Testing changes and writing unit tests. Stepping into the code using a debugger. Development Environment Follow the instructions posted here to obtain the CAS source code. Remember to indicate the relevant branch in the commands indicated to obtain the right source code for the CAS version at hand. In this tutorial and just like before, the branch to use would be 6.0.x (at the time of writing this post, the appropriate branch is master). To understand what branches are available, see this link. Your CAS version is closely tied to the branches listed in the codebase. For example, if you are deploying CAS 5.1.8, then the relevant branch to check out would be 5.1.x. Remember that branches always contain the most recent changeset and version of the release line. You might be deploying 5.1.8 while the 5.1.x might be marching towards 5.1.10. This requires that you first upgrade to the latest available patch release for the CAS version at hand and if the problem or use case continues to manifest, you can then check out the appropriate source branch and get fancy [1]. Keep UpIt is STRONGLY recommended that you keep up with the patch releases as they come out. Test early and have the environment on hand for when the time comes to dabble into the source. Postponing patch upgrades in the interest of time will eventually depreciate your lifespan. It is important that to let IntelliJ IDEA open and refresh the Gradle project (using the Refresh button on the Gradle window’s toolbar) once you do the initial import. Running ./gradlew idea MAY work but it may also completely mess up the project structure especially if the plugin is not quite compatible with your IDE version. Note that similar tasks are available for eclipse. For best results, try with IntelliJ IDEA 2018.3 (Ultimate Edition). Given the size of the CAS projects and the number of sub-modules, you need to make sure you have enough memory available for IDEA and that your custom JVM settings are correctly set per the instructions here for IntelliJ IDEA. System Requirements It’s best to get familiar with CAS system requirements. Most importantly, this means that your system must be prepped with JDK 11. Just about any JDK variant from any JDK vendor would do the job. Important changes in Oracle JDK 11 LicenseWith JDK 11 Oracle has updated the license terms on which Oracle JDK is offered. The new Oracle Technology Network License Agreement for Oracle Java SE is substantially different from the licenses under which previous versions of the JDK were offered. Please review the new terms carefully before downloading and using this product. Oracle also offers this software under the GPL License on jdk.java.net/11. For basic development and prototyping, try with: java -version java version \"11\" 2018-09-25 Java(TM) SE Runtime Environment 18.9 (build 11+28) Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11+28, mixed mode) Running CAS The CAS web application itself can be started from the command-prompt using an embedded Apache Tomcat container. In fact, this process is no different from deploying CAS using the same embedded Apache Tomcat container which means you will need to follow the instructions posted here in the way that certificates and other configurations are needed in /etc/cas/config, etc to ensure CAS can function as you need it. All feature modules and behavior that would be stuffed into the web application artifact continue to read settings from the same location, as they would be when activated from an overlay. The process is exactly the same. I use the following alias in my bash profile to spin up CAS using an embedded Apache Tomcat container. You might want to do the same thing: alias bc='clear; cd ~/Workspace/cas/webapp/cas-server-webapp-tomcat; \\ ../../gradlew build bootRun --configure-on-demand --build-cache --parallel \\ -x test -x javadoc -x check -DenableRemoteDebugging=true --stacktrace \\ -DskipNestedConfigMetadataGen=true -DskipGradleLint=true -DskipSass=true \\ -DskipNodeModulesCleanUp=true -DskipNpmCache=true -DskipNpmLint=true' Then, I simply execute the following in the terminal: &gt; bc Since you’re running bootRun under the cas-server-webapp-tomcat module, the servlet container used will be based on Apache Tomcat. You can navigate to a different module that bases itself on top of a different servlet container such as Jetty. On WindowsYou can apply the same strategy on Windows by creating a bc.bat file and making sure it's available on the PATH. The syntax of course needs to be adjusted to account for file paths and commands. To understand the meaning and function behind various command-line arguments, please see instructions posted here. You may optionally decide to tweak each setting if you are interested in a particular build variant, such as generating javadocs, running tests, etc. One particular flag of interest is the addition of enableRemoteDebugging, which allows you, later on, to connect a remote debugger to CAS on a specific port (i.e. 5000) and step into the code. More on that later. Testing Modules Per instructions posted here, the inclusion of a particular build module in the Gradle build script of the CAS web application should allow the build process to automatically allow the module to be packaged and become available to the runtime. You may include the module reference in the webapp.gradle file, which is the common parent to build descriptors that do stuff with CAS web applications. Making changes in this file will ensure that it will be included by default in the generic CAS web application, regardless of how it is configured to run using a servlet container, which means you need to be extra careful about the sort of changes you make here and what is kept and what is checked in for follow-up pull requests and reviews. So for reference and our task at hand, the file would look like the following: dependencies { ... implementation project(\":support:cas-server-support-some-module\") ... } Note the reference locates the module using its full path. The next time you run bc, the final CAS web application will have enabled some-module functionality when it’s booting up inside Apache Tomcat allowing you to make changes to said module and begin testing. The same command, bc, can be used over and over again to run CAS locally and test the change until the desired functionality is there. Once done, you may then commit the change to a relevant branch (of your fork, which is something you should have done earlier when you cloned the codebase) and push upstream (again, to your fork) in order to prepare a pull request and send in the change targetted at the right destination branch. More info on that workflow is available here. Debugging CAS One of the very useful things you can include in your build is the ability to allow for remote debugging via -DenableRemoteDebugging=true. Both IntelliJ IDEA and eclipse allow you ways to connect to a port remotely and activate a debugger in order to step into the code and troubleshoot. This is hugely useful, especially in cases where you can make a change to a source file and rebuild the component live hot-reloading the .class file to allow the changes to kick in the very next time execution passes through without restarting the servlet container. Depending on how significant the change is, this should save you quite a bit of time. There are also much fancier tools such as JRebel that let you do the same with a lot more power and flexibility. The remote debugging port by default is 5000 and should be auto-incremented in case the port is busy or occupied by some other process. You should get notices and prompts from the build, if and when that happens. A very useful flag that you may consider adding to your shell alias is -DremoteDebuggingSuspend=true, which allows you to suspend the JVM until a debugger tool is attached to the running process. This is handy in situations where you need to debug and troubleshoot a particular component or behavior that executes early during startup (i.e. fetching CAS configuration settings or servlet container bootstrapping) and you don’t want the runtime to proceed too quickly and forcing you to miss the troubleshooting window. With the inclusion of this new flag, the build outcome sort of looks like this: &gt; Task :webapp:cas-server-webapp-tomcat:bootRun Listening for transport dt_socket at address: 5000 Overlay Sometimes, it’s useful to test the new change from the perspective of the CAS Overlay. While the behavior should be identical, this step can be used in quick smoke tests and to ensure the proper set of dependencies and modules are published and installed correctly and picked up by the overlay build process without any conflicts or duplicates. To publish and install CAS artifacts locally, you may try the following: # Build CAS and install... alias bci='clear; cd ~/Workspace/cas \\ ./gradlew clean build install --configure-on-demand --build-cache --parallel \\ -x test -x javadoc -x check -DenableRemoteDebugging=true --stacktrace \\ -DskipNestedConfigMetadataGen=true -DskipGradleLint=true -DskipSass=true \\ -DskipNodeModulesCleanUp=true -DskipNpmCache=true \\ -DskipNpmLint=true -DskipBootifulArtifact=true' Be patient. This might take some time. A rather important flag in the above build is -DskipBootifulArtifact=true. This stops the Gradle build from applying the Spring Boot plugin to bootify application components, mainly the various CAS web application artifacts. This is required because the CAS Overlay needs to operate on a vanilla web application untouched by Spring Boot plugins (a.k.a non-bootiful) before it can explode and repackage it with Spring Boot. Note that the CAS build and release processes automatically take this flag into account when snapshots or releases are published and more conveniently, whether you are working on the CAS codebase or overlay, you get to work with the same bootiful web application without any extra hassle. Once the artifacts are successfully installed, you can pick up the -SNAPSHOT artifacts in overlay by changing the CAS version and resume testing. Writing Tests Ideally, changes that are introduced need to be tested using either simple unit tests or integration tests. Unit Tests Writing unit tests is rather easy. If you have added a few changes to src/main/java/org/apereo/cas/SomeCasComponent.java, you will need to create the corresponding test component under src/test/java/org/apereo/cas/SomeCasComponentTests.java for the build to identify and execute it. The outline of SomeCasComponentTests would look something like this: import static org.junit.Assert.*; @SpringBootTest(classes = { SomeCasComponentConfiguration.class }) @TestPropertySource(properties = {\"cas.some.property=value\"}) @EnableConfigurationProperties(CasConfigurationProperties.class) public class SomeCasComponentTests { @ClassRule public static final SpringClassRule SPRING_CLASS_RULE = new SpringClassRule(); @Rule public final ConditionalIgnoreRule conditionalIgnoreRule = new ConditionalIgnoreRule(); @Rule public final SpringMethodRule springMethodRule = new SpringMethodRule(); @Rule public ExpectedException thrown = ExpectedException.none(); /* Injected via SomeCasComponentConfiguration... */ @Autowired @Qualifier(\"someCasComponent\") private SomeCasComponent someCasComponent; @Before public void initialize() { } @Test public void verifyStuffHappens() throws Exception { // Invoke someCasComponent.someMethod() and examine/assert the output } } In short, you need to make sure all the correct Configuration classes are included to bootstrap the build so that the required objects can be injected into the test class at runtime. You may also need to include additional modules and dependencies in the build.gradle file of the project to make sure the test runner has access to all required classes: dependencies { testImplementation project(\":support:cas-server-support-xyz\") testImplementation project(path: \":support:cas-server-support-xyz\", configuration: \"tests\") } For best examples, scan the codebase to find similar test classes and try to follow the same pattern and structure as others to keep things as consistent as possible. Integration Tests If the change you are working on has a dependency on an external system such as a REST API or SQL database, you will need to make sure the test class is categorized appropriately. For example, let’s assume that SomeCasComponentTests requires an external Redis NoSQL database which means that your test class should indicate this as such: @Category(RedisCategory.class) @ConditionalIgnore(condition = RunningContinuousIntegrationCondition.class) public class SomeCasComponentTests { ... } Note that the test execution would always fail if the Redis database isn’t installed, running and configured correctly for everyone else working on the same CAS codebase. To work around this, we have also added a condition for the test runner to only execute the test when the CAS CI environment is handling the test execution. The CI environment, given the appropriate category, will bootstrap and initialize the required dependencies and systems (typically via Docker) for the tests to execute which allows you to run the tests locally with a (Redis) database of your own while allowing the CI process to handle the test execution all the same, automatically and with the needed external dependencies. Again, for better examples simply scan the codebase to find similar test classes. Running Tests Our Gradle test commands need to be slightly modified to only run the tests that need to run based on the category of interest. For example, to run all Redis-related tests our test command would look like this: clear cd ~/Workspace/cas ./gradlew clean testRedis -x test -x javadoc \\ --build-cache --configure-on-demand -DtestCategoryType=REDIS -x check --parallel -DskipNestedConfigMetadataGen=true \\ -DskipNestedConfigMetadataGen=true -DskipSass=true \\ -DskipNodeModulesCleanUp=true -DskipNpmCache=true' Or, to run simple unit tests our test command would look like this: clear cd ~/Workspace/cas ./gradlew clean test -x javadoc \\ --build-cache --configure-on-demand -DtestCategoryType=SIMPLE -x check --parallel -DskipNestedConfigMetadataGen=true \\ -DskipNestedConfigMetadataGen=true -DskipSass=true \\ -DskipNodeModulesCleanUp=true -DskipNpmCache=true' Note the use of the testCategoryType parameter as well as the actual task that runs the tests (test vs testRedis). To learn more about other available categories and how they are executed, please take a look here. But it works on my machine...Ultimately, all tests need to execute and pass on the CAS CI environment. There are the occasional phantom and unrelated failures which can usually be safely ignored but the canonical reference for tests and verifications is always the CI environment. When you write tests, try not to make assumptions that would later fail when the test is examined by CI. So… I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Happy Coding, Misagh Moayyed [1] There are ways to get around this limitation, by specifically downloading the source code for the exact CAS version at hand. I am skipping over those since they only lead to complications, suffering and further evil in most cases.",
    "tags": "CAS",
    "url": "/2018/11/20/cas60x-codebase-feature-build/"
  },

  
  
  
  {
    "title": "CAS 6.0.x Deployment - WAR Overlays",
    "text": "This is a short and sweet tutorial on how to deploy CAS via the WAR Overlay method. This tutorial specifically requires and focuses on: CAS 6.0.x Java 11 Need Help?If you ever get stuck and are in need of additional assistance, start by reviewing the suggestions provided here. You may also look at available support options provided here. Overlay…What? Overlay’s Anatomy Properties Dependencies The Build Configuration Keep Track LDAP Authentication Registering Applications Configuration Ticketing Configuration Multifactor Authentication via Duo Security Configuration Monitoring &amp; Status Configuration Overlay Customization User Interface Customizations Deploy Deploy Behind a Proxy What About…? So… Overlay…What? Overlays are a strategy to combat repetitive code and/or resources. Rather than downloading the CAS codebase and building it from source, overlays allow you to download a pre-built vanilla CAS web application server provided by the project itself, override/insert specific behavior into it and then merge it all back together to produce the final (web application) artifact. You can find a lot more about how overlays work here. The concept of the WAR Overlay is NOT a CAS invention. It’s specifically an Apache Maven feature and of course, there are techniques and plugins available to apply the same concept to Gradle-based builds as well. For this tutorial, the Gradle overlay we will be working with is available here. Gradle WAR OverlayThe Maven WAR overlay template is now deprecated and moved aside. The reference overlay project simply resides here and is transformed to use the Gradle build tool instead. This is done to reduce maintenance overhead and simplify the deployment strategy while allowing future attempts to make auto-generation of the overlay as comfortable as possible. Once you have forked and cloned the repository locally, you’re ready to begin. NoteRemember to switch to the appropriate branch. Today, the master branch of the repository applies to CAS 6.0.x deployments. That may not necessarily remain true when you start your own deployment. So examine the branches and make sure you checkout the one matching your intended CAS version. Overlay’s Anatomy Similar to Grey’s, a Gradle WAR overlay is composed of several facets the most important of which are the build.gradle and gradle.properties file. These are build-descriptor files whose job is to teach Gradle how to obtain, build, configure (and in certain cases deploy) CAS artifacts. KISSYou do not need to download Gradle separately. The project provides one for you automatically with the embedded Gradle Wrapper. The CAS Gradle Overlay is composed of several sections. The ones you need to worry about are the following. Properties In gradle.properties file, project settings and versions are specified: cas.version=6.0.0 springBootVersion=2.1.0.RELEASE appServer=-tomcat gradleVersion=4.10.2 tomcatVersion=9 tomcatFullVersion=9.0.12 group=org.apereo.cas sourceCompatibility=11 targetCompatibility=11 The gradle.properties file describes what versions of CAS, Spring Boot, and Java are required for the deployment. You are in practice mostly concerned with the cas.version setting and as new (maintenance) releases come out, it would be sufficient to simply update that version and re-run the build. This might be a good time to review the CAS project’s Release Policy as well as Maintenance Policy. Dependencies The next piece describes the dependencies of the overlay build. These are the set of components almost always provided by the CAS project that will be packaged up and put into the final web application artifact. At a minimum, you need to have the cas-server-webapp-${appServer} module available because that is the web application into which you intend to inject your settings and customizations if any. Also, note that the module declarations are typically configured to download the CAS version instructed by the property cas.version. Here is an example: dependencies { if (project.hasProperty(\"external\")) { compile \"org.apereo.cas:cas-server-webapp:${casServerVersion}\" } else { compile \"org.apereo.cas:cas-server-webapp${project.appServer}:${casServerVersion}\" } // Other dependencies may be listed here... } Including a CAS module/dependency in the build.gradle simply advertises to CAS your intention of turning on a new feature or a variation of a current behavior. Do NOT include something in your build just because it looks and sounds cool. Remember that the point of an overlay is to only keep track of things you actually need and care about, and no more. RememberKeep your build clean and tidy. A messy build often leads to a messy deployment, complicates your upgrade path and is a documented cause of early hair loss. Keep changes down to the absolute essentials and document their need for your deployment. If you review the configuration a year from now, you should have an idea of why things are the way they are. The Build Now that you have a basic understanding of the build descriptor, it’s time to actually run the build. A Gradle build is often executed by passing specific goals/commands to Gradle itself, aka gradlew. So for instance in the terminal and once inside the project directory you could execute things like: cd cas-overlay-template gradlew clean The WAR Overlay project provides you with an embedded Gradle wrapper whose job is to first determine whether you have Gradle installed. If not, it will download and configure one for you based on the project’s needs. So, how are you supposed to know what commands/goals can be passed to the build? You can hit the Gradle guides and docs to study these for sure, but the Overlay project also provides you with a shell script that wraps itself around the Gradle wrapper and provides an easy facade for you to remember commands and their use. NoteWhen in doubt, gradlew tasks is a good starting position to learn what tasks are available in the project. This is the build.sh file, which you can run as such: cd cas-overlay-template ./build.sh help Usage: build.sh ... The help command describes the set of available operations you may carry out with the build script. RememberDocs grow old. Always consult the overlay project's README file to keep to date. As an example, here’s what I see if I were to run the package command: ./build.sh copy package Creating configuration directory under /etc/cas Copying configuration files from etc/cas to /etc/cas/config etc/cas/config/application.yml -&gt; /etc/cas/config/application.yml etc/cas/config/cas.properties -&gt; /etc/cas/config/cas.properties etc/cas/config/log4j2.xml -&gt; /etc/cas/config/log4j2.xml Starting a Gradle Daemon (subsequent builds will be faster) Configuration on demand is an incubating feature. BUILD SUCCESSFUL in 14s 2 actionable tasks: 2 executed ... You can see that the build attempts to download, clean, compile and package all artifacts, and finally, it produces a build/libs/cas.war which you can then use for actual deployments. RememberYou are allowed to pass any of Gradle's native command-line arguments to the build.sh file. Configuration I am going to skip over the configuration of /etc/cas/config and all that it deals with. If you need the reference, you may always use this guide to study various aspects of CAS configuration. Suffice it to say that, quite simply, CAS deployment expects the main configuration file to be found under /etc/cas/config/cas.properties. This is a key-value store that is able to dictate and alter the behavior of the running CAS software. As an example, you might encounter something like: cas.server.name=https://cas.example.org:8443 cas.server.prefix=https://cas.example.org:8443/cas logging.config=file:/etc/cas/config/log4j2.xml …which at a minimum, identifies the CAS server’s URL and prefix and instructs the running server to locate the logging configuration at file:/etc/cas/config/log4j2.xml. The overlay by default ships with a log4j2.xml that you can use to customize logging locations, levels, etc. Note that the presence of all that is contained inside /etc/cas/config/ is optional. CAS will continue to fall back onto defaults if the directory and the files within are not found. Keep Track It is VERY IMPORTANT that you contain and commit the entire overlay directory (save the obvious exclusions such as the build directory) into some sort of source control system, such as git. Treat your deployment just like any other project with tags, releases, and functional baselines. LDAP Authentication We need to first establish a primary mode of validating credentials by sticking with LDAP authentication. The strategy here, as indicated by the CAS documentation, is to declare the intention/module in the build script: compile \"org.apereo.cas:cas-server-support-ldap:${casServerVersion}\" …and then configure the relevant cas.authn.ldap[x] settings for the directory server in use. Most commonly, that would translate into the following settings: cas.authn.ldap[0].type=AUTHENTICATED cas.authn.ldap[0].ldapUrl=ldaps://ldap1.example.org cas.authn.ldap[0].baseDn=dc=example,dc=org cas.authn.ldap[0].searchFilter=cn={user} cas.authn.ldap[0].bindDn=cn=Directory Manager,dc=example,dc=org cas.authn.ldap[0].bindCredential=... To resolve and fetch the needed attributes which will be used later by CAS for release, the simplest way would be to let LDAP authentication retrieve the attributes directly from the directory server. The following setting allows us to do just that: cas.authn.ldap[0].principalAttributeList=memberOf,cn,givenName,mail Registering Applications Client applications that wish to use the CAS server for authentication must be registered with the server apriori. CAS provides a number of facilities to keep track of the registration records and you may choose any that fits your needs best. In more technical terms, CAS deals with service management using two specific components: Individual implementations that support a form of a database are referred to as Service Registry components and they are many. There is also a parent component that sits on top of the configured service registry as more of an orchestrator that provides a generic facade and entry point for the rest of CAS without entangling all other operations and subsystems with the specifics and particulars of a storage technology. In this tutorial, we are going to try to configure CAS with the JSON service registry. Configuration First, ensure you have declared the appropriate module/intention in the build: compile \"org.apereo.cas:cas-server-support-json-service-registry:${casServerVersion}\" Next, you must teach CAS how to look up JSON files to read and write registration records. This is done in the cas.properties file: cas.serviceRegistry.initFromJson=false cas.serviceRegistry.json.location=file:/etc/cas/services …where a sample ApplicationName-1001.json would then be placed inside /etc/cas/services: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://app.example.org\", \"name\" : \"ApplicationName\", \"id\" : 1001, \"evaluationOrder\" : 10 } Ticketing A robust CAS deployment requires the presence and configuration of an internal database that is responsible for keeping track of tickets issued by CAS. CAS itself comes by default with a memory-based node-specific cache that is often more than sufficient for smaller deployments or certain variations of a clustered deployment. Just like the service management facility, large variety of databases and storage options are supposed by CAS under the facade of a Ticket Registry. In this tutorial, we are going to configure CAS to use a Hazelcast Ticket Registry with the assumption that our deployment is going to be deployed in an AWS-sponsored environment. Hazelcast Ticket Registry is often a decent choice when deploying CAS in a cluster and can take advantage of AWS’s native support for Hazelcast in order to read node metadata properly and locate other CAS nodes in the same cluster in order to present a common, global and shared ticket registry. This is an ideal choice that requires very little manual work and/or troubleshooting, comparing to using options such as Multicast or manually noting down the address and location of each CAS server in the cluster. Configuration First, ensure you have declared the appropriate module/intention in the build: compile \"org.apereo.cas:cas-server-support-hazlcast-ticket-registry:${casServerVersion}\" Next, the AWS-specific configuration of Hazelcast would go into our cas.properties: cas.ticket.registry.hazelcast.cluster.discovery.enabled=true cas.ticket.registry.hazelcast.cluster.discovery.aws.accessKey=... cas.ticket.registry.hazelcast.cluster.discovery.aws.secretKey=... cas.ticket.registry.hazelcast.cluster.discovery.aws.region=us-east-1 cas.ticket.registry.hazelcast.cluster.discovery.aws.securityGroupName=... # cas.ticket.registry.hazelcast.cluster.discovery.aws.tagKey= # cas.ticket.registry.hazelcast.cluster.discovery.aws.tagValue= That should do it. Of course, if you are working on a more modest CAS deployment in an environment that is more or less owned by you and you prefer more explicit control over CAS node registrations in your cluster, the following settings would be more ideal: # cas.ticket.registry.hazelcast.cluster.instanceName=localhost # cas.ticket.registry.hazelcast.cluster.port=5701 # cas.ticket.registry.hazelcast.cluster.portAutoIncrement=true cas.ticket.registry.hazelcast.cluster.members=123.321.123.321,223.621.123.521,... Multifactor Authentication via Duo Security As a rather common use case, the majority of CAS deployments that intend to turn on multifactor authentication support tend to do so via Duo Security. We will be going through the same exercise here where we let CAS trigger Duo Security for users who belong to the mfa-eligible group, indicated by the memberOf attribute on the LDAP user account. Configuration First, ensure you have declared the appropriate module/intention in the build: compile \"org.apereo.cas:cas-server-support-duo:${casServerVersion}\" Then, put specific Duo Security settings in `cas.properties. Things such as the secret key, integration key, etc which should be provided by your Duo Security subscription: cas.authn.mfa.duo[0].duoSecretKey= cas.authn.mfa.duo[0].duoApplicationKey= cas.authn.mfa.duo[0].duoIntegrationKey= cas.authn.mfa.duo[0].duoApiHost= At this point, we have enabled Duo Security and we just need to find a way to instruct CAS to route the authentication flow over to Duo Security in the appropriate condition. Our task here is to build a special condition that activates multifactor authentication if any of the values assigned to the attribute memberOf contain the value mfa-eligible. This condition is placed in the cas.properties file: cas.authn.mfa.globalPrincipalAttributeNameTriggers=memberOf cas.authn.mfa.globalPrincipalAttributeValueRegex=mfa-eligible If the above condition holds true and CAS is to route to a multifactor authentication flow, that would obviously be one supported and provided by Duo Security since that’s the only provider that is currently configured to CAS. Monitoring &amp; Status Many CAS deployments rely on the /status endpoint for monitoring the health and activity of the CAS deployment. This endpoint is typically secured via an IP address, allowing external monitoring tools and load balancers to reach the endpoint and parse the output. In this quick exercise, we are going to accomplish that task, allowing the status endpoint to be available over HTTP to localhost. Configuration To enable and expose the status endpoint, the following settings should come in handy: management.endpoints.web.base-path=/actuator management.endpoints.web.exposure.include=status management.endpoint.status.enabled=true cas.monitor.endpoints.endpoint.status.access=IP_ADDRESS cas.monitor.endpoints.endpoint.status.requiredIpAddresses=127.0.0.1 Remember that the default path for endpoints exposed over the web is at /actuator, such as /actuator/status. Overlay Customization The build/libs directory contains the results of the overlay process. Since I have not actually customized and overlaid anything yet, all configuration files simply match their default and are packaged as such. As an example, let’s grab the default message bundle and change the text associated with screen.welcome.instructions. RememberDo NOT ever make changes in the build directory. The changesets will be cleaned out and set back to defaults every time you do a build. Follow the overlay process to avoid surprises. First, I will need to move the file to my project directory so that during the overlay process Gradle can use that instead of what is provided by default. Here we go: ./build.sh getresource messages.properties Exploded the CAS web application file at build/cas Searching for resource name messages.properties... Found resource(s): build/cas/WEB-INF/classes/messages.properties Created resource at src/main/resources/messages.properties src/main/resources/messages.properties Then I’ll leave everything in that file alone, except the line I want to change. ... screen.welcome.instructions=Speak friend and enter. ... Then I’ll package things up as usual. ./build.sh package If I explode the built web application again and look at build/cas/WEB-INF/classes/messages.properties after the build, I should see that the overlay process has picked and overlaid onto the default my version of the file. RememberOnly overlay and modify files you actually need and try to use externalized resources and configuration as much as possible. Just because you CAN override something in the default package, it doesn't mean that you should. User Interface Customizations In order to modify the CAS HTML views, each file first needs to be brought over into the overlay. You can use the build.sh listviews command to see what HTML views are available for customizations. Once chosen, simply use build.sh getview footer.html to bring the view into your overlay. Exploded the CAS web application file at build/cas Searching for view name footer.html... Found view(s): build/cas/WEB-INF/classes/templates/fragments/footer.html Created view at src/main/resources/templates/fragments/footer.html src/main/resources/templates/fragments/footer.htm Now that you have the footer.html brought into the overlay, you can simply modify the file at src/main/resources/templates/fragments/footer.html, and then repackage and run the build as usual. Deploy You have a number of options when it comes to deploying the final cas.war file. The easiest approach would be to simply use the build.sh run command and have the overlay be deployed inside an embedded container. By default, the CAS web application expects to run on the secure port 8443 which requires that you create a keystore file at /etc/cas/ named thekeystore. Deploy Behind a Proxy Using the embedded Apache Tomcat container provided by CAS automatically is the recommended approach in almost all cases (The embedded bit; not the Apache Tomcat bit) as the container configuration is entirely automated by CAS and its version is guaranteed to be compatible with the running CAS deployment. Furthermore, updates and maintenance of the servlet container are handled at the CAS project level where you as the adopter are only tasked with making sure your deployment is running the latest available release to take advantage of such updates. If you wish to run CAS via the embedded Apache Tomcat container behind a proxy or load balancer and have that entity terminate SSL, you will need to open up a communication channel between the proxy and CAS such that (as an example): Apache Tomcat runs on port 8080, assuming that’s what the proxy uses to talk to CAS. Apache Tomcat has SSL turned off. Apache Tomcat connector listening on the above port is marked as secure. The above tasklist translates to the following properties expected to be found in your cas.properties: server.port=8080 server.ssl.enabled=false cas.server.tomcat.http.enabled=false cas.server.tomcat.httpProxy.enabled=true cas.server.tomcat.httpProxy.secure=true cas.server.tomcat.httpProxy.scheme=https What About…? For more content, please see this link. So… It’s important that you start off simple and make changes one step at a time. Once you have a functional environment, you can gradually and slowly add customizations to move files around. I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/11/16/cas60-gettingstarted-overlay/"
  },

  
  
  
  {
    "title": "Apereo CAS - Jib at CAS Docker Images",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Unless you’ve been living under a rock, you’ve probably heard about Docker. By combining its container engine technology and container platform, Docker enables you to bring traditional and cloud-native applications into an automated and secure supply chain, advancing dev to ops collaboration and reducing time to value. CAS embraced Docker a while ago by providing a sample Dockerfile template to kickstart the builds. This template simply wraps the necessary environment and components, such as OS and Java, around an existing WAR Overlay project. There is a fair amount of smarts and creativity that could go into the build to optimize build layers, take advantage of Docker multi-stage builds and more to produce an ideal CAS image for deployment. This tutorial focuses on an alternative approach to building CAS docker images by using Jib. Jib is an open-source Java containerizer from Google that lets Java developers build containers using the tools they know. It is a container image builder that handles all the steps of packaging your application into a container image. It does not require you to write a Dockerfile or have Docker installed, and it is directly integrated into Maven and Gradle. Starting with CAS 6, The existing Gradle overlay embraces the Jib Gradle Plugin to provide easy-to-use out-of-the-box tooling for building CAS docker images. Our starting position is based on the following: CAS 6.0.0-RC4 Java 11 CAS Overlay (The master branch specifically) Docker Overview Once you have cloned the CAS WAR overlay, a rather simplified workflow for building a CAS Docker image using jib is as follows: Create a valid keystore at ${overlay-path}/etc/cas/thekeystore Massage your CAS configuration for settings and logging at ${overlay-path}/etc/cas/config Build the CAS overlay to produce and run the docker image. Assuming you have completed the first two steps, let’s move on to the build step. Docker Image If you execute the build shell script, you should be greeted with a new docker command as such: ./build.sh help Apereo CAS Enterprise Single SignOn for all earthlings and beyond ***************************************************** Usage: build.sh [...] ... docker: Build a Docker image based on the current build and configuration ... Seems like the one we might need. Let’s run it: ./build.sh docker ... Configuration on demand is an incubating feature. warning: Setting image creation time to current time; your image may not be reproducible. Containerizing application to Docker daemon as org.apereo.cas/cas... Getting base image adoptopenjdk/openjdk11:jdk11-alpine-nightly-slim... Building dependencies layer... Building snapshot dependencies layer... Building resources layer... Building classes layer... The base image requires auth. Trying again for adoptopenjdk/openjdk11:jdk11-alpine-nightly-slim... Finalizing... Container entrypoint set to [docker/entrypoint.sh] Loading to Docker daemon... Built image to Docker daemon as org.apereo.cas/cas What’s happening here is that the Gradle build is invoking the jib plugin to fetch a base image, and then build all other required layers on top of it. Our CAS settings and logging configuration, etc as well as the cas.war are moved into the image to subsequently be handled via the startup shell script, which is the point where we instruct the build and Docker to use an entrypoint allowing our image to turn into a running container. If you query for available Docker images, you might see: docker images ... org.apereo.cas/cas latest 34a3d3502970 4 minutes ago 551MB ... …which may then conveniently be executed via the following: docker run --name cas -p 8443:8443 -d org.apereo.cas/cas docker logs -f cas That is all it takes. Aftermath It is evidently very convenient to use the same CAS build to generate a Docker image without dabbling too much into the specifics and nuances of a Dockerfile syntax. There are also few configuration options available in the Gradle build that allow one to decide the base image, expose ports and assign tags and labels. More interestingly and while the CAS build tries to keep things simple, jib really makes pushing images to remote registries easy by supporting the likes of Docker Hub, Google Container Registry and Amazon Elastic Container Registry all in on spot using a familiar consistent syntax. In doing so, it should be noted that the jib plugin and project is relatively new with the initial project announcement dating back to July 2018. Furthermore, support for Spring Boot projects and especially those that build WARs and double-specifically those that depend and work with WAR Overlays such as CAS is extremely brand new. It is completely plausible that future iterations of the plugin allow tighter integrations with the Docker engine to produce better-optimized images, expose more configuration knobs and keep improving WAR support. If the current behavior and capabilities of this plugin do not meet the requirements, you’re welcome to continue using the native Dockerfile approach and keep an eye towards newer versions of the plugin. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/11/09/cas6-docker-jib/"
  },

  
  
  
  {
    "title": "Apereo CAS 6 - Administrative Endpoints &amp; Monitoring",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. CAS, being a Spring-Boot application at heart, includes a number of endpoints to help you monitor and manage the server when it’s pushed to production. You can choose to manage and monitor the deployment using HTTP endpoints, referred to as actuators. This tutorial provides a basic overview of the endpoints provided by both Spring Boot and CAS and also provides instructions on how such endpoints can be secured for access and win. This tutorial specifically requires and focuses on: Our starting position is based on the following: CAS 6.0.0-RC4 Java 11 CAS Overlay (The master branch specifically) CLI JSON Processor jq Actua…What? In essence, actuator endpoints bring production-ready features to CAS. Monitoring a running CAS instance, gathering metrics, understanding traffic or the state of our database becomes trivial with such endpoints. The main benefit of these endpoints is that we can get production grade tools without having to actually implement these features ourselves. Actuators are mainly used to expose operational information about the running application – health, metrics, info, dump, env, etc. These are HTTP endpoints or JMX beans to enable us to interact with it. DefinitionAn actuator is a manufacturing term, referring to a mechanical device for moving or controlling something. Actuators can generate a large amount of motion from a small change. The full list of endpoints provided to your CAS deployment is posted here. Note that you do not need to do anything extra special to get these endpoints added to your deployment; these are all available by default and just need to be turned on and secured for access. Endpoints Starting with Spring Boot 2 and CAS 6.0.x, the actuator endpoints and their method of security are entirely revamped. Here are the main differences: Endpoints can individually be exposed over the web under HTTP. Security of each endpoint using the combo of enabled and sensitive is now gone, and each endpoint entirely embraces Spring Security for protection. Endpoints internally are marked as @Endpoint and can be standalone or extensions of existing endpoints such as /health. Enabling an endpoint may pass through several layers of security: Default setting if undefined, globally or per endpoint. Examples Let’s go through a number of scenarios that might be helpful. Bear in mind that in order to work with an endpoint, you must go through the following steps: The endpoint must be enabled. The endpoint may be somehow exposed. The endpoint may be somehow secured. Remember that the default path for endpoints exposed over the web is at /actuator, such as /actuator/status. Example 1 Expose the CAS status endpoint over the web, enable it and make sure its protected via basic authentication: management.endpoints.web.exposure.include=status management.endpoint.status.enabled=true cas.monitor.endpoints.endpoint.status.access=AUTHENTICATED spring.security.user.name=casuser spring.security.user.password=Mellon Example 2 Expose the CAS status endpoint over the web, enable it and make sure a list of IP addresses can reach it: management.endpoints.web.exposure.include=status management.endpoint.status.enabled=true cas.monitor.endpoints.endpoint.status.access=IP_ADDRESS cas.monitor.endpoints.endpoint.status.requiredIpAddresses=1.2.3.4,0.0.0.0 Example 3 Expose the Spring Boot health and info endpoints over the web, enable them and make sure access to health is secured via basic authentication: management.endpoints.web.exposure.include=health,info management.endpoint.health.enabled=true management.endpoint.health.show-details=always management.endpoint.info.enabled=true cas.monitor.endpoints.endpoint.health.access=AUTHENTICATED cas.monitor.endpoints.endpoint.info.access=ANONYMOUS spring.security.user.name=casuser spring.security.user.password=Mellon Example 4 Enable and expose all endpoints with no regard for security: management.endpoints.web.exposure.include=* management.endpoints.enabled-by-default=true cas.monitor.endpoints.endpoint.defaults.access=ANONYMOUS WATCH OUT!The above collection of settings MUST only be used for demo purposes and serve as an EXAMPLE. It is not wise to enable and expose all actuator endpoints to the web and certainly, the security of the exposed endpoints should be taken into account very seriously. None of the CAS or Spring Boot actuator endpoints are enabled by default. For production, you should carefully choose which endpoints to expose. Example 5 In addition to the usual, let’s remap the path to endpoints to start with endpoints instead of actuator, and lets rename the status endpoint to be heartbeat: management.endpoints.web.path-mapping.status=heartbeat management.endpoints.web.base-path=/endpoints management.endpoints.web.exposure.include=status management.endpoint.status.enabled=true cas.monitor.endpoints.endpoint.status.access=IP_ADDRESS cas.monitor.endpoints.endpoint.status.requiredIpAddresses=1.2.3.4 Dashboard Note that all GUIs related to CAS endpoints are removed and will be slightly transitioned over to the CAS Management Web Application. However, while the screens may be gone the underlying functionality remains all the same. For example, provided the endpoint is correctly enabled and secured you can invoke the statistics endpoint to get the required data: curl -k https://sso.example.org/cas/actuator/statistics | jq …where you’d see something like this: { \"upTime\": 64, \"totalMemory\": \"1 GB\", \"expiredTgts\": 0, \"expiredSts\": 0, \"maxMemory\": \"4 GB\", \"freeMemory\": \"615 MB\", \"unexpiredTgts\": 0, \"unexpiredSts\": 0 } Over time, this data should become accessible via the management application. Remember that for endpoints which are native to and provided by Spring Boot, you may always try the Spring Boot Admin Server. So… It’s important that you start off simple and make changes one step at a time. Once you have a functional environment, you can gradually and slowly add customizations to move files around. I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/11/06/cas6-admin-endpoints-security/"
  },

  
  
  
  {
    "title": "Apereo CAS - SAML2 Metadata with MongoDb",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. MongoDB is a free and open-source cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schemata and is supported in CAS in many different ways. In this walkthrough, we are going to take a pass at getting CAS connected to MongoDB to store SAML2 identity provider and service provider metadata documents. Our starting position is based on the following: CAS 6.0.0-RC4 Java 11 CAS Overlay (The master branch specifically) Docker MongoDB To run MongoDB for development and testing, we can use the provided Docker image: docker run -d -p 27017:27017 -e MONGO_INITDB_ROOT_USERNAME=root \\ -e MONGO_INITDB_ROOT_PASSWORD=secret --name=\"mongodb-server\" mongo:4.0-xenial docker ps This runs a MongoDB database server which is useful for development but SHOULD NOT be used in production. To access the MongoDB instance using a UI, run: docker run --link mongodb-server -d -p 8081:8081 \\ -e 'ME_CONFIG_MONGODB_ADMINUSERNAME=root' \\ -e 'ME_CONFIG_MONGODB_ADMINPASSWORD=secret' \\ -e 'ME_CONFIG_MONGODB_SERVER=mongodb-server' mongo-express The ME_CONFIG_MONGODB_SERVER is the address of the docker container that runs the MongoDB server. By default, Docker containers use the container as the DNS host name. So we can just specify the mongodb-server the name of the container that runs our MongoDB instance. Shell into the container: CID=docker ps -aqf name=mongodb-server docker exec -it $CID /bin/bash When inside the container: mongo --host mongodb://root:secret@localhost:27017 use database cas; # Create a database user for authentication db.createUser({user:\"casuser\", pwd:\"Mellon\", roles: [\"readWrite\", \"dbAdmin\"]}) Point your browser to http://localhost:8081 and let’s create a collection called cas-saml-sp-metadata with the following document: Note the value field which contains a base64-encoded version of the metadata for a SAML2 service provider which makes it easier to get the metadata added to the MongoDB document. I am also skipping over the metadata signature that would have been used to validate its integrity and that could have just as easily been added to the document using a signature field. That should do for now. Let’s get CAS running. CAS SAML2 Service Provider Metadata So in order to enable a CAS integration with MongoDB directly, you want to start with the CAS Overlay, clone the project and follow the notes here to get CAS acting as SAML2 identity provider. In its simplest form, it comes to down to the following settings: cas.authn.samlIdp.entityId=https://sso.example.org/idp cas.authn.samlIdp.scope=example.org cas.authn.samlIdp.metadata.location=file:/etc/cas/config/saml …and this module in the CAS build: compile \"org.apereo.cas:cas-server-support-saml-idp:${project.'cas.version'}\" To keep things simple, we could use the JSON service registry to manage our SAML2 service provider definitions. Here is what our service definition might look like for SAML2 service provider in a SAML-1.json file: { \"@class\" : \"org.apereo.cas.support.saml.services.SamlRegisteredService\", \"serviceId\" : \"&lt;your-sp-entity-id&gt;\", \"name\" : \"SAML\", \"id\" : 1, \"description\" : \"This SP has its metadata in MongoDB somewhere.\", \"metadataLocation\" : \"mongodb://\" } The metadata location in the registration record above simply needs to be specified as mongodb:// to signal to CAS that SAML metadata for our service provider must be fetched from MongoDB data sources defined in CAS configuration. As the next step, let’s teach CAS about our MongoDB setup. Just like before, you’d need this module in your CAS build: compile \"org.apereo.cas:cas-server-support-saml-idp-metadata-mongo:${project.'cas.version'}\" …and CAS needs to know how to connect to MongoDB to fetch stuff: cas.authn.samlIdp.metadata.mongo.host=localhost cas.authn.samlIdp.metadata.mongo.port=27017 cas.authn.samlIdp.metadata.mongo.userId=casuser cas.authn.samlIdp.metadata.mongo.password=Mellon cas.authn.samlIdp.metadata.mongo.collection=cas-saml-sp-metadata cas.authn.samlIdp.metadata.mongo.databaseName=cas That’s it. Build and run CAS. At this point, you should be able to log into service provider successfully whose metadata is fetched and processed by CAS from MongoDB. SAML2 Identity Provider Metadata If you examine your CAS startup logs, you might notice the following statement: [...FileSystemSamlIdPMetadataLocator] - &lt;Metadata directory location is at [/etc/cas/config/saml]&gt; …which matches our setting above: cas.authn.samlIdp.metadata.location=file:/etc/cas/config/saml Metadata artifacts that belong to CAS as a SAML2 identity provider may also be managed and stored via MongoDb. This includes things such as the metadata XML document, signing and encryption keys, etc. While CAS has the ability to generate brand new metadata in MongoDB, let’s instead figure out how our existing metadata might be relocated to MongoDB. Let’s create a MongoDB collection called saml-idp-metadata in our cas database to hold IdP artifacts with the following document in it: { \"signingCertificate\": \"...\", \"signingKey\": \"...\", \"encryptionCertificate\": \"...\", \"encryptionKey\": \"...\", \"metadata\": \"...\" } Here is the drill: The metadata, signing and encryption certificates may be base64-encoded. The signing and encryption keys MUST be signed and encrypted using CAS crypto settings and keys. The signing secret key and the encryption secret key are both JWKs of size 512 and 256. We can use the command-line shell to create the two keys: cas&gt; generate-key key-size 512 $signingKey cas&gt; generate-key key-size 256 $encryptionKey Once you have the keys, you can try to secure the metadata keys: cas&gt; cipher-text file /etc/cas/config/saml/idp-signing.key signing-key $signingKey encryption-key $encryptionKey ... cas&gt; cipher-text file /etc/cas/config/saml/idp-encryption.key signing-key $signingKey encryption-key $encryptionKey ... The signing and encryption SAML2 metadata keys plus the base64-encoded versions of the signing and encryption certificates and the metadata XML can next be put into the MongoDB document. CAS settings will then take on the following form: # cas.authn.samlIdp.metadata.location=file:/etc/cas/config/saml cas.authn.samlIdp.metadata.mongo.idpMetadataCollection=saml-idp-metadata cas.authn.samlIdp.metadata.mongo.crypto.encryption.key=$encryptionKey cas.authn.samlIdp.metadata.mongo.crypto.signing.key=$signingKey Build and run CAS. At this point, you should be able to log into the service provider successfully with CAS using its own SAML2 metadata from MongoDB to produce a SAML2 response, etc. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/11/03/cas6-saml2-metadata-mongodb/"
  },

  
  
  
  {
    "title": "Apereo CAS - Slurp Configuration with Groovy",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. CAS allows you to externalize your configuration settings so you can work with the same CAS instance in different environments. You can use properties files, YAML files, environment variables and command-line arguments (just to name a few!) to externalize and provide configuration. These strategies present a very flexible and powerful way to manage CAS configuration for production deployments in a variety of use cases. As your CAS deployment moves through the deployment pipeline from dev to test and into production, you can manage the configuration between those environments separately, and be certain that each tier has everything it needs to run when the server migrates. Tier-specific configuration is usually managed and activated through the use of application (aka. Spring) profiles while the rest of the more common settings are gathered centrally that apply to all environments. When you run CAS in standalone mode specially, the default configuration directory on the filesystem (i.e. /etc/cas/config) may include (cas|application).(yaml|yml|properties) files that can be used to control behavior. Such configuration files may also specifically apply to a profile (i.e. ldap.properties) that can be activated using spring.profiles.active or spring.profiles.include settings. Starting with CAS 6, Groovy can also serve as a strategy for loading configuration in a way that allows one to consolidate common and tier-specific files in one place. This tutorial explores that possibility with a starting position is based on the following: CAS 6.0.0-RC4 Java 11 CAS Overlay (The master branch specifically) Groovy ConfigSlurper If you are familiar with Groovy, then ConfigSlurper is no stranger to you. This is a utility class for reading configuration files defined in the form of Groovy scripts. Configuration settings can be defined using dot notation or scoped using closures: grails.webflow.stateless = true smtp { mail.host = 'smtp.myisp.com' mail.auth.user = 'server' } resources.URL = \"http://localhost:80/resources\" CAS takes advantage of this very component, allowing you to isolate tier-specific settings in form of conditional closures. In the simplest scenario, it expects to find a cas.groovy file in the same configuration directory while running standalone mode that might look like this: profiles { dev { cas.authn.accept.users=\"test::dev\" } prod { cas.authn.accept.users=\"test::prod\" } } cas.common.setting=\"value\" When you run CAS using the dev profile, the collection of settings that are picked up from the script are: cas.authn.accept.users=\"test::dev\" cas.common.setting=\"value\" …and when you run CAS using the prod profile, the collection of settings that are picked up from the script are: cas.authn.accept.users=\"test::prod\" cas.common.setting=\"value\" For small configuration changes between tiers, this is arguably simpler than having, for example, cas.properties, dev.properties and prod.properties files. For anything else larger and more complicated, you still may want to think about separating settings into multiple files or perhaps consider using the Spring Cloud Config Server. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/11/02/cas6-groovy-config-slurper/"
  },

  
  
  
  {
    "title": "Apereo CAS - Configuration Management with MongoDb",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. MongoDB is a free and open-source cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schemata. MongoDB is developed by MongoDB Inc., and is published under a combination of the Server Side Public License and the Apache License. MongoDB is supported in CAS in many different ways. In this walkthrough, we are going to take a pass at getting CAS connected to MongoDB to store properties and settings. We will also try to reload settings dynamically in real-time as they are changed and updated inside MongoDB databases. Our starting position is based on the following: CAS 6.0.0-RC4 Java 11 CAS Overlay (The master branch specifically) Docker CLI JSON Processor jq MongoDB To run MongoDB for development and testing, we can use the provided Docker image: docker run -d -p 27017:27017 -e MONGO_INITDB_ROOT_USERNAME=root \\ -e MONGO_INITDB_ROOT_PASSWORD=secret --name=\"mongodb-server\" mongo:4.0-xenial docker ps This runs a MongoDB database server which is useful for development but SHOULD NOT be used in production. To access the MongoDB instance using a UI, run: docker run --link mongodb-server -d -p 8081:8081 \\ -e 'ME_CONFIG_MONGODB_ADMINUSERNAME=root' \\ -e 'ME_CONFIG_MONGODB_ADMINPASSWORD=secret' \\ -e 'ME_CONFIG_MONGODB_SERVER=mongodb-server' mongo-express The ME_CONFIG_MONGODB_SERVER is the address of the docker container that runs the MongoDB server. By default, Docker containers use the container as the DNS host name. So we can just specify the mongodb-server the name of the container that runs our MongoDB instance. Shell into the container: CID=docker ps -aqf name=mongodb-server docker exec -it $CID /bin/bash When inside the container: mongo --host mongodb://root:secret@localhost:27017 use database cas; # Create a database user for authentication db.createUser({user:\"casuser\", pwd:\"Mellon\", roles: [\"readWrite\", \"dbAdmin\"]}) When ready, point your browser to http://localhost:8081 and let’s create a few documents with CAS settings in them. MongoDb documents are required to be found in the collection MongoDbProperty, as the following document: { \"id\": \"...\", \"name\": \"the-setting-name\", \"value\": \"the-setting-value\" } So I am going to create a MongoDB database called cas inside which the MongoDbProperty needs to be created. Next, each of the below settings will be housed inside an indibidual MongoDB document that matches the above JSON structure: cas.authn.accept.users=casuser::MongoDB management.endpoints.web.exposure.include=* management.endpoints.enabled-by-default=true cas.monitor.endpoints.endpoint.defaults.access=AUTHENTICATED spring.security.user.name=casuser spring.security.user.password=Mellon The end result will look something like this: WATCH OUT!The above collection of settings MUST only be used for demo purposes and serve as an EXAMPLE. It is not wise to enable and expose all actuator endpoints to the web and certainly, the security of the exposed endpoints should be taken into account very seriously. None of the CAS or Spring Boot actuator endpoints are enabled by default. For production, you should carefully choose which endpoints to expose. You may also want to create an index on name: That should do for now. Let’s get CAS running. CAS Integration with MongoDB in CAS to manage configuration can be done in a number of ways: If you have the Spring Cloud Config Server deployed, MongoDB could be one of its many sources for settings and properties. In this scenario, you will just need to make sure the CAS server can talk to the Spring Cloud Config Server correctly, and the Config Server is then in charge of communicating with MongoDB to fetch settings, etc. Alternatively, you may decide to connect your CAS server directly to MongoDB and fetch settings. This is the approach we are going to try in this tutorial for a quick win, but do note that the strategy is almost the same if we were to use the Cloud Config server. So in order to enable a CAS integration with MongoDB directly, you want to start with the CAS Overlay, clone the project and then put the following settings into a src/main/resources/bootstrap.properties file: spring.application.name=cas spring.profiles.active=mongodb cas.spring.cloud.mongo.uri=mongodb://casuser:Mellon@localhost:27017/cas Of course, don’t forget to include the required module in your CAS build: compile \"org.apereo.cas:cas-server-support-configuration-cloud-mongo:${project.'cas.version'}\" Build and deploy. At this point, you should be able to log into CAS using casuser and MongoDB as the credentials! Refresh &amp; Reload If a setting changes, MongoDB has no way to broadcast the updated value(s) to its own clients, such as the CAS server itself. Therefore, in order to broadcast such change events, CAS presents various endpoints that allow the user to refresh the configuration as needed. This means that an adopter would simply change a required CAS setting and then would submit a request to CAS to refresh its current state. At runtime! All CAS internal components that are affected by the external change are quietly reloaded and the setting takes immediate effect, completely removing the need for container restarts or CAS re-deployments. For example, start by changing the value of cas.authn.accept.users in MongoDB to something like casuser::HelloWorld. Then, execute the following command to refresh the CAS application context: curl -k -u casuser:Mellon https://sso.example.org/cas/actuator/refresh -d {} -H \"Content-Type: application/json\" ... [\"cas.authn.accept.users\"] At this point, you should be able to log into CAS using casuser and HelloWorld as the credentials! Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/10/31/cas6-configuration-mongodb/"
  },

  
  
  
  {
    "title": "Apereo CAS - Integration with HashiCorp Vault",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret while providing tight access control and recording a detailed audit log. The CAS integration with vault has been available for some time. In this walkthrough, we are going to take a pass at getting CAS connected to Vault to store properties and settings. We will also try to reload settings dynamically in real-time as they are changed and updated inside Vault. More HashiCorpYou may also be interested in a CAS integration with HashCorp Consul. Our starting position is based on the following: CAS 6.0.0-RC4 Java 11 CAS Overlay (The master branch specifically) Docker CLI JSON Processor jq Vault To run Vault for development and testing, we can use the provided Docker image: docker run --cap-add=IPC_LOCK -d -e 'VAULT_DEV_ROOT_TOKEN_ID=CAS' -p 8200:8200 --name=vault vault docker ps This runs a completely in-memory Vault server, which is useful for development but SHOULD NOT be used in production. Note the environment variable VAULT_DEV_ROOT_TOKEN_ID which sets the ID of the initially generated root token to the given value. We will use this token, later on, to log into the Vault UI and it will be also be utilized when CAS attempts to connect to Vault. To access the Vault UI, point your browser to http://localhost:8200/ui and use the above token to log into Vault where you’d be greeted with the following screen: So, let’s create a few secrets. Secrets inside Vault can be managed inside folders where from the CAS perspective, the folder hierarchy is expected to match the following: /secret/{application}/{profile} /secret/{application} …where application is the value of spring.application.name which is by default cas and the profile is any a tag/label assigned to a collection of settings that would be activated and fetched if the CAS server is deployed using said profile(s). So, as an example, we can create a secret for cas.authn.accept.users with the value of casuser::Vault. We will put this secret inside the path /secret/cas/vault where cas is the name of our application and vault is the profile name we shall activate when running CAS. Note that I have added a number of other settings to allow access to the CAS actuator endpoints. This will allow us to refresh the state of CAS application context, once a setting is updated with a new value. WATCH OUT!The above collection of settings MUST only be used for demo purposes and serve as an EXAMPLE. It is not wise to enable and expose all actuator endpoints to the web and certainly, the security of the exposed endpoints should be taken into account very seriously. None of the CAS or Spring Boot actuator endpoints are enabled by default. For production, you should carefully choose which endpoints to expose. That should do for now. Let’s get CAS running. CAS Integration with Vault in CAS is handled using Spring Cloud Vault and can be done in a number of ways: If you have the Spring Cloud Config Server deployed, Vault could be one of its many sources for settings and properties. In this scenario, you will just need to make sure the CAS server can talk to the Spring Cloud Config Server correctly, and the Config Server is then in charge of communicating with Vault to fetch settings, etc. Alternatively, you may decide to connect your CAS server directly to Vault and fetch settings. This is the approach we are going to try in this tutorial for a quick win, but do note that the strategy is almost the same if we were to use the Cloud Config server. So in order to enable a CAS integration with Vault directly, you want to start with the CAS Overlay, clone the project and then put the following settings into a src/main/resources/bootstrap.properties file: spring.application.name=cas spring.profiles.active=vault spring.cloud.vault.host=localhost spring.cloud.vault.port=8200 spring.cloud.vault.token=CAS spring.cloud.vault.enabled=true spring.cloud.vault.reactive.enabled=false spring.cloud.vault.fail-fast=true spring.cloud.vault.scheme=http spring.cloud.vault.kv.enabled=true spring.cloud.vault.kv.backend=secret We are teaching CAS to find our Vault server at http://localhost:8200 and use the generated token CAS for authenticated requests. AuthenticationBesides a token, there are many other ways to ensure requests to Vault are authenticated such AppIds, roles, AWS-EC2, etc. See Spring Cloud Vault for more info. We have also enabled the versioned Key-Value secret backend. The key-value backend allows storage of arbitrary values as key-value store. A single context can store one or many key-value tuples. Contexts can be organized hierarchically. Per our previous work in Vault, the backend is called secret. Note that there are many other types of backends supported. See Spring Cloud Vault for more info. Of course, don’t forget to include the required module in your CAS build: compile \"org.apereo.cas:cas-server-support-configuration-cloud-vault:${project.'cas.version'}\" Build and deploy. At this point, you should be able to log into CAS using casuser and Vault as the credentials! Refresh &amp; Reload If a secret changes, Vault has no way to broadcast the updated value(s) to its own clients, such as the CAS server itself. Therefore, in order to broadcast such change events CAS presents various endpoints that allow the user to refresh the configuration as needed. This means that an adopter would simply change a required CAS setting and then would submit a request to CAS to refresh its current state. At runtime! All CAS internal components that are affected by the external change are quietly reloaded and the setting takes immediate effect, completely removing the need for container restarts or CAS re-deployments. For example, start by changing the value of cas.authn.accept.users in Vault to something like casuser::HelloWorld. Then, execute the following command to refresh the CAS application context: curl -k -u casuser:Mellon https://sso.example.org/cas/actuator/refresh -d {} -H \"Content-Type: application/json\" ... [\"cas.authn.accept.users\"] At this point, you should be able to log into CAS using casuser and HelloWorld as the credentials! Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/10/30/cas6-configuration-vault/"
  },

  
  
  
  {
    "title": "CAS 6.0.0 RC3 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.3.0 GA was released on June 29th, 2018. Since then, the project has been moving forward with development of the next feature release that is tagged as 6.0.0. Note that this is a major release of the CAS software which may present significant changes in architecture, configuration or behavior. Please review the release policy to learn more about the scope of the release. This post intends to highlight some of the improvements and enhancements packed into the third release candidate in the 6.0.0 series. You can read about the previous release candidate here. Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. Note that CAS releases are strictly time-based releases; they are not scheduled or based on specific benchmarks, statistics or completion of features. To gain confidence in a particular release, it is strongly recommended that you start early by experimenting with release candidates and/or follow-up snapshots. In order to start experimenting with release candidates, at any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Overlay In the gradle.properties of the overlay, adjust the following setting: casVersion=6.0.0-RC3 Changes New &amp; Noteworthy JDK 11 CouchDb Support SAML2 IdP Single Logout Delegated AuthN via HiOrg-Server SAML2 Encryptable Attributes Multifactor Authentication &amp; Duo Security RADIUS Multifactor Authentication Spring Boot Administration Server SAML2 IdP Metadata via Amazon S3 Smaller Stuff Library Upgrades Resources Get Involved Credits New &amp; Noteworthy JDK 11 Starting with this version and continuing the effort from previous releases, CAS requires and builds against JDK 11. Travis CI has switched over to use OpenJDK 11 to build and publish CAS server SNAPSHOT releases, and the entire distribution has also been tested using Oracle JDK 11. Important changes in Oracle JDK 11 LicenseWith JDK 11 Oracle has updated the license terms on which Oracle JDK is offered. The new Oracle Technology Network License Agreement for Oracle Java SE is substantially different from the licenses under which previous versions of the JDK were offered. Please review the new terms carefully before downloading and using this product. Oracle also offers this software under the GPL License on jdk.java.net/11. The key part of the license is as follows: You may not: use the Programs for any data processing or any commercial, production, or internal business purposes other than developing, testing, prototyping, and demonstrating your Application. So, do NOT download or use the Oracle JDK unless you intend to pay for it. Use an OpenJDK build instead. CouchDb Support Extensive CouchDb support is now provided by CAS to handle storage concerns when it comes to ticketing, authentication, audit and throttling, multifactor authentication, and more. SAML2 IdP Single Logout Basic functionality is now included to have CAS submit SAML2 logout requests to SAML2 service providers, who currently have a registered a session with CAS. This will continue to be a work-in-progress item, to be improved and finalized prior to the final GA release. Delegated AuthN via HiOrg-Server Delegated authentication is now able to support HiOrg-Server. SAML2 Encryptable Attributes Configuration for SAML2 registered services can now specify attributes that should be optionally included in or excluded from encryption in the final SAML2 response. Multifactor Authentication &amp; Duo Security Significant changes in the multifactor authentication API and modules are incorporated in this release to better handle failure modes across all providers. The integration with Duo Security is also greatly improved internally to reduce API noise when it comes to registering multiple Duo configurations with CAS. RADIUS Multifactor Authentication RADIUS authentication is now able to honor the AccessChallenge response from the radius server, and properly prompt for multifactor authentication. This capability was best tested against CensorNet’s RADIUS server functionality. Spring Boot Administration Server The CAS integration with the Spring Boot Administration Server is now brought up to speed to be compatible with the latest Spring Boot release. SAML2 IdP Metadata via Amazon S3 Metadata artifacts that belong to CAS as a SAML2 identity provider may also be managed and stored via Amazon S3 buckets. Smaller Stuff Additional settings to support fallback principal attributes when dealing with X.509 principal resolution. Delegated authentication is improved to execute the authentication step only once. SAML2 delegated authentication is now capable of virtually renaming SAML2 attributes. Service access strategy for SAML2 service providers and other service types can now handle the unauthorizedRedirectUrl setting. Radius authentication now attempts to also submit the client IP address to the radius server. Small fixes to the SAML2 callback url pattern construction. New attribute renderer components are introduced to enhance the CAS v1 validation response, if needed. CAS internal Gradle build should continue to work against IDEA 2018.3 EAP. SAML2 responses can optionally include a NameID for SubjectConfirmation blocks, on a per-service basis. SAML2 responses can populate the Destination field. The background job responsible for cleaning trusted expired MFA records is now scheduled correctly on startup. Attribute resolution via external groovy scripts, handled by PersonDirectory, can now properly recognize the engine name. Hazelcast health monitoring imports its reporting of memory statistics. Registration of PrincipalResolver and AuditPrincipalIdProvider is now refactored to use *Configurer type of strategies as callbacks. Loading CAS configuration files is modified to better match Spring Boot behavior. Performance improvements to HTTP calls and caching of responses. Small number of dependency fixes that deal with auto configuration of Spring Cloud Config, Spring Cloud Config Bus and Spring Cloud Config Watch. Detection of the SAML2 SLO url location in metadata is now changed to locate the right binding (See SAML2 SLO support above). A new setting is now introduced to force CAS to restrict the authentication handler selection via source attached to the credential and provided via the login form. A new authentication policy is now included to force all authentication handlers to validate the given credential. The default RADIUS authentication strategy is switched to use the send-and-receive asynchronous model in anticipation of AccessChallenge RADIUS server responses. Library Upgrades Spring Spring Boot Spring Boot Admin Hazelcast OpenSAML Jackson Mockito Spotbugs Person Directory Pac4j Spring Data Spring Cloud Amazon SDK Micrometer UnboundID Twilio Nexmo Spring Security Google Maps Apache Groovy Resources Documentation Release Schedule Release Policy Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Credits Big thanks to all who participate in the development of this release to submit patches and contribute improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2018/10/26/600rc3-release/"
  },

  
  
  
  {
    "title": "Why you should choose CAS as your SSO system",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Most of the customers for whom I work have already chosen the CAS server and its ecosystem when I come in to help them. Yet, from time to time, I’m contacted earlier in the decision process when the client is still thinking about the products and protocols he wants to use. Advocating for the CAS server is an easy task for me, even if generally, technical reasons are just a small part of the game (politics and relationships really matter). I especially want to disabuse people who believe that CAS software is just about the CAS protocol, it’s so much more. Some may think that as a CAS committer and as an IAM freelance, I’m biased towards CAS. This is true, but certainly less than any salesman who will earn fees for each sold product. Eventually, this is what I say: 1) CAS is Open Source Most customers primarily choose Open Source software because it’s free. While this is a good reason, they still need to pay consultants to help them. To me, there are greater benefits, especially the fact that you can contribute to the project. If you buy an SSO system from a big company, want a new feature and are the only one in the world, it’s too bad for you, there is little chance you will get your new feature. With Open Source software, you can make it happen! 2) CAS is a very modern software While the general code quality of the CAS server has always been good, I must admit that the whole architecture and design have strongly improved since version 5 where it has embraced the Spring Boot ecosystem. I was a bit reluctant on this huge change, but Misagh was definitely right as using Spring Boot was a big jump forward. There are some glitches here and there, but overall, the code is easy to read and understand and things are really modular. 3) CAS has many features The CAS server offers many useful capabilities, from obvious ones to more advanced ones. It handles various authentication methods, multi-factor authentication (MFA), can remember the user, force or try authentication, offers a dashboard and monitoring, has logs and audits, manages passwords, etc. Of course, you cannot only assess a software by the number of its features but having many options is generally a good thing. 4) CAS is very popular The CAS server is one of the most popular software in IAM. With around five thousands stars on github.com, CAS is a well-known project. Many higher-education schools and companies use it, so you can easily find help from the CAS community or paid consultants. The more the CAS server is installed, the more people read its source code and test it, the more security vulnerabilities are discovered and fixed. It makes it a safe choice for your SSO system. 5) CAS fits everywhere Your existing environment is the first most important criteria when choosing an SSO system. Most companies never start a new project from scratch: for example, they use Redis on CentOS, a bit of MongoDB also and their users’ storage is an old LDAP system. You must cope with all that constraints. If your software only supports technologies A and B, you can only address clients willing to use A or B. The CAS server can: use many authentication methods: LDAP, databases, X509, Cassandra, Radius, Spnego, JWT, AWS Cloud Directory and many more handle many storage systems: Memcached, Redis, Oracle, Hazelcast, CouchDB, Couchbase, etc. 6) CAS is the master of interoperability Your existing environment is also the second most important criteria when choosing an SSO system! Big bang projects almost always fail and it’s hard to deal with legacy. I don’t remember having a customer without an existing software to integrate with. And this is the great strength of CAS: the CAS server can act as a SAML IdP, an OAuth provider, an OpenID Connect provder or as a CAS server of course but it can also play the role of a client delegating the authentication to another CAS server, to a SAML IdP, to Facebook, Google, Twitter and many other identity providers. This is one of the main contributions I brought to CAS and I’m especially proud of this interoperability. CAS clients used for integration in web applications exist in many technologies as well: Java, PHP, .Net, Ruby, Python, Node.js, Apache module, etc. CAS is a great software, it is worth considering if you plan to choose an SSO system. Jérôme LELEU Originally posted on the pac4j blog",
    "tags": "Blog CAS",
    "url": "/2018/10/25/why-you-should-choose-cas-as-your-sso-system/"
  },

  
  
  
  {
    "title": "Apereo CAS - Integration with Spring Cloud Config Server",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. As your CAS deployment moves through the deployment pipeline from dev to test to production, you can manage the configuration between those environments and be certain that applications have everything they need to run when they migrate through the use of an external configuration server provided by the Spring Cloud project. While most CAS deployments tend to fall into the simpler category of managing CAS configuration directly alongside the CAS server deployment, this tutorial focuses on allowing CAS to work with the Spring Cloud Config server for distributed configuration management. The Spring Cloud Config server is an external and central configuration server to keep state and settings for all sorts of applications, CAS included. It provides an abstract way for CAS (and all of its other clients) to obtain settings from a variety of sources such as file system, git or svn repositories, MongoDb databases, Vault, etc. The beauty of this solution is that to the CAS web application server, (or the clients of the Spring Cloud Config server in general), it matters not where settings come from since CAS has no knowledge of the underlying property sources. It simply talks to the configuration server to locate settings and move on. In this walkthrough, we will focus on the following tasks: Spring Cloud Config Server deployment Property source configuration Endpoint and operational security Managing sensitive settings via encryption Distributed real-time updates to settings CAS server integration with the Config server Our starting position is based on the following: CAS 6.0.0-RC3 Java 11 CAS Overlay (The master branch specifically) CAS Spring Cloud Config server overlay CLI JSON Processor jq Spring Cloud Config Server Configuration Overlay Basics The Spring Cloud Config server runs a standalone Spring Boot application on its own with a setup that is very similar to the CAS server itself. There is a WAR overlay that can be used to configure and deploy the server. By default, the application runs on port 8888 and is available at /casconfigserver and does require SSL with a keystore that is expected at file:/etc/cas/thekeystore. The default settings should match the following: server.port=8444 server.ssl.key-store=file:/etc/cas/thekeystore server.ssl.key-store-password=changeit server.ssl.key-password=changeit Security In order to secure the Config server, we can create a src/main/resources/application-security.properties to contain the following settings: spring.security.user.name=casuser spring.security.user.password=Mellon management.endpoints.web.base-path=/actuator management.endpoints.env.enabled=true management.endpoints.web.exposure.include=env Run We should also modify the build.sh file to auto-activate the security profile to allow our security-related settings to be loaded: function run() { package &amp;&amp; java -jar -Dspring.profiles.include=security build/libs/casconfigserver.war } Once you’re ready, execute the following: ./build.sh run …at which point a successful startup attempt would demonstrate the following in the logs: &lt;The following profiles are active: security,native&gt; ... &lt;Starting Servlet Engine: Apache Tomcat/9.0.12&gt; ... &lt;Starting ProtocolHandler [\"https-jsse-nio-8888\"]&gt; ... &lt;Started CasConfigurationServerWebApplication in 14.823 seconds (JVM running for 16.248)&gt; …and the server should be available at https://admin.example.org:8888/casconfigserver. Configuration Sources The Spring Cloud Config server by default runs under a native profile, which basically allows it to locate properties and settings under the /etc/cas/config folder, which is very similar to the default CAS server setup. We are going to take this one step further and allow it to also load settings from a git repository. To do this, we need a src/main/resources/bootstrap.properties file with the following: spring.application.name=casconfigserver spring.profiles.active=native,default,security spring.cloud.config.server.native.searchLocations=file:///etc/cas/config spring.cloud.config.server.git.uri=file://path/to/config-server-repo # spring.cloud.config.server.bootstrap=true Not only the Config server is loading properties from embedded resources on the classpath, but it is also configured to look at /etc/cas/config as well as our Git repository at config-server-repo which is expected to contain properties and settings. As an example, we can create and initialize the config-server-repo directory as a Git repository and then add and commit the following files to it: application.yml Global settings regardless of the application: info: description: Spring Cloud Config Server cas.properties Global settings for the cas application: server.port=8555 cas-dev.properties Settings for the cas application under the dev profile: cas.authn.accept.users=casuser::Devel cas-qa.properties: Settings for the cas application under the qa profile: cas.authn.accept.users=casuser::QA Build and run as usual. Query Configuration Now that the Config server is connected to a number of property sources with a number of files organized in fancy ways, we can query the server and ask for application settings. For example, ask the server to get all the configuration settings for cas under the qa profile: curl -k -u casuser:Mellon https://config.example.org:8888/casconfigserver/cas/qa | jq …or the dev profile: curl -k -u casuser:Mellon https://config.example.org:8888/casconfigserver/cas/dev | jq Notice how in each scenario, global settings, and common application settings and then profile-specific settings are returned back to you. As the caller, you don’t know where the settings come from or how they are controlled and by whom. All you need to know is: Get me the right set of settings for my app at this profile. Let’s make a change. Navigate to the cas-qa.properties file and add the following, then commit the change to the repository: cas.authn.accept.users=casuser::QASomething …and the call the Config server again: curl -k -u casuser:Mellon https://config.example.org:8888/casconfigserver/cas/qa | jq Notice how your change was picked up automatically. As a bonus exercise, push your git repository to a cloud provider such as Github or Bitbucket and modify the Config server with the URL of the new Git repository. Then make a change using the Github/BitBucket online editor to one of the settings and observe how the Config server recognizes changes automatically. Very cool! Sensitive Configuration So far, we have been embedding values directly in configuration files. Let’s try to make our setup a bit more secure by encrypting values before they are added to our repository. In the bootstrap.properties file add the following settings: encrypt.key-store.location=file:///etc/cas/casconfigserver.jks encrypt.key-store.password=changeit encrypt.key-store.alias=cas encrypt.key-store.secret=changeit You will, of course, need to create the above keystore using keytool: keytool -genkeypair -alias cas -keyalg RSA \\ -dname \"CN=CAS,OU=Unit,O=Organization,L=City,S=State,C=US\" \\ -keypass changeit -keystore /etc/cas/casconfigserver.jks -storepass changeit The keystore above is what controls the semantics of encryption/decryption of settings. The encryption is done with the public key, and a private key is needed for decryption. As a test, I am going to ask the Config server to encrypt the text casuser::QASomething for me: curl -k -u casuser:Mellon https://config.example.org:8888/casconfigserver/encrypt -d casuser::QASomething If you take the encrypted value and simply try to decrypt it you should see the original: curl -k -u casuser:Mellon https://config.example.org:8888/casconfigserver/encrypt -d $ENCRYPTED_VALUE Once the value is encrypted, it can be put back into the cas-qa.properties configuration file: cas.authn.accept.users={cipher}$ENCRYPTED_VALUE If you ask the Config server for the qa profile of the cas application, you should see the decrypted value in the results: curl -k -u casuser:Mellon https://config.example.org:8888/casconfigserver/cas/qa | jq That’s it for now. Let’s move onto the CAS server configuration and let it fetch settings from the Config server. CAS Server Configuration The task at hand is to describe the Spring Cloud Config server to the CAS server so it can begin to configure itself via provided settings. To do so, you want to start with the CAS Overlay, clone the project and then put the following settings into a src/main/resources/bootstrap.properties file: spring.application.name=cas spring.profiles.active=default spring.cloud.config.uri=https://casuser:Mellon@config.example.org.unicon.net:8888/casconfigserver spring.cloud.config.profile=qa spring.cloud.config.label=master spring.cloud.config.enabled=true spring.cloud.config.watch.enabled=true spring.cloud.config.watch.initialDelay=30000 spring.cloud.config.watch.delay=1000 spring.cloud.config.fail-fast=true health.config.enabled=true In summary, we have the Spring Cloud config enabled with a location to the Config server. Next, we teach CAS to activate the qa profile when it asks for configuration settings, and we switch the CAS server application profile to default to disable the standalone strategy of locating settings. As for the other settings, hold onto them right now and we’ll review them in just a bit. The label setting is useful for rolling back to previous versions of configuration; with the default Config Server implementation it can be a git label, branch name or commit id. A label can also be provided as a comma-separated list, in which case the items in the list are tried one-by-one until one succeeds. This can be useful when working on a feature branch, for instance, when you might want to align the config label with your branch, but make it optional. So at this point, our expectation is that CAS will load its own application.properties file by default which has a bunch of settings that for instance deal with SSL, keystores, ports, etc. Then we expect CAS to load any and all settings from the Spring Cloud config server that are associated with cas and qa where these settings should override anything that CAS by default handles and provides. This means that when it’s all said and done, our CAS server should be running on port 8555 (as opposed to the default 8443) and the static credentials used to authenticate users should include the username/password casuser and QASomething (as opposed to the default casuser and Mellon). Right? If you have followed the story so far, crank up the your CAS server deployment and examine the above scenario. Works as advertised, doesn’t it?! Refresh &amp; Reload The CAS spring cloud configuration server is constantly monitoring changes to the underlying property sources automatically but has no way to broadcast those changes to its own clients, such as the CAS server itself. Therefore, in order to broadcast such change events, CAS presents various endpoints that allow the user to refresh the configuration as needed. This means that an adopter would simply change a required CAS setting and then would submit a request to CAS to refresh its current state. At runtime! All CAS internal components that are affected by the external change are quietly reloaded and the setting takes immediate effect, completely removing the need for container restarts or CAS re-deployments. In order to handle automatic updates to CAS settings from the Spring Cloud Config server, we can try the following: First, we are going to switch the CAS server to activate the dev profile (instead of the current qa) when querying for settings in the bootstrap.properties file: spring.cloud.config.profile=dev Then, we are going to modify and commit the cas-dev.properties file of the Spring Cloud Config server in our Git repository to enable CAS actuator endpoints by default which will allow us to invoke the actuator/refresh endpoint provided by Spring Boot: management.endpoints.web.exposure.include=* management.endpoints.enabled-by-default=true cas.monitor.endpoints.endpoint.defaults.access=AUTHENTICATED spring.security.user.name=casuser spring.security.user.password=Mellon WATCH OUT!The above collection of settings MUST only be used for demo purposes and serve as an EXAMPLE. It is not wise to enable and expose all actuator endpoints to the web and certainly, the security of the exposed endpoints should be taken into account very seriously. None of the CAS or Spring Boot actuator endpoints are enabled by default. For production, you should carefully choose which endpoints to expose. Once the changes are committed, we can switch back to the CAS server and re-run it one more time for it to pick up the dev profile settings and give us access to the relevant endpoints. When the CAS server is up, try invoking the refresh endpoint of the CAS server: curl -k -u casuser:Mellon https://sso.example.org:8555/cas/actuator/refresh -d {} -H \"Content-Type: application/json\" Watch the CAS server logs where you see something like: INFO [...CasConfigurationEventListener] - &lt;Refreshing CAS configuration. Stand by...&gt; Let’s change something then. Switch over to the cas-dev.properties file of the Spring Cloud Config server and change and commit the following setting: cas.authn.accept.users=casuser::Developers Once the change is committed, invoke the refresh endpoint again just as before and observe the output: [\"config.client.version\",\"cas.authn.accept.users\"] At this point, we should be able to pull up the CAS server in the browser and log in using casuser and Developers as credentials. Right? Give it a shot. Works as advertised, doesn’t it?! RememberCAS components that qualify for the refresh operations need to have been marked with a special Java annotation that is @RefreshScope. If you find that the refresh operation does not actually do its job, chances are the components that are affected and controlled by the setting are not marked that way. A pull request should fix that right up! This is very handy. You can make a change to a given application and profile in a centralized configuration server and simply invoke the client, that is the CAS server to refresh itself. Imagine the possibilities with distributed development and configuration management! What About… There a few things that we have yet to address that would be outside the scope of this document. Here they are: Spring Cloud Config Bus If we have more than one CAS server we need to invoke the refresh endpoint for each and every single server node for it to refresh itself and pick up changes. To solve this problem, we can use Spring Cloud Bus. The bus acts as the communication channel across all CAS server nodes and can be backed via RabbitMQ, Kafka, Redis, etc. Each CAS server will be connected to the bus and gains a special endpoint called bus-refresh. Calling this endpoint will cause the receiving node to: Get the latest configuration from the config server and update its configuration annotated by @RefreshScope Send a message to the bus informing about refresh event All subscribed CAS nodes will update their configuration as well Spring Cloud Config Monitor How does the Spring Cloud Config server detect changes from property sources? Could we make that process automatic, and have it broadcast a notification to CAS server nodes? This is where the Spring Cloud Config Monitor comes in handy. Similar to the above, the Config server can take advantage of this monitor that may be backed by a bus via AMQP. As changes are detected, they are broadcasted via events on the bus for the receiving CAS nodes to recognize and update themselves automatically, without manual refresh invocations. Final Thoughts So, as you can observe there is quite a lot involved here to make for a cloud-ready distributed configuration management system. For many CAS deployments, this might seem overkill as most simply just rely on a standalone type of deployment where there is only a couple of CAS server nodes each feeding off of a simple cas.properties file adjacent to the node itself. It is true that the setting up CAS in the cloud using the described strategies in this post can take quite a bit of time and expertise. Thus, evaluate options carefully before jumping into coolness. If you have a strategic vision of managing configuration in distributed cloud-ready fashion, this is a good long-term investment. If you are thinking about centralizing application configuration across your entire institution and manage the configuration in a distributed and real-time fashion, it’s worth it to go through the setup. If you have use cases that require configuration changes in real-time without downtime and restarts in a distributed environment, it makes sense to explore such options. Otherwise, you may find the pain and the cons outweigh the pros. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/10/25/cas6-cloud-config-server/"
  },

  
  
  
  {
    "title": "Apereo CAS - Spring Boot Admin Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Spring Boot Admin is a community project to manage and monitor Spring Boot applications such as Apereo CAS. The admin server presents an AngularJS-based UI that interacts with the actuator endpoints provided by Spring Boot in CAS. One CAS has registered itself with the admin server, either using the Spring Admin Client via HTTP or as part of discovery using technologies such as Eureka, Consul, etc, the admin server can begin to provide feature to monitor CAS for health status, JVM &amp; memory metrics, environment settings, thread dumps, audit data, logs, etc. While the CAS integration with the Spring Boot Admin server has been available for some time (likely since CAS 5.1.x), in this tutorial we will focus on how to get the latest version of Apereo CAS integrated with the Admin server. At a high-level, we need to accomplish the following: Deploy and configure the Spring Boot Admin server Configure CAS to register with the Spring Boot Admin server Our starting position is based on the following: CAS 6.0.0-RC3 Java 11 CAS Overlay (The master branch specifically) Spring Boot Admin overlay CLI JSON Processor jq Spring Boot Admin Server Configuration The Spring Boot Admin server runs a standalone Spring Boot application on its own with a setup that is very similar to the CAS server itself. There is a WAR overlay that can be used to configure and deploy the server. Once you clone the Admin overlay project, you may need to create a src/main/resources/application.properties to control the behavior of the Admin server. By default, the application runs on port 8444 and does require SSL with a keystore that is expected at file:/etc/cas/thekeystore. The default settings should match the following: server.port=8444 server.ssl.key-store=file:/etc/cas/thekeystore server.ssl.key-store-password=changeit server.ssl.key-password=changeit # Protect the boot-admin endpoints for basic/form authn spring.security.user.name=casuser spring.security.user.password=e3f98098-edb5-4217-9dcb-ad04999a8794 Given the Admin server itself is based on top of Spring Boot, all relevant Spring Boot settings here do also apply to control the general behavior of the web application. There are also many other settings available to tweak the behavior of the Admin server functionality itself. For a more comprehensive list, please see the Spring Boot Admin documentation. Once you’re ready, execute the following: ./build.sh run …at which point a successful startup attempt would demonstrate the following in the logs: INFO [org.apereo.cas.CasSpringBootAdminServerWebApplication] - &lt;No active profile set, falling back to default profiles: default&gt; ... INFO [org.springframework.boot.web.embedded.tomcat.TomcatWebServer] - &lt;Tomcat started on port(s): 8444 (https) with context path ''&gt; ... INFO [org.apereo.cas.CasSpringBootAdminServerWebApplication] - &lt;Started CasSpringBootAdminServerWebApplication in 20.798 …which allows you to navigate to Admin server in your browser at https://admin.example.org:8444: There is nothing registered with the Admin server yet. As the next step, we will connect our CAS server to the Admin server. CAS Server Configuration Each individual CAS server is given the ability to auto-register itself with the Admin server. This is done using the following module that should go into the CAS overlay: compile \"org.apereo.cas:cas-server-support-bootadmin-client:${project.'cas.version'}\" Of course, we need to teach CAS about our Admin server using the cas.properties file: spring.boot.admin.client.enabled=true spring.boot.admin.client.url=https://admin.example.org:8444 spring.boot.admin.client.instance.management-base-url=https://sso.example.org/cas So, our CAS server is running on https://sso.example.org/cas which presents a number of actuator endpoints that are used by the Admin server to monitor status and report results. Therefore, we will need to enable the endpoints in CAS in cas.properties so they may be consumable by the Admin server: management.endpoints.enabled-by-default=true management.endpoints.web.exposure.include=* spring.security.user.name=casuser spring.security.user.password=Mellon cas.monitor.endpoints.endpoint.defaults.access=AUTHENTICATED These settings are primarily offered and controlled by Spring Boot and accomplish the following: Enable all actuator endpoints by default. Expose all actuator endpoints over the web via http. Secure all actuator endpoints using basic authentication where the master credentials are casuser and Mellon. WATCH OUT!The above collection of settings MUST only be used for demo purposes and serve as an EXAMPLE. It is not wise to enable and expose all actuator endpoints to the web and certainly, the security of the exposed endpoints should be taken into account very seriously. None of the CAS or Spring Boot actuator endpoints are enabled by default. For production you should carefully choose which endpoints to expose. To verify, you can try to hit a few of the endpoints to see the behavior in action: curl -u casuser:Mellon -k https://sso.example.org/cas/actuator/status | jq …where you get back: { \"status\": 200, \"description\": \"OK\", \"health\": \"UP\", \"host\": \"misaghmoayyed\", \"server\": \"https://sso.example.org/cas\", \"version\": \"6.0.0-RC3 - ...\" } You can also try hitting actuator/health, actuator/info and many others. Now that are endpoints are enabled and secured, we need to configure CAS to use our security credentials when contacting the Admin server as well: spring.boot.admin.client.instance.metadata.user.name=casuser spring.boot.admin.client.instance.metadata.user.password=Mellon # In case Spring Boot Admin endpoints are protected via basic authn spring.boot.admin.client.username=casuser spring.boot.admin.client.password=e3f98098-edb5-4217-9dcb-ad04999a8794 WATCH OUT!While the actuator endpoints in CAS are protected in some fashion, the endpoints of the Spring Boot Admin server that are responsible for handling registration requests and more are not by default protected using the existing overlay. This is an item that will likely get worked out before the final CAS release.&lt;/a&gt;. When you build and deploy CAS next, the Admin server should properly recognize the registration request and display something like this: …where you can drill into the app and look at various screens and monitoring activity. For example, check out the available http web mappings and URLs: …or logging configuration: There is a lot more you can do with the Admin server to add security, custom notifications, etc. Please see the Spring Boot Admin documentation. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/10/22/cas6-springboot-admin-server/"
  },

  
  
  
  {
    "title": "Apereo CAS - Fun with HashiCorp Consul",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Consul is a distributed, highly-available, and multi-datacenter aware tool for service discovery, configuration, and orchestration. Consul enables rapid deployment, configuration, and maintenance of service-oriented architectures at a massive scale. For more information, please see the consul documentation. The CAS integration with Consul has been available for some time and comes in multiple flavors. First, the server can use Consul for service discovery which is one of the key tenets of a cloud-based HA architecture. As Josh Long puts it: A service registry is a phone book for your microservices. Each service registers itself with the service registry and tells the registry where it lives (host, port, node name) and perhaps other service-specific metadata - things that other services can use to make informed decisions about it. In our case, we could have each CAS server instance in a cluster register itself with the discovery server automatically, (i.e. the CAS server is a client of the discovery server), and then have individual discovery-aware CAS clients query the discovery server to figure out the availability and location of each CAS server node. Throw in a software load-balancer like Netflix Ribbon and things begin to get interesting. Netflix EurekaA similiar integration with Netflix Eureka Server is also available and supported by CAS. The other available CAS integration with Consul deals with managing distributed configuration using the Consul Key/Value store. Consul provides a Key/Value Store for storing configuration and other metadata. CAS takes advantage of the Spring Cloud Consul Config integration library to fetch such configuration and metadata as an alternative to the Config Server and Client. To learn more about the Consul Key/Value store, please see this page. In this tutorial, we will focus on a simple walkthrough of how to integrate Consul with CAS for both service discovery and configuration management. Our starting position is based on the following: CAS 6.0.0-RC3 Java 11 CAS Overlay (The master branch specifically) CLI JSON Processor jq Docker Consul Configuration To configure a simple Consul server, we can use the available Docker image which is perfectly good for demos and testing. Use the following command to run the Consul server: docker run --name=consul -p8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul By default, Consul allows connections to these ports only from the loopback interface (127.0.0.1). When you run the Consul agent, it listens on 6 ports all of which serve different functions. The three ports essential to our discussion are: HTTP API (default port: 8500): handles HTTP API requests from clients CLI RPC (default port: 8400): handles requests from CLI DNS (default port: 8600): answers DNS queries Our Docker command runs a completely in-memory Consul server agent with default bridge networking and no services exposed on the host, which is useful for development but SHOULD NOT be used in production. Once you have the server running, you can point your browser to http://localhost:8500/ui where you will see something like this: There is nothing registered with the server yet. As the next step, we will connect the CAS server to Consul. CAS Server Configuration Service Discovery Registration Each individual CAS server is given the ability to auto-register itself with the Consul server. This is done using the following module that should go into the CAS overlay: compile \"org.apereo.cas:cas-server-support-consul-client:${project.'cas.version'}\" Of course, we need to teach CAS about our Consul server using the cas.properties file: spring.cloud.consul.port=8500 spring.cloud.consul.enabled=true spring.cloud.consul.host=localhost spring.cloud.consul.discovery.heartbeat.enabled=true spring.cloud.consul.discovery.heartbeat.ttlValue=60 spring.cloud.consul.discovery.heartbeat.ttlUnit=s These settings are primarily offered and controlled by Spring Cloud that teaches CAS the location of the Consul server and how it may register itself with that server as a Consul client. When you build and deploy CAS next, the Consul server should properly recognize the registration request and display something like this: …where you can drill into the cas service and look at various screens: As extra proof, CAS logs would indicate the following too: INFO [ConsulServiceRegistry] - &lt;Registering service with consul: NewService{id='cas-8443', name='cas'... Discovery So far, we have only been reviewing the service registration aspect. As the next step, you would want to build and configure clients that are able to contact the discovery server, asking about available CAS instances. Spring Cloud makes this rather easy. As an example your Java client would look something like this: @EnableDiscoveryClient @SpringBootApplication public class SampleClientApplication { public static void main(String[] args) { SpringApplication.run(SampleClientApplication.class, args); } } @RestController class ServiceInstanceRestController { @Autowired private DiscoveryClient discoveryClient; @RequestMapping(\"/service-instances/{applicationName}\") public List&lt;ServiceInstance&gt; serviceInstances( @PathVariable String applicationName) { return discoveryClient.getInstances(applicationName); } } …where you’d have: spring.application.name=cas With the above code snippet, our sample CAS client defines a Spring MVC REST endpoint that returns an enumeration of all the ServiceInstance instances registered in the Consul registry. From then on, the client may proceed deal with each ServiceInstance that would be refreshed automatically as CAS servers come and go in the discovery server. Configuration Management Consul provides a Key/Value Store for storing configuration and other metadata. Configuration is loaded into the CAS environment during the special bootstrap phase at runtime. Configuration is stored in the /config folder by default. Multiple PropertySource instances are created based on the application’s name and the active profiles that mimic the Spring Cloud Config order of resolving properties. For example, an application with the name cas and with the dev profile will have the following property sources created: config/cas,dev/ config/cas/ config/application,dev/ config/application/ The most specific property source is at the top, with the least specific at the bottom. Properties in the config/application folder are applicable to all applications using consul for configuration. Properties in the config/cas/ folder are only available to the instances of the service named cas. ConfigurationThere is no other extra step required in CAS to make distributed configuration management work with Consul. If you have the discovery piece working, you will be able to automatically take advantage of the Key/Value store. So let’s create config/cas/ folder in Consul and add a sample property cas.authn.accept.users which controls static authentication in CAS with a list of hardcoded credentials: Once you save the setting, CAS logs should indicate the application context refreshing to recognize the change: INFO [RefreshEventListener] - &lt;Refresh keys changed: [cas.authn.accept.users]&gt; After the change is picked up, you should be able to log into CAS using casuser and Misagh as the credentials! Just as well, we can delete the setting from Consul, let CAS pick up the change and we should be able to fall back onto the default credentials for static authentication which are casuser and Mellon. How is this possible? There is a thing called Consul Config Watch which in CAS takes advantage of the ability of consul to watch a key prefix. It makes a blocking Consul HTTP API call to determine if any relevant configuration data has changed for the current application. If there is new configuration data a Refresh Event is published and captured by CAS to refresh the status of the application context, as is demonstrated by the logs. Pretty cool! Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/10/22/cas6-consul-discovery/"
  },

  
  
  
  {
    "title": "Apereo CAS - Multifactor Authentication with RADIUS",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The ability to authenticate credentials using the RADIUS protocol and a compliant RADIUS server has been available in CAS for some time. In more recent CAS versions, this capability has been improved to support multifactor authentication scenarios by allowing CAS to recognize the Access-Challenge response type. This is a special signal sent by the RADIUS server requesting more information in order to allow access. The authentication flow is typically composed of the following steps: Primary authentication via RADIUS typically using username+password credentials. Capturing the Access-Challenge and the session State passed back from the RADIUS server. RADIUS server provides the end-user with a one-time code, typically via SMS, email or mobile app. Reroute the next step in the authentication flow, allowing the end-user to enter the code. Submit the code and the previous State to the RADIUS server. Validate the final response which should be an Access-Accept type, if all goes well. A patch was submitted to the CAS project a while back to handle this exact scenario. This brief tutorial incorporates this patch into the CAS software and outlines the necessary configuration steps required to deliver multifactor authentication via RADIUS as noted above. Our starting position is based on the following: CAS 5.3.6 Java 8 Maven Overlay (The 5.3 branch specifically) Configuration RADIUS Setup The setup is fairly simple, given CAS does all of the heavy-lifting. First, we need to prepare the CAS overlay with the right set of dependencies to enable RADIUS functionality: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-radius&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-radius-mfa&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; …and next, we need to teach CAS about our RADIUS setup: # Handle primary authentication via RADIUS (i.e. username+password) cas.authn.radius.server.protocol=MSCHAPv2 cas.authn.radius.client.sharedSecret=xyz cas.authn.radius.client.inetAddress=1.2.3.4 # Handle MFA via RADIUS (i.e. one-time code) cas.authn.mfa.radius.server.protocol=MSCHAPv2 cas.authn.mfa.radius.client.sharedSecret=xyz cas.authn.mfa.radius.client.inetAddress=1.2.3.4 # Signal webflow to handle MFA via RADIUS cas.authn.mfa.radius.id=mfa-radius cas.authn.mfa.radius.allowedAuthenticationAttempts=1 That should do it. When credentials are validated via RADIUS as part of primary authentication, the user is routed to the next screen to enter the code provided by the RADIUS server via SMS, etc. Once entered, CAS will submit the code as well as any previous session state back to the RADIUS server which would have it validate the request and produce a successful response that allows CAS to collect attributes and establish a single sign-on session. Note that we are also configuring CAS to limit the number of authentication attempts to 1, meaning after the first failed attempt at providing a valid token CAS would reject MFA and should route back to the login screen to restart the flow. Test RADIUS To test the basic tenants of this scenario using CAS APIs, the following code snippet may be used as an example: RadiusClientFactory factory = new RadiusClientFactory(1813, 1812, 2000, \"1.2.3.4\", \"xyz\"); JRadiusServerImpl server = new JRadiusServerImpl(RadiusProtocol.MSCHAPv2, factory); RadiusResponse response = server.authenticate(\"username\", \"password\", Optional.empty()); System.out.println(response); System.out.println(\"Enter code: \"); Scanner scanner = new Scanner(System.in); String code = scanner.nextLine(); Optional&lt;Serializable&gt; state = Optional.of(response.getAttributes() .stream() .filter(a -&gt; a.getAttributeName().equalsIgnoreCase(\"State\")) .findFirst() .get() .getValue() .getValueObject()); RadiusResponse mfaResponse = server.authenticate(\"username\", code, state); System.out.println(mfaResponse); LDAP Attributes Since RADIUS is used to handle primary authentication, we are going to try to switch to LDAP in order to fetch for user attributes. The following configuration should do the job: cas.authn.attributeRepository.ldap[0].attributes.uid=uid cas.authn.attributeRepository.ldap[0].attributes.displayName=displayName cas.authn.attributeRepository.ldap[0].attributes.cn=commonName cas.authn.attributeRepository.ldap[0].attributes.memberOf=memberOf cas.authn.attributeRepository.ldap[0].ldapUrl=ldap://... cas.authn.attributeRepository.ldap[0].useSsl=false cas.authn.attributeRepository.ldap[0].useStartTls=false cas.authn.attributeRepository.ldap[0].baseDn=dc=example,dc=edu cas.authn.attributeRepository.ldap[0].searchFilter=uid={0} cas.authn.attributeRepository.ldap[0].bindDn=... cas.authn.attributeRepository.ldap[0].bindCredential=... cas.personDirectory.principalAttribute=uid We are instructing CAS to build the final authenticated Principal identified by the uid attribute (instead of whatever the user types into the login form as the credential id). We have some settings for the LDAP attribute repository that describe the LDAP server, and of course we have a section of settings for attribute mapping where we fetch uid and virtually rename/remap it to uid or we fetch cn and remap it to commonName, etc. After the primary authentication event, the attribute repository kicks in to determine the needed attributes for the user by running the query uid={0} against the LDAP server where {0} is replaced with the authenticated user id (typically the credential id). Once the user entry is located, attributes are fetched and mapped and the authenticated Principal from the CAS perspective has an identifier determined by the uid attribute as well as at most four extra person attributes attached to it, which can then be used for attribute release. Credits Huge thanks to Jozef Kotlar, Bo Simonsen, Jesper Grøndahl and many others who contributed guidance, code, and working examples to see this feature to completion. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS MFA",
    "url": "/2018/10/18/cas5-radius-mfa-authn/"
  },

  
  
  
  {
    "title": "CAS Vulnerability Disclosure",
    "text": "Overview This is the public version of an Apereo CAS project vulnerability disclosure, describing an issue in CAS where an adversary may be able to bypass the second factor (token) although MFA is requested during the login process. This issue applies to all MFA providers except the Duo provider (which is therefore NOT vulnerable). Affected Deployments The attack vector applies to all deployments of the CAS server for the versions: 5.3.0, 5.3.1 and 5.3.2 lower or equal to 5.2.6. If you have deployed the version 5.3.0, 5.3.1 or 5.3.2, you MUST upgrade to the version 5.3.3. If you have deployed a version lower or equal to version 5.2.6, you MUST upgrade to the version 5.2.7. Severity This is a serious issue where successfully exercising this vulnerability allows the adversary to bypass the second factor (token) required by the MFA policy. This makes any MFA configuration to re-inforce security completely useless. Patching Patch releases are available to address CAS vulnerable deployments. Upgrades to the next patch version for each release should be a drop-in replacement. The patch simply ensures that the MFA factor (token) is effectively required when MFA is requested. Timeline The issue was originally reported to the CAS application security team on August, 2018 and upon confirmation, CAS was patched. Procedure Modify your CAS overlay to point to the version 5.2.7 or 5.3.3. A snippet of a pom.xml for a CAS overlay follows: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;cas.version&gt;5.3.3&lt;/cas.version&gt; &lt;/properties&gt; Support If you have questions on the details of this vulnerability and how it might be reproduced, please contact security@apereo.org or cas-appsec-public@apereo.org. Resources Original Announcement CAS Security Vulnerability Response Model Jérôme LELEU",
    "tags": "CAS",
    "url": "/2018/09/26/mfavulndisc/"
  },

  
  
  
  {
    "title": "CAS 6.0.0 RC2 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.3.0 GA was released on June 29th, 2018. Since then, the project has been moving forward with development of the next feature release that is tagged as 6.0.0. Note that this is a major release of the CAS software which may present significant changes in architecture, configuration or behavior. Please review the release policy to learn more about the scope of the release. This post intends to highlight some of the improvements and enhancements packed into the second release candidate in the 6.0.0 series. You can read about the previous release candidate here. Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. Note that CAS releases are strictly time-based releases; they are not scheduled or based on specific benchmarks, statistics or completion of features. To gain confidence in a particular release, it is strongly recommended that you start early by experimenting with release candidates and/or follow-up snapshots. In order to start experimenting with release candidates, at any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Overlay In the gradle.properties of the overlay, adjust the following setting: casVersion=6.0.0-RC2 Changes New &amp; Noteworthy JDK 10 WAR Overlay OAuth2 UMA Authentication Source Selection Forgot Username OAuth2 Token Management Hazelcast Discovery Strategies Small Stuff Library Upgrades Resources Get Involved Credits New &amp; Noteworthy JDK 10 Work continues to ensure CAS can support and build on top of JDK 11. At this time, a number of supporting libraries that handle code generation, test coverage and static analysis are not quite ready for JDK 11, and a few more foundational frameworks such as Spring and Spring Boot have yet to be upgraded to a release friendly to JDK 11. In this release, the JDK requirement continues to stay at 10 with the hopes that said core components would be ready for JDK 11 around the time of the next release candidate. Note that this release candidate builds on top of Spring framework 5.1 and Spring Boot 2.1. The upgrade should provide improvements for CAS startup time and be ready in anticipation of the upcoming JDK 11 release. WAR Overlay The Maven WAR overlay template is now deprecated and moved aside. The reference overlay project simply resides here and is transformed to use the Gradle build tool instead. This is done to reduce maintenance overhead and simplify the deployment strategy while allowing future attempts to make auto-generation of the overlay as comfortable as possible. OAuth2 UMA A first pass at OAuth2 User-Managed Access is now available. This is very much a rough take and will require some fine-tuning and tweaking in future iterations to fully make it spec-compliant and functional. Authentication Source Selection In the event that there is more than one (primary) authentication source defined, CAS is given the ability to present the user with a choice in the login screen to select the appropriate credential source before authenticating. This capability can also be automated using credential predicates if a pattern can formulated and linked to a specific authentication source. This variation here is the less-automated way of selecting an authentication source, taking into account user input directly. Forgot Username The Forgot your username? scenario is now supported by the CAS password management facility. OAuth2 Token Management Specific endpoints are provided as part of CAS monitoring toolkit to manage and revoke OAuth2 access and refresh tokens. Hazelcast Discovery Strategies CAS is now able to take advantage of Kubernetes for Hazelcast auto discovery of nodes. Support for discovery strategies based on Docker Swarm is also included and available. Small Stuff Expired registered service definitions are now blocked by CAS as always, but are not strictly modified in the service registry as disabled services. A ton of improvements to the Travis CI integration tests to ensure performance and compliance. This area continues to improve. Release of authentication-level attributes, typically those related to protocols or those captured by metadata populators is now controlled via a central policy. Generation of CAS configuration metadata is massaged to take into account enumerations and nested inner classes. Delegated authentication now attempts to check for SSO status before handing off the request to a provider. REST API authentication using X509 is now capable of TLS client authentication. Delegated authentication gains the ability to use path variables for client names instead of query parameters, for identity providers such as Azure. CAS documentation integrates with Angolia for its search capabilities. SAML2 support in CAS begins to support encrypted attributes as well as name ids. Minor bug fixes to database schema handling, log messages, MFA context validation, ticket serialization, and OATH validations. CAS OpenID Connect support gains a better handle on logout and session management. OAuth2 grant type selection is now enforced for relying parties, etc. Kryo for memcached continues to auto-register a few more components, specially with CAS has turned on MFA or delegated authentication. Session replication can now be done using a JDBC backend. Yaml Service Registry is able to recognize both .yml and .yaml files. Delegated authentication to SAML identity providers gains a few bug fixes when resolving SP or IdP metadata over URLs. The service provider metadata generated by CAS can now optionally be signed using metadata signing keys. Library Upgrades Inspektr Pac4j Spring Spring Boot Spring Security Spring Security RSA Spring Data Spring Session Spring Cloud Oshi ActiveMQ jClouds JavaParser Commons Lang Commons Configuration Amazon AWS Google Maps UnboundID LDAP Twilio Nexmo Gradle Nimbus Apache Tomcat Hibernate Resources Documentation Release Schedule Release Policy Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Credits Big thanks to all who participate in the development of this release to submit patches and contribute improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2018/09/14/600rc2-release/"
  },

  
  
  
  {
    "title": "Apereo CAS - dotCMS SAML2 Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Contributed ContentKeith Conger of Colorado College, an active member of the CAS community, was kind enough to contribute this guide. dotCMS is an open source content management system (CMS) written in Java for managing content and content-driven sites and applications. As a SAML2 service provider, dotCMS can be integrated with CAS running as a SAML identity provider and this blog post provides a quick walkthrough of how to make that integration possible. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) Configuration First, ensure that your CAS deployment is equipped to act as a SAML2 identity provider. Next, you may also use the JSON Service Registry to keep track of the dotCMS relying-party registration record in JSON definition files. The JSON file to contain the dotCMS registration record would be as follows: { @class: org.apereo.cas.support.saml.services.SamlRegisteredService serviceId: your-dotcms-entity-id name: dotCMS id: 1 description: dotCMS Content Mangement System attributeReleasePolicy: { @class: org.apereo.cas.services.ReturnAllowedAttributeReleasePolicy attributeFilter: { @class: org.apereo.cas.services.support.RegisteredServiceMutantRegexAttributeFilter patterns: { @class: java.util.LinkedHashMap memberOf: (?&lt;=CN=)([^,]+)-&gt;$1 } } allowedAttributes: [ java.util.ArrayList [ mail givenName memberOf sn ] ] } metadataLocation: https://path.to.your.dotcmscloud.com/dotsaml/metadata/3dd4ad1e-e2ab-492e-a428-87af35d341fd signAssertions: true skipGeneratingSubjectConfirmationNotBefore: true signResponses: true } A few things to point out: You will of course need to adjust the serviceId and metadataLocation to match your data and dotCMS instance. Make sure the AssertionConsumerService endpoint in the dotCMS metadata contains the urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect binding. Make sure CAS has retrieved the allowed attributes (i.e. mail, givenName, etc) listed in the JSON definition file. Regarding the memberOf attribute, the values fetched from the directory are typically in the format of CN=WebAdmin,OU=something,OU=something,DC=somewhere,DC=edu. The service provider requires only the CN portion of the attribute value where CAS would need to produce &lt;saml2:AttributeValue&gt;WebAdmin&lt;/saml2:AttributeValue&gt; instead of &lt;saml2:AttributeValue&gt;CN=WebAdmin,OU=something,OU=something,DC=somewhere,DC=edu&lt;/saml2:AttributeValue&gt;. This bit is handled via the RegisteredServiceMutantRegexAttributeFilter element in the JSON file. Finale Thanks to Keith Conger of Colorado College who was kind enough to share the above integration notes. If you too have an integration with a well-known SAML2 service provider, please consider sharing that guide in form of a blog post here as well. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2018/09/06/cas53-dotcms-saml2-integration/"
  },

  
  
  
  {
    "title": "Effective Software Troubleshooting Tactics",
    "text": "As an IAM consultant, a good portion of my time throughout the day is spent troubleshooting issues, analyzing logs, helping client and colleagues figure out how to make sense of a seemingly impossible situation when it comes to production system failures, behavioral weirdness or just simply getting something to work per a piece of documentation. I have found that having a documented set of steps and methods proves helpful at a high level as you set out a strategy to solve almost any issue dealing with software. In this blog post, I am sharing a few tactics I have learned and gathered over the years to help boost up my problem-solving foo and I hope that these continue to serve as helpful reminders for you as you troubleshoot software issues or diagnose deployment failures. Please note that these techniques are not listed in any particular order and all weigh more or less equally in terms of importance and priority. Use what works best for you, in the order that works best for you. Component Break-down As you set to configure and deploy a piece of software, one of the very first things you should do is to identify the key actors and their role in your particular deployment. For instance, if you are deploying a Java-based web application somewhere, your component break-down would include: The application itself Server deployment environment Dependent libraries/tooling Operating system Network Underlying programming language/framework … As you enumerate the components, it is important that you get to know each player to a reasonable degree. Be suspicious of everything. Once you have identified the key suspects, start working down the list and question everything. Start Simple The weirdness you are trying to diagnose may, in fact, be a consequence of a rather complicated use case that involves many players, ugly preconditions and a decent weather forecast. It is generally rather difficult and sometimes impossible to get every aspect of that difficult use case configured and developed in one initial attempt, specifically if you are not too familiar with the technical solution or even the use case at hand. So, start simple and break down the use case into logical, concrete, bounded chunks. Shoot for best case scenarios small enough to be manageable in your starting attempts. Once successful, tweak one aspect of the configuration in oh-so-small ways, introduce a variable and observe how the behavior changes. Repeat this process until you get home. Not too long ago, a colleague and I were trying to figure out how to let Apache Tomcat handle clientAuth. After a component break-down, we had the following key actors: Apache Tomcat Application Realm Configuration SSL Certificate Setup Browser Setup … Then we broke the use case down: Visit URL in application Browser presents certificate choice Apache Tomcat processes that choice Application accepts certificate Other stuff happens… So, we started to work down the list: Can the URL be accessed without Tomcat’s interference? What browser version/type is used? Is our test certificate sane and valid?, etc. Our very best initial outcome simply was the success of getting to a particular URL. We did not necessarily care what the URL looked like, whether it could or should be changed or rewritten, how one could end up at that URL, web access vs non-web access, etc. All those details were entirely irrelevant and we would get to them later. Things must be simple before they are complicated. Thou Shall Log Application logs are THE BEST RESOURCE for determining the root cause of a problem, provided you have configured the appropriate log levels. Specifically, you want to make sure DEBUG or TRACE levels are turned on for the relevant packages and components in your logging configuration. Know where the logging configuration is, become familiar with its syntax when changes are due and know where the output data is saved. Also: When changes are applied, you may need to restart the server environment and observe the log files to get a better understanding of behavior. Remember that you may not always be dealing with a single log file. Various events may get logged to different files at different locations on the system and you will need to be mindful of all locations where diagnostic data may be. For example, Apache Tomcat has a catalina.out log file, then some kind of a localhost-xyz file, then some sort of a accesslog file, then you have the application log files which may or may not choose to use the same the log files as target destinations for data, etc. Know your toolset. Remember to look at everything. Nuke all logs before you start the next test attempt. ALWAYS start clean. When you or anyone else analyzes diagnostics data, there should never be a question of Wait. Is this recent? Is this actually my attempt at doing X? It says there is an error, but the date goes back to 2 years ago. How?. Put a stop to all that. Stop wasting time. Save lives. If there is one take away in this section for you, dear reader, and one that you should take to heart, internalize, build statues for in tribute and pray to in the morning when you wake up, is this: REVIEW LOGS. Put another way: Are you troubleshooting software? Please review logs. Cannot get some vendor integration working? Please review logs. Neighbor’s loud music keeping you up at night? Please review logs. Ran out of milk? Please review logs. Dog shedding on the carpet? Cat doesn’t approve of your life choices? Sure. Please review logs. In summary, the answer is almost always in the logs. Compare Solutions If you can afford it, another helpful technique is to find environments and/or solutions that actually deliver the use case you need so that you can begin to compare differences. Your objective here is to try to eliminate variables that make the job unnecessarily unique and bothersome and remove those. Identification of these gotchas is the first step, but perhaps more importantly, understanding them and their effect is more ideal. For example, when we were trying to figure out Apache Tomcat’s way of handling clientAuth, we started asking the following questions: This is Apache Tomcat 8. Does it work with 7? Does it work with 6? Do we have a certificate that actually does work? How is that different from ours? Docs say we need file X at THIS location, but we have X at THAT location. Is that important? Logs say we cannot connect to our new LDAP. Can we connect to our old LDAP? What’s changed? Again, you want to find a solution that works and start comparing to identify differences and variables. Find working examples. Try different versions of software components with the same configuration you have today. Once you have spotted the difference, it’s important that you establish a baseline first and then start tweaking that baseline one small step at a time in configuration and elsewhere to find the missing element or changing behavior. If you thought option X in the configuration does blah, it’s important to figure out why it does or does not do as advertised. Identify what works and what doesn’t. Getting something to work is important and is one best case scenario sure, but you should not have to stop there, as there will come a time where you would have to go above and beyond option X and getting something to work might bring about other (usually security-related) consequences of which you should be mindful. Code Speaks Truth So, thus far you have identified the key components, broke down the use case, examined logs, and played around with alternative solutions. X works but X+1 does not. You know that. Your logs know that. Your previous working examples and legacy environments and your cat know that. What’s next? Truth can only be found in one place: the code, and surely, you must handle the truth. In my earlier anecdote of dealing with Apache Tomcat and clientAuth, all the steps led us to a suspicious realm configuration that was not activated quite correctly. We knew the realm worked and we know it was recognized by Apache Tomcat, yet it was never invoked at the right moment. So we started out by configuring Apache Tomcat for remote debugging, got the source code, compiled it and connected it via IntelliJ IDEA to a live running Tomcat instance so we could step through each statement. This method allowed us to debug the application, the realm, specific portion of Apache Tomcat code dealing with the realm…and surely, the cat. What I am trying to say here is that, (if you have access and a permitting license), you must be prepared for stepping down into the code to either trace the flow and logic statically by simply reading (between) the lines or begin a remote debugging session as we did to figure out how it is actually executing. Logs, comparable solutions and such can only take you so far. In the end, code speaks the truth. Share Pain, Responsibly With enough collected data, you should, of course, ask for help and guidance as time and opportunity allows. Sharing data and problem reports requires a degree of discipline to make it easy for others to understand the request easily and respond to it quickly. While there would always be room for follow-up questions and clarifications, it is best to produce and collect as much data as possible and share them using well-understood conventional formats and channels for the best outcome. A very good discipline is to use a starting template for sharing such reports. A template is basically a stubbed out application, categorized with a series of questions relevant for diagnostics where you fill in the gaps and state the problem description. Again, whether or not the project or community asks this of you, try to provide the following data points: Problem Statement State the problem description. What are you trying to do? Why are you doing it at all? This is where you begin to explain the use case at hand, and circumstances that led you to it. Be brief but precise: Avoid statements such as We have X and it doesn’t work. That statement simply doesn’t work. Reformulate statements such as Is it possible to do X? to explain the why, the what and the how. Expected Outcome As the title suggests, what do you expect to happen? What should be the end result in your view? Current Outcome As the title suggests, what do you see happening today? Reproduce How exactly should one go about reproducing the current outcome? Do you have a series of test cases that demonstrate some faulty behavior? Do you have a sample, a test application to exhibit the issue at hand? Diagnostics What steps have you taken to identify and diagnose what you consider to be an issue? How far down the rabbit hole have you traveled to debug the code, analyze the logs, find comparable solutions and track breaking change and incompatibility across software releases? Workarounds Do you have a solution at hand today that does the job? Have you experimented with code and configuration to determine the root cause and come up with a suggestion on how X may be improved, fixed, etc? Logs It is important that you provide the full story given to you by log data. You may either attach a clean log file that shows the faulty sequence of operations from start to finish, or (and you should avoid this where you can) you may decide to paste relevant sections of the log although this option is usually risky since the portions you think are relevant may not, in fact, be the entire story. If you do decide to share snippets of logs, remember to not paste the entire log output into a forum or description field, and learn to format and organize the data so it can be easily and readily understood by others quickly. Environment Describe the environment you have today. What are the key components at play here? What precise version of the software do you run? Where did you download it? How old is it and have you considered upgrading? How did you install it? What changes have been applied to the software or its surrounding ecosystem, etc? Stick to a template. Less guesswork leads to quicker responses and better outcomes. Practice. Eat, Sleep, Think This particular item may not be all too relevant when it comes to troubleshooting software, as issue resolution is usually time-sensitive and a task with a fair amount of pressure and stress, but I personally find this to be very valuable during design or coding sessions. At times, where you are stumped for a solution and have been staring at the screen and logs for a long time, unsure of how to connect certain pieces together and pigeonholed into a particular line of thinking, it is very useful to leave it all behind for a period of time and switch to a more physical activity. Go for a walk around the neighborhood’s park, take a nap, shoot a few free throws, etc and allow your brain to reset itself and subconsciously work on the problem in the background. Once you come back, you would have the equivalent of a second pair of eyes and a fresh perspective on how to attack the problem. In the same category, I find that re-iterating the problem and insofar solutions using a whiteboard, pen/pencil, chatting with a colleague or just about any other type of physical activity outside the use of electronics has the same effect. This effectively tickles your brain to get moving on a solution without you actively realizing it, and of course, a short break every once in a while can do a lot of good. My personal best is around 40-minute mark where I get up, walk around and try to do something totally different and silly, like attempting to train the pigeons outside to dubstep. Believe me, it works. (The technique, not the dubstep). Start Early This. So… I hope this review was of some help to you. This is by no means a comprehensive list; a lot of it is subjective and could be entirely inapplicable to you, your personality and work etiquette. Either way, if you have other tactics and strategies to share please feel free to edit this post as best you can. Also, many thanks to @jtgasper3 for reviewing this post and providing feedback. Misagh Moayyed",
    "tags": "Blog",
    "url": "/2018/09/05/effective-diagnostics/"
  },

  
  
  
  {
    "title": "Apereo CAS - MaxMind Geo2IP ISP Integration",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. I have been consulting on a CAS project with the main requirement of doing an integration with MaxMind GeoIP2 services. According to the MaxMind website: MaxMind GeoIP2 offerings identify the location and other characteristics of Internet users for a wide range of applications including content personalization, fraud detection, ad targeting, traffic analysis, compliance, geo-targeting, geo-fencing and digital rights management. There certainly is an existing integration already with MaxMind and CAS, which is primarily giving CAS the ability to cross-check a browser-provided IP address against the MaxMind database to geolocate the request and perform additional processing later on, such as auditing the event with richer information or executing risk-based authentication decisions. Our particular use case here was a bit different. We were presented with a MaxMind database file that contained a list of IP addresses known to be linked to VPN services and anonymous service providers. Our objective was to examine the request for the provided IP address, cross-check against the MaxMind database and ultimately present a warning to the user if a match is found. Our initial assumption was that such a warning is presented to the after the primary authentication event inclusive of any and all multifactor authentication flows such as Duo Security. This sort of use case can easily be done in form of webflow interrupts. CAS has the ability to pause and interrupt the authentication flow to reach out to external services and resources, querying for status and settings that would then dictate how CAS should manage and control the SSO session. Interrupt services are able to present notification messages to the user, provide options for redirects to external services, etc. This sounds exactly like what we could use. We just need to provide our own particular interrupt services that handle the cross-examination of the IP address with MaxMind and we should be good to go. Let’s do it. CollaborateIf you want to learn more about webflow interrupts, please see this post. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) Configuration First, we need to prepare the CAS overlay with the right set of dependencies to enable interrupt functionality and get access to the MaxMind APIs: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-interrupt-webflow&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.maxmind.geoip2&lt;/groupId&gt; &lt;artifactId&gt;geoip2&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt; &lt;/dependency&gt; Next, we can create our own configuration component and design the declaration of our interrupt service, tasked to talk to MaxMind APIs: @Configuration(\"SomeConfiguration\") @EnableConfigurationProperties(CasConfigurationProperties.class) public class SomeConfiguration { @Value(\"${our.maxmind.isp-file:file:/etc/cas/config/maxmind/GeoIP2-ISP.mmdb}\") private Resource ispDatabase; @Bean public InterruptInquirer interruptInquirer() { return new MaxmindInterruptInquirer(ispDatabase); } } Note that out particular MaxmindInterruptInquirer gains access to the MaxMind ISP database file to be used for cross-examination of IP addresses. Obviously, we need to design the MaxmindInterruptInquirer itself: public class MaxmindInterruptInquirer implements InterruptInquirer { private final DatabaseReader ispDatabaseReader; public MaxmindInterruptInquirer(final Resource ispResource) { try { File ispFile = ispResource.getFile(); ispDatabaseReader = new DatabaseReader.Builder(ispFile).build(); } catch (final Exception e) { throw new RuntimeException(e); } } @Override public InterruptResponse inquire(Authentication authentication, RegisteredService registeredService, Service service, Credential credential) { HttpServletRequest request = WebUtils.getHttpServletRequestFromExternalWebflowContext(); String address = request.getRemoteAddr(); /* Check the address in Maxmind database and return back the proper response */ ... } } Here is what happens: After all authentication flows have completed, the interrupt webflow kicks in and picks up our MaxmindInterruptInquirer component. It begins to examine the IP address linked to this request and does a look-up to find a match in the MaxMind database. If and when found, it will pass a response back up which would then get translated and stuff into the webflow available to the warning page for your user’s pleasure. That’s it. I should note that our requirement later on changed to present the same sort of warning before any of the authentication flows have commenced. An interesting nuance indeed, as the user must face the warning page before CAS presents the login screen and family in the browser, and one we might cover in a separate blog post. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/08/27/cas5-maxmind-isp-interrupt-integration/"
  },

  
  
  
  {
    "title": "Notes from Better by Design 2018",
    "text": "Notes from a design conference in Madison, WI Things I encountered at this conference that challenged me to grow: Celeste Headlee’s articulating the importance of conversations. Jorel Dray’s reminder to provide the feedback that others need to grow. Lou Downe’s call to enable scaling good design by extending more broadly the privilege of the opportunity to practice better service design. Have (better) conversations I found a lot to challenge me Celeste Headlee’s morning keynote (10 ways to have better conversations) and in the conversations practice workshop that immediately followed. See also: 11 minute TedX talk by this speaker Book by this author: We need to talk: how to have conversations that matter Our conversations are under-intentional, under-designed. There’s opportunities to have better conversations, by design. Bad news: you cannot fix others’ conversational behavior. (In general, you can’t fix other people). Good news: You can improve your own conversational skills. Online and in email: you are the worst version of yourself. To have better conversations: Single-task. Be present. Don’t lecture. Don’t try to change minds. Instead, go into conversation intending to learn from others. Ask open-ended questions. Who, what, when, where, why, how. Not yes-no questions. Go with the flow of the conversation. Don’t get caught up by some bit or by whatever your mind is teling you relates – let it go and keep up with the conversation as it flows past this. Say you don’t know when you don’t know. Never say “I know how you feel.” You don’t know how the other person feels. Even if you experienced something very similar, you still don’t know how even that experience felt, since with time and distance your mind has dulled that memory. Avoid conversational narcissism. Do not repeat yourself. Say it exactly once, and thereby become the kind of person who’s known to say things exactly once. If people have the impression you repeat yourself, they don’t listen, since their mind assumes they needn’t bother listening because the information will be available from the environment again in the future. If you’re known to say things only once, then people will listen to you the first and only time you say things. Stay out of the weeds. Most details don’t matter most of the time. Most people most of the time do not have the capacity to presently engage with those details. So just drop them. Listen. Really listen to people. Be interested in other people. Keep it brief. Online: you have 8 seconds. In face-to-face conversation, you have 30-60 seconds. It’s not a lot. New research: the liking gap. We under-estimate how much other people like us and enjoy our company. Your inner critic is more critical than others are and hold you to higher standards. Others don’t notice or remember your conversational failures so much as you think. Audience question: What about a culture of “healthy debate”? Answer: Rule for knowing when to engage in “debate”: Any time you want to accomplish anything, don’t “debate”. Audience question: Conversations as ephemeral. What about written communication, email as a way to have a record of conversations? Answer: that record is worth a lot less than you think it is. There’s a huge gap between what the email author thinks the email said and what the email recipient thinks it said. Email is good for: Lists, agendas, and summaries. Send an email listing or agendaing things that you need to have a conversation about. Have the conversation. Then send an email summarizing the conversation. Conveying attachments. Letters. The kind of thing that would have been a longhand real letter in a pre-email era. Praise. It turns out, straight up praise works as well over email as it does in conversation, maybe because looking at it afterward actually works for recipients of praise emails. Remote work: modern teleconferencing tools work great. Phone almost as good as f2f, and solutions with cameras close this gap further. How to get others to behave better in conversation: you can’t. The best you can do is model good behavior. Think of conversation as a game of catch. Both the turn taking, and the setting the other person up for success (catch is only fun if they successfully catch the ball.) Do not offer unsolicited advice. Shift responses vs support responses. Some conversational responses attempt to shift focus to oneself, whereas other conversational responses support the other person. Interesting to think about how this relates to the Async Manifesto and to more generally the advantages in making information available asynchronously, on demand, when people are ready to consume it rather than just when you’re ready to say it. How to discover what your users really need Paige Bennett’s talk How to discover what your users really need. We won’t uncover user needs by looking at the data alone. Ways to discover user needs Do workshops with users. Actively involve stakeholders – in working roles, photography, facilitation, greeters. Presence of stakeholders improves buy-in through their direct observation. This is more powerful than your reporting results. Field visits Observe users in their natural environment. Metaphors Helps people to be more expressive and more heard. Reframing the question We are not great at imagining what we may do. “Would you use this” –&gt; “Have you used something like this before?” Flip a request for a promise (what would you do) to an observation of current action (what do you currently do). “What would have gotten you to stay?” –&gt; “What did you hope this product would have done for you?” Sharing findings with stakeholders Your findings must live on without you. Workshops Exhibit pop-ups. Mini museum. Collateral Brown bags Audience question: what about remote users? Answer: consider a diary study. Art of feedback Jorel Dray’s The art of feedback. Feedback is a process, not an event. Getting feedback (in context of feedback about design work): Seek out more feedback. Set the tone. Handling feedback you don’t agree with: try it before you discredit it. Do what’s right, and also do what was asked for. Show both. Handling amorphous “I don’t like it” feedback. Gently remind that “it ain’t about you and what you like”, it’s about the design being effective for whatever its goal is. Circle back to the goal and try to get feedback on how the design fares against its goals. Fight hard, but know when to let it go. Giving feedback: Respect before anything else. There’s no point in giving feedback to anyone or about anything you don’t respect. Build a process. What’s working well? What needs to change to meet our objectives? (We do have identified objectives, right?) What would make the work more awesome? Recap. Take notes. Feedback becomes standard and routine, not a punishment. What, how, when of feedback matters. “You made it too busy” –&gt; “It’s too busy” –&gt; “Try to simplify” –&gt; “Try a version that’s simplified” –&gt; “Try simplifying so that people can focus on that really cool thing you made.” If time is tight, be specific. Talk in person when possible. Email is always brutal. Be timely. Ask for feedback. If you’re the kind of person who asks for feedback it’s more natural for you to be giving feedback. Demonstrate a state of constant improvement. Demonstrate accepting feedback effectively. Balance. Affirming and corrective. Standard 3 Mr Rogers to 1 Gorden Ramsay ratio, but sometimes much more Rogers. It’s not about you. Be what they need you to be to grow. In conclusion: Work is never bad, it’s just not there yet. Positive feedback keeps us going. Great feedback improves the world. Try to find happiness and put energy into growth, not outcome. Keynote: the future of (public) service design Lou Downe ‘s The future of (public) service design. Just hearing Lou Downe speak in person was inspirational in itself. They’re one of those leaders where you hear them speak and have that feeling of “Yes! Your heart is in the right place. You’re brave. You’re doing the right thing and doing the right things in the right ways. I’d follow you.” The vision they laid out was also compelling. Cenrtalization brought a significant initial increment of experience improvement for people interacting with the UK government, but the UK will achieve the next increment of improvement through empowering decentralized attentions to user experience throughout the UK government. Transformation is the ability of an organization to deliver and maintain a service over time. delivery –&gt; scale and sustainability Successfully delivering services at all is good, better than not. But the long term wins will come from scaling and sustaining service delivery. “Digital” is just a means to an end. Most of government is service design most of the time. Digital Service Standard –&gt; Government Service Standards Design your infrastructure, or your infrastructure will design you. Corralary: designing and offering infrastructure is high leverage. Don’t try to design the future. Design something the future can design. Be strong. Be kind. Carry on. Privilege and sharing privilege; privilege as lens for service design Give people the skills and opportunities to help themselves. Collaboration is a privilege. Barriers include money, time, and access to data. Having the space, the slack, the empowerment to improve service design and delivery is a tremendous privilege. Public servants often want to do a better job, to do the right thing, to better serve the public. To deliver experiences that are reasonable, that are in the proudest traditions of thoughtfully and kindly treating others. And often public servants have very little room, empowerment, expertise, support for doing this. In extrema, sticking your neck out to criticize an existing experience, that’s a way to jeopardize a job you may not be able to afford to lose. Making things better is a privilege. The next increment of improvements will be achieved through sharing that privilege. (Unpublished) ranty blog posts for the win Anecdote that resonated: Lou’s proudest achievement so far has been spinning up the 5M Pound / year initiative around service delivery manual, style guidance, etc. This originated in a ranty blog post Lou had drafted and been asked not to actually publish, and instead to do something about the issues articulated. There is power in writing. It clarifies thinking and it shares vision, persuades. There are also necessary steps that come after the ranty blog post to take strides forward. Not all ranty blog posts should actually be published (but perhaps really should nonetheless be written). On how to approach accessibility and usability Mobile-first, accessibility-first. Extreme testing first. Testing with screen readers. User testing with users with physical and cognitive disabilities. If it works for some of the most difficult user contexts, then it’s more likely to work in other contexts too. This testing teaches you more sooner. Making services accessible is like making a muffin be a blueberry muffin. It’s really hard to get the blueberries in later if you don’t bake them in from the beginning. Extreme testing first is time and resource consuming and expensive and always needs justified. It’s also the most effective way to design highly usable, accessible services. And when it comes right down to it, the law probably requires you to do this. So if you’re taking compliance with that law seriously, well, this is what it really takes to do it. Conclusions Be interested in humans. Interested in learning from conversation with humans, interested in discovering what humans really need, interested in growing from feedback from humans, and in provding humans the feedback they need to grow, interested in empowering humans to design and deliver better services at government scale Andrew Petro",
    "tags": "Blog",
    "url": "/2018/08/24/better-by-design-2018/"
  },

  
  
  
  {
    "title": "Apereo CAS - Authentication Lifecycle Phases",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. There may come a time in your CAS deployment where you realize that simple username/password type of authentication strategy is no longer sufficient and you need to introduce additional policies that sanitize the credentials before submission, check for account status, reach out to external systems and more before you can vouch for a valid authentication request to proceed. The authentication engine in Apereo CAS is most flexible, where there are specific phases throughout the lifecycle of a given in-process request that can be extended and massaged for prosperity and fancy use cases. In this tutorial, we’ll quickly tap into a few of these phases, where our objectives are as follows: Before credentials are validated, we shall reach out to an external system (such as a REST API) to check for user account status. Depending on the response, we may decide to entirely block the request and prevent the user from actually authenticating. After a successful authentication attempt though before a single sign-on session is established, we would want to check the authentication result and reach out to an external API/system to determine whether we need to inform the user about any particular messages or warnings. Whatever the result, we do not intend to block the request and it would be great if the end-user is still given the ability to proceed, despite the forewarned dangers. Cool, eh? Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay (The 5.3 branch specifically) Configuration As the first step, we need to figure out an authentication strategy. For this tutorial, I taught CAS to use JAAS for authentication in my cas.properties: cas.authn.jaas[0].realm=CAS cas.authn.jaas[0].loginConfigType=JavaLoginConfig cas.authn.jaas[0].loginConfigurationFile=/etc/cas/config/jaas.conf Of course, my /etc/cas/config/jaas.conf file is fairly simple: CAS { org.apereo.cas.authentication.handler.support.jaas.AccountsPreDefinedLoginModule required accounts=\"casuser::Mellon\"; }; This basically means that I can authenticate using the static credentials casuser and Mellon. Not too impressive yet, I suppose, but let’s kick this into gear and address our first objective, which is pre-validation of authentication attempts. There are many ways of doing this and as an option, we are going to examine the use case with Authentication PreProcessor components. Pre-Processing Authentications The authentication engine in CAS is in fact quite elaborate. It is composed of my distinct steps, sort of like a factory production line, where some piece of data whether input by the user or from the browser, etc comes in from the outside and is transformed into a form of credential whereby a series of actions and surgeries take place to operate on the credential. One of these steps early on in the process is a component referred to as Authentication PreProcessor, which does exactly what its name suggests. This component registers itself with the engine and is tasked with any pre-vetting the credential before any particular authentication strategy kicks into action. RememberNote that this sort of thing may be considered overkill if your user account store is capable of detecting user account status and blocking the authentication attempt. Using Authentication PreProcessor is generally only required if you have a rather fancy use case with unusual requirements and workflows, and dependencies on outside systems. If you do not, close your eyes and head into the next section. So in order to create our own Authentication PreProcessor, we’ll need to design our own configuration class and register the pre-processor as such: @Configuration(\"FancyCasConfiguration\") @EnableConfigurationProperties(CasConfigurationProperties.class) public class FancyCasConfiguration implements AuthenticationEventExecutionPlanConfigurer { @Override public void configureAuthenticationExecutionPlan(final AuthenticationEventExecutionPlan plan) { plan.registerAuthenticationPreProcessor(accountStatusRetrievalPreProcessor()); } @RefreshScope @Bean public AuthenticationPreProcessor fancyPreProcessor() { return new FancyPreProcessor(); } } Our FancyPreProcessor then could look like this: public class FancyPreProcessor implements AuthenticationPreProcessor { @Override public boolean process(final AuthenticationTransaction transaction) throws AuthenticationException { transaction.getPrimaryCredential().ifPresent(c -&gt; { /* Replace with your own condition... */ if (checkExternalSystemOrApiAndFail()) { final Map&lt;String, Throwable&gt; errors = new HashMap&lt;&gt;(); errors.put(AccountPasswordMustChangeException.class.getSimpleName(), new AccountPasswordMustChangeException(\"Expired account\")); throw new AuthenticationException(errors); } }); return true; } } RememberYou will need to include a number of CAS module dependencies in your build process for the above snippets to properly compile. All that is happening here is that the authentication engine keeps track of this pre-processor and invokes before it does anything else. Our FancyPreProcessor when invoked, simply goes in to contact needed systems and check for conditions as needed and finally proper errors are thrown back to CAS that halt the authentication flow and get translated by the upper layers into reasonable messages for the end-user. Post-Processing Authentications Our second objective can in fact be done in form of a normal password policy for JAAS, implemented in your favorite toolkit ever that is Groovy. As you might guess, we need to teach CAS to activate the policy when JAAS completes: cas.authn.jaas[0].passwordPolicy.enabled=true cas.authn.jaas[0].passwordPolicy.strategy=GROOVY cas.authn.jaas[0].passwordPolicy.groovy.location=/etc/cas/config/SomePasswordPolicyStrategy.groovy …and of course, we need to write the SomePasswordPolicyStrategy.groovy script: import org.apereo.cas.* import java.util.* import org.apereo.cas.authentication.* def List&lt;MessageDescriptor&gt; run(final Object... args) { def response = args[0] def configuration = args[1] def logger = args[2] logger.debug(\"Things are happening for [{}]\", response) if (thereBeDragonsAhead()) return [new DefaultMessageDescriptor(\"be.afraid.message.code\")] return [] } If the policy sees the need, it will collect messages and warnings that would be passed up to the login flow which tries to navigate and switch to a screen where such messages are pulled from language bundles using their code and displayed back for the end-user to examine. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/08/23/cas5-authn-lifecycle-extensions/"
  },

  
  
  
  {
    "title": "CAS 6.0.0 RC1 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.3.0 GA was released on June 29th, 2018. Since then, the project has been moving forward with development of the next feature release that is tagged as 6.0.0. Note that this is a major release of the CAS software which may present significant changes in architecture, configuration or behavior. Please review the release policy to learn more about the scope of the release. This post intends to highlight some of the improvements and enhancements packed into the first release candidate in the 6.0.0 series. Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. Note that CAS releases are strictly time-based releases; they are not scheduled or based on specific benchmarks, statistics or completion of features. To gain confidence in a particular release, it is strongly recommended that you start early by experimenting with release candidates and/or follow-up snapshots. In order to start experimenting with release candidates, at any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Overlay In the build.properties of the overlay, adjust the following setting: casVersion=6.0.0-RC1 The template overlays are getting reorganized to some degree before they can be fully functional with CAS 6. Be sure to double check the branch and the overlay structure as you navigate though CAS versions and release candidates. Changes New &amp; Noteworthy Java 10 Servlet Specification v4 Spring v5 Spring Boot v2 Metrics Endpoints Endpoint Security CAS Command-line Shell Dynamic SAML2 Metadata Webflow Decorations Adaptive Authentication IP Intelligence Azure MFA Integration Google Authenticator Account Management OAuth &amp; OpenID Connect JSON Output OAuth Device Flow OAuth Proof Key Code Exchange (PKCE) CAS as Multifactor Authentication Provider Couchbase Audits SAML2 Metadata Health Status OAuth Token Introspection YubiKey Account Management Nexmo SMS Integration Small Stuff Library Upgrades Resources Get Involved Credits New &amp; Noteworthy Java 10 WATCH OUT!This is a breaking change. You will need to make sure the deployment platform is prepped with the correct Java version before moving forward. Oracle recently announced that they intend to move Java to a release every six months. Under the new release schedule, Oracle proposes strict time-based releases, known as feature releases. These will appear every year in March and September. The new release schedule is intended to begin immediately after the release of Java 9 (which is long-gone at this point), with the next release of Java to come in early 2018. The release schedule of the CAS software quite happily lends itself to the Java release schedule as well. There has been a feature release once every 6 months or so for the past couple of years and such releases have exclusively been time-based releases with a number of candidates in between them for adopters to experiment. That being said, in order to keep up with the Java release schedule, stay on a supported platform and keep the progress ball moving forward, the minimum required Java version is set to be 11 starting with CAS 6. This has not been an easy effort; the CAS 6 development has been in progress since February 2018 with early testing of snapshots and release candidates of Java as well as all other software packages and libraries to ensure a successful build and deployment model. For the most part, all functionality continues to remain the same as it was and the change in platform requirements should remain completely invisible to the deployment. Note that this particular release candidate will be based on top of Java 10, having passed 9 already. As other libraries begin to catch up with Java 11 and provider better support, CAS will ultimately switch to Java 11 before the final GA release. While there are no specific plans as of this writing, there will likely be follow-up feature releases after CAS 6 in form of 6.1, 6.2, etc each of which may require and depend on future Java releases such as 12, 13, etc. Servlet Specification v4 AttentionThis might be a breaking change. While there isn't anything in CAS (yet) that would take advantage of the new specification features, we obviously reserve the right to do. You are better off switching to the required version as time and energy allows. The embedded server containers provided by CAS (Apache Tomcat, Jetty, etc) have been and will be upgraded to include support for the new specification version. This will most notably include required support for Apache Tomcat 9+ and Undertow 2+. Spring v5 Given changes in the platform requirements, the Spring framework that is very heavily used internally by CAS has been updated to its most recent version that is version 5.0.x. You can read all about Spring 5 here. While for the most part, the upgrade is rather invisible to the CAS developer and adopter, one area that is negatively impacted by the change is the SAML2 functionality in CAS that uses the Velocity templating engine needed by the OpenSAML library to submit SAML responses, etc. Velocity support is no longer available in Spring 5 and additional measures are taken in CAS to ensure OpenSAML and friends and continue to do the job without relying on Velocity support assumed to be available with the Spring framework. It is quite likely that CAS would ultimately switch to Spring 5.1.x to take full advantage of Java 11 support. Spring Boot v2 CAS is entirely based on the Spring Boot framework at heart, which controls the orchestration and management of CAS settings, configuration modules, and many other things. Moving to the newer version of the Java platform as well as the Spring framework requires CAS to switch to the latest iteration of the Spring Boot framework, namely the 2.x series. You can read all about Spring Boot 2 here. JDK CompatibilityFull support for Java 11 will be provided by Spring Boot 2.1.x, expected to be released in September 2018. Given the impact and utility of the framework in the CAS codebase, a rather large number of changes have had to be introduced in order to achieve a successful upgrade and keep as much of the current functionality as possible. However, a number of areas in CAS are negatively impacted by this upgrade some of which are more visible than others and sometimes for the better. These areas include are but not limited to CAS metrics, actuator/admin endpoints as well as their security and protection strategy. It is quite likely that CAS would ultimately switch to Spring Boot 2.1.x to take full advantage of Java 11 support. Metrics WATCH OUT!This is a breaking change. Consult the CAS documentation and adjust accordingly. As part of the Spring Boot v2 upgrade, CAS metrics are cleaned up as much as possible to delegate the entire task of capturing and recording metrics to Spring Boot, which internally delegates that functionality by auto-configuring components from the micrometer project. This is an application metrics facade for the most popular monitoring tools whose connection information is entirely controlled by specific properties and settings provided by Spring Boot. In this area, CAS only begins to prepare the deployment environment with the right set of dependencies and libraries and then gets out of the way, allowing micrometer and native Spring Boot functionality to take over. While a large set of options are supported by micrometer and auto-configured by Spring Boot to capture and store metrics, as a result of this change support for services such as MongoDb, Redis and such are removed from CAS given support for the equivalent components in Spring Boot is removed. However, note that micrometer continues to add support for newer services and target systems and by simply keeping the dependencies up-to-date and relevant, those options would automatically become available to CAS. Endpoints Actuator endpoints, known in CAS as admin endpoints, let you monitor and interact with your application. Spring Boot includes a number of built-in endpoints and lets you add your own. For example, the health endpoint provides basic application health information. Spring Boot 2 brings a brand new endpoint infrastructure that allows you to define one or several operations in a technology independent fashion with support for Spring MVC, Spring WebFlux and more. WATCH OUT!This is a breaking change. Consult the CAS documentation and adjust accordingly. This means while the endpoints provided by Spring Boot will transition quite nicely over to CAS 6, those that are provided by CAS needed to be redesigned again to lend themselves to the new technology-agnostic strategy. In this new model, endpoints exhibit the following traits: Each endpoint can be individually enabled or disabled and a global default is available to control this behavior en mass. The security of each endpoint is entirely controlled by Spring Security, once and if found in the application bundle on the classpath. More on this later in the following section. Each endpoint may be individually chosen for exposure over the web. By default, endpoints are exposed over HTTP under the /actuator path by using the ID of the endpoint. However, endpoints can be remapped. For example, the following settings remap /actuator/health to /healthcheck: management.endpoints.web.base-path=/ management.endpoints.web.path-mapping.health=healthcheck DashboardsNote that all UI functionality and dashboards are removed from the CAS where the server is only tasked to fetch and produce data using the available endpoints in RESTful and secure ways. The ultimate end goal is to introduce relevant UI components and screens into the CAS management web application that would consume data from such endpoints, making the management web application truly a management web application. To learn more about endpoints, monitors and health indicators from the Spring Boot perspective, please review this document. Endpoint Security Endpoint security in Spring Boot v2 and by extension CAS receives a complete overhaul. All endpoints are considered disabled and sensitive by default, protected by a pair of pre-defined master credentials in CAS properties. Spring Boot 2.0 does not provide separate auto-configuration for user-defined endpoints and actuator endpoints with a rather overloaded sensitive property. All that functionality is handed off to Spring Security. WATCH OUT!This is a breaking change. Consult the CAS documentation and adjust accordingly. When Spring Security is on the classpath, the auto-configuration secures all endpoints by default. CAS relies on Spring Security’s content-negotiation strategy to determine whether to use httpBasic or formLogin, and security of endpoints is extended by CAS configuration to determine the access level and permissions of each endpoint. There will be follow-up guides and posts about how to get endpoints secured and available for proper access but for now, this document should be a decent starting point. CAS Command-line Shell The CAS command-line shell, as a result of upgrading to the latest Spring Shell version, is impacted such that basic command-line options available in the non-interactive version of the shell are now removed. This means that you may still log into the shell and work with available CAS commands as you did interactively, taking advantage of features such as command history, tab completion, etc. Dynamic SAML2 Metadata Dynamic SAML2 metadata management via JPA and MongoDb is now able to support and store SAML2 identity provider metadata artifacts. Support for additional storage options may be added in future on demand. Webflow Decorations Learn how to fetch and display data dynamically from external data sources and endpoints and pass those along to the webflow by reviewing this guide. Adaptive Authentication IP Intelligence Adaptive Authentication gains support to examine client IP addresses using a variety of strategies to determine whether requests should be allowed or rejected. Azure MFA Integration The integration with Microsoft’s Azure multifactor authentication, previously marked as deprecated functionality, is now removed from CAS. Google Authenticator Account Management Accounts registered with Google Authenticator can now be monitored and managed administratively via CAS monitoring capabilities. OAuth &amp; OpenID Connect JSON Output WATCH OUT!This is a breaking change. Service definitions and/or schemas need to be updated accordingly. The jsonFormat property assigned to each OAuth or OpenID Connect services is now removed and JSON is now made the default output syntax. OAuth Device Flow OAuth device flow is now supported. OAuth Proof Key Code Exchange (PKCE) OAuth PKCE flow is now supported. CAS as Multifactor Authentication Provider CAS gains the ability to act as a simple multifactor authentication provider, issuing tokens on its own and sharing them with the end-user via email and/or text messages. Couchbase Audits Couchbase is now supported for CAS audit logs. SAML2 Metadata Health Status Status of SAML metadata assigned to a SAML service can now be reported back as part of the CAS health monitoring. OAuth Token Introspection CAS OAuth support can now lend itself to token introspection. The semantics of this functionality are identical to that of OpenID Connect. YubiKey Account Management Accounts registered with YubiKey Authentication can now be monitored and managed administratively via CAS monitoring capabilities. Nexmo SMS Integration CAS can now integrate with the Nexmo platform for sending text messages. Small Stuff Delegated to the OpenID Connect provider for authentication now supports a new tenant option. Aspects of OpenID Connect discovery profile, such as supported claim types, signing algorithms, etc can now be customized via CAS settings. While generating JWTs, a typ header parameter is now specified. The signing algorithm of OpenID Connect services can now be defined for each RP. Delegated authentication should correctly take advantage of the unauthorizedUrl field assigned to a service definition. Delegated authentication should hide aspects of the CAS user interface while auto-redirecting to a provider. Additional audit points are now provided for OAuth functionality to capture access token requests and responses as well as device codes. The multifactor trusted devices endpoint can now fetch registered devices linked to a user name. Internal APIs used to manage Google Authenticator tokens and accounts are improved to support additional removal and counting ops. Consistent package import order rules are now applied across the codebase and enforced by Checkstyle. CAS is now using SonarQube for static analysis and extra code quality measures. A ton of improvements to the Travis CI test harness to ensure CAS builds can execute as efficiently as possible while running integration tests. Binary attribute values should now be properly encoded in CAS validation payload. Acceptable Usage Policy and Interrupt Notification features of CAS are now wired up to play nice with delegated authentication flow. SPNEGO authentication properties are now split into two sections were one deals with system-level settings and the other controls a collection of SPNEGO authntication attempts with support for multiple service principals, etc. Small number of adjustments to ensure CAS cookie management can optionally control cookie session-pinning. Library Upgrades Java Spring Spring Boot Apache Tomcat Spring Boot Admin JUnit Kryo JAXB Swagger Eureka InfluxDb Apache Ignite MongoDb Driver MariaDb Driver PostgreSQL Driver Couchbase Hazelcast MySQL Guava Amazon SDK Twilio Pac4j Nimbus JWT Cassandra Driver Font Awesome Bootstrap Resources Documentation Release Schedule Release Policy Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Credits Big thanks to all who participate in the development of this release to submit patches and contribute improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2018/08/03/600rc1-release/"
  },

  
  
  
  {
    "title": "Apereo CAS Delegated Authentication with ADFS",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Apereo CAS has had support to delegated authentication to Microsoft ADFS for quite some time now. This functionality, if memory serves me correctly, started around CAS 3.x in form of an extension which then later found its way into the CAS codebase as a first class feature. Since then, the functionality more or less has evolved to allow the adopter less configuration overhead and fancier ways to automated workflows. The story is actually quite simply: The integration between the CAS Server and ADFS delegates user authentication from CAS Server to ADFS, making CAS Server an ADFS client. Delegation of course is just a fancy word that ultimately means, whether automatically or at the click of a button, the browser is expected to redirect the user to the appropriate ADFS endpoint and on the return trip back, CAS is tasked to parse the response and extract claims, etc in order to establish an authentication session, issue tickets, etc. In other words, in delegated scenarios, the main identity provider is an external system such as ADFS in this case and CAS simply begins to act as a client or proxy in between. In the most common use case, CAS is made entirely invisible to the end-user such that the redirect simply happens automatically and as far as the audience is concerned, there is only the external identity provider (i.e. ADFS) and the target application that is, of course, prepped to speak the CAS protocol. This is important note to consider: target applications are CASified applications. While the end-user just interacts with ADFS and the application, the application itself only interacts with CAS since of course, CAS is proxying the workflow in between. The application should not have to care about the source of the identity information and the intricacies of data extraction from various identity providers. It cannot. Its sole concern is to speak the CAS protocol and exchange a service ticket with the CAS server for the right stuff that CAS may have gathered from any number of sources. Of course, you and I know that source could very well be ADFS; but that’s just between you and me…and let’s keep it that way! Usage WarningIf you are trying to figure how you may log into ADFS while CAS plays the role of a SAML2 identity provider, you are in the wrong place. Please read this post instead. Our starting position is based on the following: CAS 6.0.x Java 11 Maven Overlay (The 6.0 branch specifically) The Cutting EdgeNote that as of this writing today, CAS 6 is very much in development and is not officially released. While the functionality and instructions noted here, more or less remain the same for CAS 5, you may want to take steps described here with a pinch of salt, and of course as always, shake well before use. Configuration The initial setup is in fact super simple; as the documentation describes you simply need to add the required dependency in your overlay: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-wsfederation-webflow&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; …and then in your cas.properties, instruct CAS to hand off authentication to ADFS: # cas.authn.wsfed[0].identityProviderUrl=https://sample.adfs.org/adfs/ls/ # cas.authn.wsfed[0].identityProviderIdentifier=http://sample.adfs.org/adfs/services/trust # cas.authn.wsfed[0].relyingPartyIdentifier=urn:cas:sample # cas.authn.wsfed[0].name=ADFS Server # cas.authn.wsfed[0].identityAttribute=upn # cas.authn.wsfed[0].signingCertificateResources=file:/etc/cas/adfs-signing.cer # cas.authn.wsfed[0].autoRedirect=false A few tips for the enlightened: Surely, swap out sample.adfs.org with your ADFS domain as appropriate. Remember to register CAS as a client of ADFS by setting up a relying party trust under the id urn:cas:sample. You can choose any identifier you prefer, so long as CAS and ADFS both agree to use the same value. If you make changes, please be generous and share the value with both systems. ADFS tends to sign responses using a signing certificate. The certificate will need to be obtained and shared with the CAS server with you physically defining its home and sharing that path with CAS, as is done in my example above with adfs-signing.cer. Of course, CAS somehow needs to figure out the authenticated username from the ADFS-produced response. To do this, it tends to look at a specific claim within that response typically released as upn. That is to say, you need to ensure ADFS is releasing this attribute (or anything else you prefer) to CAS and then ensure CAS is using the same claim name when it begins to do its extraction magic. If you are interested to learn more about the settings, I recommend checking out the CAS commandline shell or better yet, use the CAS administrator dashboards to look up documentation and configuration metadata by querying for settings. Mutating Attributes I wish this section was more about how certain ADFS claims begin to start a revolution, rise up against the X-Men and transform into evil giant XML blobs on demand to wreak havoc but sadly, the topic here is much more boring than that. As ADFS claims are released to CAS, you are here given the opportunity to transform and mutate those claims and attributes before they are packed into the CAS-enveloped authenticated subject. You can add or remove attributes or more commonly change and sanitize values for certain claims. To do so, CAS provides you with a brand-new option to implement said transformation rules as a Groovy script whose path may be taught to CAS as such: # cas.authn.wsfed[0].attributeMutatorScript.location=file:/etc/cas/config/wsfed-attr.groovy …and of course, the script may look like this: import org.apereo.cas.* import java.util.* import org.apereo.cas.authentication.* def Map run(final Object... args) { def attributes = args[0] def logger = args[1] logger.info(\"Mutating attributes {}\", attributes) return [upn: \"Wolverine\"] } So, we are getting a bunch of claims or attributes from ADFS and are tasked to simply return a map of keys and values. In my example above and regardless of what ADFS delivers to CAS, I decided to only stuff the upn attribute into that final map with a single value that is Wolverine. Of course, since upn is designated to act the username claim, the ultimate CAS principal will be established under the username Wolverine. …without the claws, certainly, though that is possible too. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/07/31/cas6-delegated-authn-adfs/"
  },

  
  
  
  {
    "title": "Apereo CAS Swag with Swagger",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. For some time now, CAS has had the ability to take advantages of Swagger natively to produce API documentation automatically. The generated documentation supports all CAS endpoints and REST APIs provided they are made available to the runtime application context. This means that any and all modules that declare API endpoints will automatically be recognized by the CAS Swagger integration, provided of course the module is activated and included in your CAS configuration. If you wish to learn more about Swagger, please visit this link and the reference documentation for CAS 5.3.x as of this writing is available here. Our starting position is based on the following: CAS 5.3.x Java 8 Maven Overlay Configuration The setup is in fact super simple; as the documentation describes you simply need to add the required dependency in your overlay: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-documentation-swagger&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; …and just to keep things more interesting, I also chose to include support for CAS REST Protocol: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-rest&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; That’s it. Package and run the overlay as usual. Once the server is up and running, simply navigate to https://&lt;your-cas-server-address&gt;/cas/swagger-ui.html and examine the APIs presented to you via Swagger. For instance, this is what I see: Notice how certain entries are surrounded in a blue square. This is not a Swagger feature; rather this is me trying to outline that the endpoints and APIs that are presented as part of the CAS protocol are also automatically picked up by Swagger and presented to you beautifully via this user interface. This behavior, as a reminder, applies to any module that presents APIs. Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/07/24/cas-apis-swagger/"
  },

  
  
  
  {
    "title": "Get Productive with Shell Aliases",
    "text": "Over the years, I have collected a number of shell aliases from various blog posts and websites that have tremendously helped me navigate and automate confusing workflows and remember complicated terminal commands. This post, for what it’s worth, is about giving back to the developer community with me sharing aliases I find to be extremely useful in hopes that you, dear reader, also find them useable and productive. There may be better options for housing such aliases, but for better or worse, all commands are to be put inside ~/.profile, all of which have been exercised on macOS. Activate Profile alias editp='edit ~/.profile' alias actp='source ~/.profile' Change Directory alias cd..='cd ../' # Go back 1 directory level (for fast typers) alias ..='cd ../' # Go back 1 directory level alias ...='cd ../../' # Go back 2 directory levels alias .3='cd ../../../' # Go back 3 directory levels alias .4='cd ../../../../' # Go back 4 directory levels alias .5='cd ../../../../../' # Go back 5 directory levels alias .6='cd ../../../../../../' # Go back 6 directory levels Editors alias edit=\"code\" # Visual Studio Code alias this=\"edit .\" alias subl=\"/Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl $@\" alias this=\"edit .\" Variables for Colorful Output BOLD=$(tput bold) BLACK=$(tput setaf 0) WHITE=$(tput setaf 7) BLUE=$(tput setaf 4) GREEN=$(tput setaf 2) NORMAL=$(tput sgr0) Mastering the SSH Agent export env=$HOME/.ssh/environment function agent_is_running() { if [ \"$SSH_AUTH_SOCK\" ]; then # ssh-add returns: # 0 = agent running, has keys # 1 = agent running, no keys # 2 = agent not running ssh-add -l &gt;/dev/null 2&gt;&amp;1 || [ $? -eq 1 ] else false fi } function agent_has_keys() { ssh-add -l &gt;/dev/null 2&gt;&amp;1 } function agent_load_env() { . \"$env\" &gt;/dev/null } function agent_start() { echo \"Starting SSH agent...\" (umask 077; ssh-agent &gt;\"$env\") . \"$env\" &gt;/dev/null } function add_all_keys() { echo \"Adding SSH keys...\" ls ~/.ssh | grep ^id_rsa.*$ | sed \"s:^:`echo ~`/.ssh/:\" | xargs -n 1 ssh-add } if ! agent_is_running; then agent_load_env fi # if your keys are not stored in ~/.ssh/id_rsa.pub or ~/.ssh/id_dsa.pub, you'll need # to paste the proper path after ssh-add if ! agent_is_running; then agent_start add_all_keys elif ! agent_has_keys; then add_all_keys fi echo `ssh-add -l | wc -l` SSH keys registered. unset env Fancy Git Prompt if [ -f \"$(brew --prefix bash-git-prompt)/share/gitprompt.sh\" ]; then GIT_PROMPT_THEME=Default source \"$(brew --prefix bash-git-prompt)/share/gitprompt.sh\" fi Switch JDK Versions function setjdk() { if [ $# -ne 0 ]; then removeFromPath '/System/Library/Frameworks/JavaVM.framework/Home/bin' if [ -n \"${JAVA_HOME+x}\" ]; then removeFromPath \"$JAVA_HOME/bin\" fi export JAVA_HOME=`/usr/libexec/java_home -v $@` export PATH=$JAVA_HOME/bin:$PATH echo -e \"JAVA_HOME to $@\" fi } function removeFromPath() { export PATH=$(echo $PATH | sed -E -e \"s;:$1;;\" -e \"s;$1:?;;\") } …where you can do: setjdk 1.8 or: setjdk 11 Spawn Databases via Docker function mysql() { docker run --name mysql -p3306:3306 --env=\"MYSQL_ROOT_PASSWORD=password\" --env=\"MYSQL_DATABASE=test\" -d mysql } function sqlserver() { docker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=p@ssw0rd' -p 1433:1433 microsoft/mssql-server-linux:2017-CU7 } Gradle Dependency Insight function gdep() { ./gradlew dependencyInsight --configuration \"$2\" --dependency \"$1\" } …where you can do: gdep compileClasspath jackson Properties alias gprop=\"edit ~/.gradle/gradle.properties\" Helpers alias openPorts='sudo lsof -i | grep LISTEN' alias cls=\"clear\" alias del='rm' alias path='echo -e ${PATH//:/\\\\n}' alias hostfile=\"sudo atom /etc/hosts\" # Requires Atom function mcd() { mkdir -p \"$1\" &amp;&amp; cd \"$1\"; } alias dir=\"ls -a -l\" alias myip=\"curl ifconfig.co/json\" Docker Search &amp; Destroy alias dkc=\"docker stop $(docker ps -aq); docker rm $(docker ps -aq)\"; SSH Into Container function dockerssh() { export CID=$(docker ps -aqf \"name=$1\"); docker exec -it $CID /bin/bash } Git Commit Changes function gc() { echo -e \"${GREEN}Commit message:\\n${WHITE}\\t$1\\n${NORMAL}\" echo \"Adding all changes...\" git add --all echo \"Committing changes...\" git commit -S -am \"$1\" echo \"Fetching all submodules...\" modules=($(git submodule | awk '{print $2}')) for module in \"${modules[@]}\"; do echo -e \"\\tSwitching to module ${WHITE}${module}${NORMAL}\" pushd $module &gt; /dev/null echo -e \"\\tFetching status for module ${WHITE}${module}${NORMAL}\" modulestatus=$(git status --porcelain | wc -l) if [[ $modulestatus -ne 0 ]]; then echo -e \"\\t${GREEN}Updating module: ${WHITE}${module}${NORMAL}\" echo -e \"\\tAdding changes for module ${WHITE}${module}${NORMAL}\" git add --all echo -e \"\\tCommitting changes for module ${WHITE}${module}${NORMAL}\" git commit -S -am \"$1\" git status --short else echo -e \"\\tNo changes found to commit for module ${WHITE}${module}${NORMAL}\" fi popd &gt; /dev/null done echo -e \"${GREEN}Done!\\nStatus:${NORMAL}\" git status } Misc alias delmerged=\"git branch --merged | grep -v \"\\*\" | grep -v master | grep -v dev | xargs -n 1 git branch -d\" alias gco=\"git checkout $1\" alias gbo=\"git checkout -b $1\" alias gp=\"git push --set-upstream $1 $2\" alias gl=\"git pull $1 $2\" alias grs=\"git reset --hard &amp;&amp; git clean -fd\" alias gba=\"git branch -a\" alias gbr=\"git branch -r\" alias gs=\"git status -s -b\" alias gpl=\"git pull origin master --no-edit --allow-unrelated-histories\" alias gps=\"git push origin master --recurse-submodules=on-demand \" alias gst=\"git status\" alias ggc=\"git gc --aggressive --prune=now\" Processes function pidit() { ps -ef | grep \"$@\" | grep -v grep | awk '{print $2}' } function proc() { ps -ef | grep \"$@\" | grep -v grep } function kp() { ps -ef | grep \"$1\" | grep -v grep | awk '{print $2}' | xargs kill } Search Aliases function cm() { alias | grep \"$@\" | head -n 1 } Contribute to Apereo Blog Once you have cloned the Apereo Blog repository: alias blog=\"cd /path/to/apereo.github.io\" alias blogthis=\"blog; this\" That’s it. I hope you find these useful. Misagh Moayyed",
    "tags": "Blog",
    "url": "/2018/07/14/shell-aliases-collection/"
  },

  
  
  
  {
    "title": "feat(conventional_commits): signal breaking changes in commit titles",
    "text": "Short version I like Conventional Commits. Conventional Commits miss an important opportunity to signal the breakingness of change in the title rather than just the body of a commit message. Introducing a “BREAK: “ prefix might be a good way to do this. There are other ideas. Call to action: help make Conventional Commits better in this and other respects Status quo: feat: split `ROLE_VIEW_ABSENCE_HISTORIES` (Is this a breaking change? You’ll have to read the exciting commit message body and footer to find out…) Better: BREAK: feat: split ROLE_VIEW_ABSENCE_HISTORIES or !feat: split ROLE_VIEW_ABSENCE_HISTORIES or FEAT: split ROLE_VIEW_ABSENCE_HISTORIES Conventional Commits I like Conventional Commits. Conventional Commits are a commit message format specification. Much of the value of Conventional Commits is in encouraging semantic commits that thoughtfully express carefully crafted units of meaning. Like Jeremy Mack, I think that taking care to compose single-thought semantic commits makes me a better programmer. Conventional Commits look like this: feat: turbocharge the whatsit That token at the front is the type, followed on the line by a super-brief description. This first line altogether is the title of the commit message. Conventional Commit messages have an optional body fix: correct the twinkle The twinkle was not previously astronomically correct; this fix corrects to a precision of six decimal places. Fixes #14 Conventional Commits thinks of the last part of the body as an optional footer. Conventional Commits can also express a scope, an area of the project where the change type is being applied. docs(song): note that carbon stars are sort-of diamonds in the sky Characterizing breaking changes in the body or footer Conventional Commits are meant to help with [Semantic Versioning][]. A release containing only backwards-compatible fixes like fix: tighten the goober would be a patch release (like 2.4.1). A minor release (like 2.5) introducing new features would include commits like feat: expose HRS URLs in the JSON API at /api/urls One is meant to be able to take a look at the commit log and thereby figure out what sort of Semantic Versioning bump is in order. An adopter faced with a major release is meant to be able to look at the commit history to inspect the breaking changes. Conventional commits of any type can be API-breaking changes. These changes occasion a major version change (5 to 6, say) in Semantic Versioning. An author notes the breakingness of a change (and advice for how clients of the library might adapt to the breaking change) in the body or footer of a Conventional Commit. So, fix: correct spelling of referrer in header BREAKING CHANGE: Rather than using misspelled \"Referer\" as name of header, instead use correct spelling \"Referrer\". Clients expecting \"Referer\" will no longer receive that header and will presumably not honor the new \"Referrer\" until updated to support this new name for this header. Improving Conventional Commits: signal the breakingness in the commit title There are contexts in which only the title and not the body of commit messages display, e.g. in GitHub’s presentation of a branch’s history or in some Git command line tooling. Which of these are breaking changes? fix: correct spelling of referrer in header fix: correct spelling of referrer in label fix: tighten the wingnut feat: bolt on the blender You can’t tell from the commit title. You’d have to look at the body of the message for each one to realize that e.g. the header spelling fix is a breaking change. I think Conventional Commits should be improved to reliably reflect the breakingness of change in the title of the commit rather than just in the body. There are a few ideas on how to do this: The sigil idea !fix: correct spelling of referrer in header A sigil is delightfully succinct. However, it might not be immediately apparent to a naive reader what meaning that ! is trying to convey. Question: how would a screen reader or other accessibility tool treat that sigil? The ALL-CAPS idea FIX: correct spelling of referrer in header This solution consumes zero characters. It’s also relatable in that ALL-CAPS ON THE INTERNET IS SHOUTING and that’s just the idea, to shout out the most important changes so that adopters can more readily identify the changes that are breaking their usages. I think it’s likely as readable and self-evident as a sigil, and it’s elegant that it consumes zero characters. However, Conventional Commits has not to date specified the capitalization of type. Some have argued for specifying the capitalization, or specifying that the capitalization is unspecified. In any case it’s the kind of thing developers might be inconsistent about. Any inadvertent ALL-CAPS commit messages will be false positives for this signal. Question: how well would a screen reader or other accessibility tool present the fact that the type is ALL-CAPS rather than lowercase? The prefix idea BREAK: fix: correct spelling of referrer in header I like this solution best. It consumes 7 characters, but it’s also more self-documenting, more readily apparent even to someone unfamiliar with Conventional Commits what it’s trying to say. Which commits are the breaking changes? Oh yeah, the ones that are shouting at me “BREAK”. Call to action I think that some (required!) way of indicating the breakingness of change in Conventional Commit titles should be specified. What is often the most important thing to say about a breaking-change commit shouldn’t be only in the body of the message. Maybe you have other ideas for how to convey breakingness in Conventional Commit commit titles. Maybe you have some expertise to offer about how screen readers and other accessibility tools would present the title under the different options under consideration. Maybe you like one of these ideas. Maybe you too don’t know which solution should be adopted but really wish Conventional Commits would go ahead and accept some solution so that identifying breaking changes in repositories using Conventional Commits will get easier sooner. Maybe you like the status quo just fine and don’t want to see Conventional Commit titles change for this. However you think this ought to play out, engage in GitHub to help make it happen. References and learn more Bookmarks about Conventional Commits Author: Andrew Petro",
    "tags": "Blog",
    "url": "/2018/07/07/indicate-breaks-in-conventional-commit-titles/"
  },

  
  
  
  {
    "title": "uPortal annual report, June 2018 edition",
    "text": "Apereo’s 2017-2018 annual report includes a section on uPortal, based on some notes the uPortal community put together. This post works from that content, evolving towards a more free-standing yet hyperlinked read. uPortal continues to lead as an open source enterprise portal solution by and for higher education. Calls to action Join uPortal’s Supporting Subscription program. Propose projects into the new uPortal Ecosystem Intake Process. Directly participate in uPortal. Engage in Apereo. Become an individual Apereo member. (These calls to action are re-stated with supporting detail in the conclusion.) Summary (The year described herein is 2017-05-01 through 2018-04-30). Growth: Growth of the uPortal-as-ecosystem idiom, with the uPortal-home software product successfully graduating from Apereo Incubation, and 4 new software products entering the ecosystem via a clarified Intake Process. Life: Almost 100 versioned releases of uPortal ecosystem software products. Participation: 7 new core contributors, 1 new core committer, calls, meetups, presentations, and list discussions, oh my. Financial responsibility: $26,000 recurring revenue with a $51,000 fund balance. Hope: to increase recurring revenue to sustainably fund effort transforming individual and institutional return-on-investment on uPortal participation and thereby encouraging a virtuous cycle towards more investment with better ROI encouraging more investment yielding better returns encouraging more investment yielding… Ecosystem A variety of software products complement the core platform to make up the greater uPortal ecosystem. uPortal further developed the ecosystem idiom this year, introducing a more formal uPortal Ecosystem Intake Process clarifying how to recognize projects as part of the ecosystem, ideally starting collaboration and openness at a very early stage in these ancillary software product initiatives. The ecosystem grew with 1 project successfully exiting Apereo Incubation (uPortal-home) and 4 new projects entering the ecosystem via the new Intake Process: ESUP-filemanager Soffit-kotlin-example uPortal-setup-scripts uPortal-web-components A new uPortal-contrib Github organization hosts projects upon intake. Releases The project continues to show healthy activity, with almost 100 versioned releases of software products within the ecosystem. Counting core, intook, and incubating software products (“software products in the uPortal ecosystem”), and not counting open source software products in the neighborhood but not formally part of the ecosystem: 97 total releases. uPortal core releases 22 releases (1 major, 7 patch, 1 release candidate, and 13 milestones) Alternative user interfaces uPortal-home: 13 releases (2 major, 6 minor, 5 patch) uPortal-app-framework: 16 releases (5 major, 5 minor, 6 patch) Portlet releases 9 Portlet software products saw at least one release, with 36 total releases. AnnouncementsPortlet: 10 releases. (1 minor, 9 patch) CalendarPortlet: 4 releases. (1 minor, 3 patch) FeedbackPortlet: 3 releases (1 minor, 2 patch) JasigWidgetPortlets: 1 minor release. NewsReaderPortlet: 7 releases. (1 major, 1 minor, 5 patch) NotificationPortlet: 6 releases. (2 minor, 4 patch) SimpleContentPortlet: 6 releases. (1 major, 3 minor, 2 patch) WeatherPortlet: 2 patch releases. WebProxyPortlet: 2 patch releases. Supporting software products Resource-server: 5 releases (2 minor, 3 patch) Participation The core uPortal platform project added 1 new committer (Jim Helwig 2017-07-19) and 7 new contributors, with 18 total contributors. This year saw an increase in direct participation by commmunity members in France, through submissions to the new Intake Process and translations of documentation. Contributors this year to core uPortal, new in bold: Ludovic Auxepaules Chris Beach Josh Brudnak Colin Campbell Christian Cousquer Nisith Dash Mairi Fraser Benito Gonzalez Allan Jackson KaJuan Johnson Christian Murphy Gary Roybal Andrew Petro Brandon Powell Corey Rowe Jonathan Tran Timothy Vertein Drew Wills (Note that this is counting committers and contributors in the core uPortal platform itself and does not account for contributors and committers in the other ecosystem projects.) Public engagement opportunities included 5 calls or webinars, 2 in-person meetups, 16 conference presentations, and over 1,000 discussion list posts. Newly introduced shared Google Team Drives welcome collaboration and sharing of artifacts in less source-code-centric ways. This tooling has already proven conducive to sharing local user research findings from uPortal adopters. uPortal handled one security vulnerability this year: 2017-09-26: Feedback portlet injectable fixed in Feedback Portlet 1.2.1. Aaron Grant, Drew Wills, and Christian Murphy filled roles in the security incident handling process. Financials Institutions can sustain the project through the uPortal Supporting Subscription program, a rider to the institutional Apereo membership. uPortal added 1 subscriber to a total of 3 with annual revenue of $26,000 and a fund balance of $51,000. Current uPortal Supporting Subscribers: University of Wisconsin-Madison (uPortal Champion) Oakland University (uPortal Booster) Brigham Young University (uPortal Friend) Thusfar the project has avoided spending these funds in ad-hoc ways, preferring to accumulate a stabilizing asset balance and work towards a level of recurring revenue that will enable a sustainable application of funds. In the year to come, the project hopes to reach a threshold of recurring revenue to afford funding a full-time Foundation position charged with driving down barriers to adoption and participation improving the institutional and individual return-on-investment in that participation. Improving the return-on-investment on adoption and participation will make adoption and participation more rewarding which will encourage more of it. More investment will create more opportunities to improve the return-on-investment. A virtuous cycle ensues. Challenges and opportunities Apereo as CVE numbering authority Formal vulnerability identifiers (CVE IDs) are prohibitively difficult to acquire. This limits effectiveness of communication about security. Apereo becoming a CVE Numbering Authority could reduce friction in and increase effectiveness of communication about security vulnerabilities. Measuring and recruiting adopters We do not have an effective way to measure adopters. There are doubtless unrealized opportunities to draw in adopters as Apereo institutional members, uPortal supporting subscription subscribers, and most importantly as collaborators in the uPortal ecosystem. Growing the uPortal ecosystem The growth of the intake, contrib, ecosystem, and attic concepts and processes sets the stage to more clearly welcome, characterize, collaborate within, and communicate about projects in the uPortal ecosystem. Sustainably converting uPortal Supporting Subscription revenue to forward progress Hitting recurring revenue thresholds would unlock converting revenue to forward progress yielding a return-on-investment for subscribers which might encourage additional investment, a virtuous and sustainable cycle ensuing. Discourse as superior discussion forums solution Discourse has been adopted elsewhere to positive effect and might do a lot of good in Apereo as a next step beyond the exising Google Groups forums solution. Collaborate with other Apereo projects uPortal and other Apereo projects might collaborate more on shared concerns like project lifecycle process security incident handling communications release engineering doing these and other things better in collaboration than they can be done in isolated project siloes. Calls to action, reprise uPortal adopting institutions, join uPortal’s Supporting Subscription program. This rider to an institutional Apereo membership builds essential recurring revenue for resourcing the uPortal project for confident sustainability. Begin this as modestly as your institution may need; every little bit will help this program hit the transformative threshold of potentially adding a full time staffer focused on carrying uPortal qua open source project forward. If your institution is already subscribing, increase your commitment. The opportunities for a more confident uPortal future are real. Propose ancillary projects (software products) into uPortal’s new Ecosystem Intake Process. It has never been easier to approach developing a plug-in for use with uPortal (whether user-facing content, back-end service, or otherwise). The best time to share code and welcome involvement of the wider community is the moment you start. If you locally see a need, it’s very likely that another adopter could learn from this, could collaborate upon it, or could adopt the add-on and likewise has locally developed add-ons that you could be adopting too. The opportunities for more and better collaboration are real. Directly participate in uPortal. It has never been easier to collaborate on uPortal, its documentation, and its ancillary projects. Suggesting an edit to even this “marketing-flavored” post is feasible via GitHub’s tooling, without leaving your Web browser. The opportunities for collaboration are real, and are beyond code. Engage in Apereo. Ensure your institution is a member of Apereo. Maintain an active relationship with your institutional representative. Engage directly on the open@ list and ensure you’re subscribed to the announcements@ list. The opportunities for participation in all things Apereo are real. Become an individual Apereo member. Apereo’s membership model is no longer solely that of higher education institutions as members – you as an individual human being can join, gaining a vote for a Foundation Board seat. The opportunities to engage in more interesting ways are real. - Andrew Petro wearing individual contributor hat.",
    "tags": "uPortal Apereo",
    "url": "/2018/06/25/up-annual-report/"
  },

  
  
  
  {
    "title": "One Can Only Hope in Buchistan",
    "text": "A true story inspired by real events. Seriously. Bryan Cranston has been approached for the role of “Some”. United Nations Strategic Alliance Hotline. How may I help you? Hi there. This is Some Person and I am calling to share some valuable suggestions about the desperate state of Buchistan with you. Is this the right line? Certainly. What seems to be your concern? I don’t know if you are keeping tabs on this, but Buchistan is in complete disarray. Crime is rampant and deadly infectious diseases are widespread. People… If you would allow me a quick mome… …are starving and wildlife habitat is miserably endangered. Natural resources are at an all-time low. Sigh…I am really not sure how I am supposed to… If I could ask for your… …take my enterprise family to production…I mean…vacation next month with all this misery. The entire state of affairs in Buchistan is like one horror show after another; the very real combination of all Black Mirror episodes combined into one giant pile of despondent torturous anguish looping through for all eternity. What is being done about this? We are pulling all our resources into resolving issues. In fact, there is a great website with instructions on how you can get invo… My apologies; I simply have no time or energy to spare here. Just wanted to share notes and let you know that I will not be considering Buchistan for any joyous excursions unless and until such issues are handled. Understood; thank you Some. I can assure you that all concerns are being reviewed. We will have more news on this later. Ah, that is so wonderful to hear. When? Some time. #HappyFriday Misagh Moayyed",
    "tags": "Blog",
    "url": "/2018/06/22/united-nations-buchistan/"
  },

  
  
  
  {
    "title": "Apereo CAS - Extending Webflows",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Unlike previous versions, CAS 5 attempts to automate all required Spring Webflow changes on a per-module basis. In this new model, all one should have to do is to declare the appropriate module in the build script…and viola! CAS will take care of the rest. If you wish to learn how that is done internally and furthermore, how you may take advantage of the same approach to extend CAS webflows and introduce your own, this is the right post for you. This tutorial specifically requires and focuses on: CAS 5.3.x Java 8 Maven WAR Overlay This post might equally apply to CAS 5.2.x. YMMV. To learn the same answers with CAS 5.0.x, please see this post. Webflow Configurers Every CAS module that needs to dynamically augment the Spring Webflow routes simply takes on the following form: package com.example.cas; public class SomethingWebflowConfigurer extends AbstractCasWebflowConfigurer { public SomethingWebflowConfigurer(final FlowBuilderServices flowBuilderServices, final FlowDefinitionRegistry loginFlowDefinitionRegistry, final ApplicationContext applicationContext, final CasConfigurationProperties casProperties) { super(flowBuilderServices, loginFlowDefinitionRegistry, applicationContext, casProperties); } @Override protected void doInitialize() throws Exception { final Flow flow = super.getLoginFlow(); // Magic happens; Call 'super' to see what you have access to... } } CAS modules register their WebflowConfigurer instances in @Configuration classes: package com.example.cas; @Configuration(\"SomethingConfiguration\") public class SomethingConfiguration implements CasWebflowExecutionPlanConfigurer { @Autowired @Qualifier(\"loginFlowRegistry\") private FlowDefinitionRegistry loginFlowDefinitionRegistry; @Autowired private FlowBuilderServices flowBuilderServices; @Autowired private ApplicationContext applicationContext; @Autowired private CasConfigurationProperties casProperties; @ConditionalOnMissingBean(name = \"somethingWebflowConfigurer\") @Bean public CasWebflowConfigurer somethingWebflowConfigurer() { return new SomethingWebflowConfigurer(flowBuilderServices, loginFlowDefinitionRegistry, applicationContext, casProperties); } @Override public void configureWebflowExecutionPlan(final CasWebflowExecutionPlan plan) { plan.registerWebflowConfigurer(somethingWebflowConfigurer()); } } Note that each CasWebflowConfigurer implementation may be assigned a specific order which is a numeric weight that determines its execution position once webflow auto-configuration kicks into action. RememberIf you are looking for XML flow definitions to extend CAS, you are simply holding it wrong. While you may be creative enough to find a solution and make that approach work, it is pretty much guaranteed that your design will break quite quickly in the next upgrade. Next, we just need to ensure that CAS is able to pick up our special configuration. To do so, create a src/main/resources/META-INF/spring.factories file and reference the configuration class in it as such: org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.example.cas.SomethingConfiguration …and that should be it. So… CAS itself handles Spring Webflow changes related to its first-class features by default automatically. That strategy equally applies, should you need to write your own configurers if you absolutely need to. Be sure to take extra as accidents may happen. What if you have two WebflowConfigurers who all decide to inject actions and state into the same Spring Webflow areas? What if multiple WebflowConfigurers are competing to set themselves up as starting points of the CAS webflow? Who wins, who mourns? Indeed, these are questions you ought to be thinking about as a developer. With power comes responsibility. Remember Changes are all scoped to one technology, that is Java. You have the full power of Java to dynamically augment the Spring Webflow as you see fit. Your changes are all self-contained. Unlike XML, your changes are now part of the CAS APIs. If you upgrade and something breaks, you will be notified immediately at build time. That’s all. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/06/19/cas53webflow-extensions/"
  },

  
  
  
  {
    "title": "Apereo CAS - Administrative Endpoints &amp; Monitoring",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. CAS, being a Spring-Boot application at heart, includes a number of additional features to help you monitor and manage the server when it’s pushed to production. You can choose to manage and monitor the deployment using HTTP endpoints, referred to as actuators. This tutorial provides a basic overview of the endpoints provided by both Spring Boot and CAS and also provides instructions on how such endpoints can be secured for access and win. This tutorial specifically requires and focuses on: CAS 5.3.x Java 8 CLI JSON Processor jq Maven WAR Overlay Actua…What? In essence, actuator endpoints bring production-ready features to CAS. Monitoring a running CAS instance, gathering metrics, understanding traffic or the state of our database becomes trivial with such endpoints. The main benefit of these endpoints is that we can get production grade tools without having to actually implement these features ourselves. Actuators are mainly used to expose operational information about the running application – health, metrics, info, dump, env, etc. These are HTTP endpoints or JMX beans to enable us to interact with it. DefinitionAn actuator is a manufacturing term, referring to a mechanical device for moving or controlling something. Actuators can generate a large amount of motion from a small change. The full list of endpoints provided to your CAS deployment is posted here. Note that you do not need to do anything extra special to get these endpoints added to your deployment; these are all available by default and just need to be turned on and secured for access. Endpoints Each endpoint, whether provided by CAS or Spring Boot, is generally given two special properties: enabled: Turn on the endpoint and make it available for access by outsiders. sensitive: Determines whether endpoint security should be controlled via the likes of Spring Security with extra configuration. So as an example, if you wish to turn on the status endpoint in CAS you need to simply turn on the following settings: cas.monitor.endpoints.status.enabled=true cas.monitor.endpoints.status.sensitive=false What the above settings indicate is that the status endpoint should be turned on at runtime and it’s one whose security is NOT controlled by the Spring Security library. SensitivityThe sensitive flag is a rather loaded and confusing term presented by the Spring Boot library that has since been revamped and redesigned, starting with Spring Boot v2. It's quite possible that once and if CAS switches Spring Boot v2, the above property pair get cleaned up too. So in summary, access to our status endpoint above is purely dictated by CAS itself which by default is controlled by an IP pattern. So here’s a rule that allows access to all CAS endpoints from everywhere: cas.adminPagesSecurity.ip=.+ Once you have the above in place, simply open up a command prompt and execute: # You might need the -k flag if the server's certificate is untrusted... $ curl https://login.example.org/cas/status Health: UP Host: misaghmoayyed Server: https://login.example.org Version: 5.3.0 Troubleshooting For easier diagnostics, you need to turn on the following logging configuration in your log4j2.xml file: &lt;AsyncLogger name=\"org.pac4j\" level=\"debug\" additivity=\"false\"&gt; &lt;AppenderRef ref=\"console\"/&gt; &lt;AppenderRef ref=\"file\"/&gt; &lt;/AsyncLogger&gt; &lt;AsyncLogger name=\"org.springframework.security\" level=\"debug\" additivity=\"false\"&gt; &lt;AppenderRef ref=\"console\"/&gt; &lt;AppenderRef ref=\"file\"/&gt; &lt;/AsyncLogger&gt; …which then help you diagnose issues if access to an endpoint is blocked with: cas.adminPagesSecurity.ip=192\\.168\\.3\\.1 …and then when you run: $ curl https://login.example.org/cas/status | jq …you might get: { \"timestamp\": 1529124120075, \"status\": 401, \"error\": \"Unauthorized\", \"message\": \"No message available\", \"path\": \"/cas/status\" } …where the logs would indicate: INFO [IpClient] - &lt;Failed to retrieve or validate credentials: Unauthorized IP address: 0:0:0:0:0:0:0:1&gt; DEBUG [IpClient] - &lt;Failed to retrieve or validate credentials&gt; org.pac4j.core.exception.CredentialsException: Unauthorized IP address: 0:0:0:0:0:0:0:1 at org.pac4j.http.credentials.authenticator.IpRegexpAuthenticator.validate... Endpoint Security CAS endpoints prior to the adoption of Spring Boot and family (i.e. CAS v4 and priors) were always protected by an IP pattern which more or less was a regular expression pattern. Today and by default, this same protection mechanism is kept as well where all CAS endpoints are considered disabled whose security is exclusively controlled by the IP pattern noted above. In other words, in the event that access to an endpoint is allowed, (i.e endpoint is enabled and is not marked as sensitive), CAS will attempt to control access by enforcing rules via IP address matching, delegating to itself, etc. Note that while almost all CAS endpoints can be secured via other means (such as a CAS server), the /status endpoint is always protected by an IP pattern allowing monitoring and CLI tools to easily query the endpoint from a protected recognized IP address. Let’s Boot As an exercise, let us enable the Spring Boot’s health &amp; info endpoints and compare them with CAS’ own status endpoint. We are also going to secure the health endpoint using the Spring Security library by taking advantage of the basic authentication scheme. So, the first order of business is to simply enable the endpoints: cas.adminPagesSecurity.ip=192\\.168\\.3\\.1 endpoints.health.enabled=true endpoints.health.sensitive=false endpoints.info.enabled=true endpoints.info.sensitive=false …and with executing a request from a trusted IP address that would match the above pattern: $ curl https://login.example.org/cas/status/health | jq …we shall receive: { \"status\": \"UP\" } …or we can try the info endpoint too: $ curl https://login.example.org/cas/status/info | jq …which results in a lot of information, summarized here for sanity: \"cas\": { \"version\": \"5.3.0\", \"java\": { \"home\": \"../jdk1.8.0_171.jdk/Contents/Home/jre\", \"version\": \"1.8.0_171\", \"vendor\": \"Oracle Corporation\" } }, \"description\": \"CAS\", ... Nice. Two questions: How could we get more information from the health endpoint? Weren’t we going to enable basic authentication for some of these endpoints? What happened there? Let’s Health According to the documentation, the health endpoint shows application health information (when the application is secure, a simple “status” when accessed over an unauthenticated connection or full message details when authenticated). That has been the case since our requests are not exactly authenticated. We have simply honored the IP rules when submitting requests but we need to take this one step further and ask for credentials. Fancier modes of authenticating requests to such endpoints are provided by Spring Security (a library Spring Boot depends upon to auto-configure the access rules for endpoints marked as sensitive). So, let’s get that configured. RememberRegardless of your method of authentication, the IP access rules are always in effect and do not back off once you turn on Spring Security and family. If you need the IP access restrictions to go away, simply open up the pattern to allow .+ where that would allow you to exclusively rely upon the protection offered by Spring Boot and its authentication strategy. The first task is to configure our CAS overlay to include the relevant dependency: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp-config-security&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; …and then, mark the endpoint as sensitive in our CAS properties: endpoints.health.enabled=true endpoints.health.sensitive=true Next order of business is to define our master credentials that would be asked of all requests. Note that if the password is left blank, a random password will be generated/printed in the logs by default. We can define our own using the following: security.user.name=wade security.user.password=de@dp00L With the above settings, if you try the same request as before: $ curl https://login.example.org/cas/status/health | jq …you might see the following: { \"timestamp\": 1529126720131, \"status\": 401, \"error\": \"Unauthorized\", \"message\": \"Full authentication is required to access this resource\", \"path\": \"/cas/status/health\" } So we need to be fully authenticated. Let’s present credentials: $ curl -u wade:de@dp00L https://login.example.org/cas/status/health | jq …and the full output shall then be something as follows where CAS presents some additional health information regarding session and memory which correspond to its own health indicators monitoring the runtime memory status as well as the ticket registry repository: { \"status\": \"UP\", \"memory\": { \"status\": \"UP\", \"freeMemory\": 3006834288, \"totalMemory\": 3817865216 }, \"session\": { \"status\": \"UP\", \"sessionCount\": 0, \"ticketCount\": 0, \"message\": \"OK\" }, \"diskSpace\": { \"status\": \"UP\", \"total\": 500068036608, \"free\": 115889942528, \"threshold\": 10485760 }, \"refreshScope\": { \"status\": \"UP\" } } …and if you happen to submit an incorrect authentication request with bad credentials, you might be presented with: { \"timestamp\": 1529127019737, \"status\": 401, \"error\": \"Unauthorized\", \"message\": \"Bad credentials\", \"path\": \"/cas/status/health\" } Of course, this is just basic authentication with a pre-defined pair of credentials. You can get the endpoints secured with a CAS server as well, or you can try basic authentication with an underlying account store backed by LDAP or JDBC…or as always, you can take full advantage of Spring Security in all its glory and design your authentication scheme for the win. Looking Ahead As an FYI, as of this writing, the CAS version at hand depends on Spring Boot 1.5.x to deliver endpoints and get them secured. Starting with Spring Boot v2, there is no separate auto-configuration for user-defined endpoints and actuator endpoints. Security is strictly controlled and provided by Spring Security if the library is included in CAS and found on the classpath whereby the auto-configuration secures all endpoints by default. Spring Boot then relies on Spring Security’s content-negotiation strategy to determine whether to use a basic authentication mode or form-based login and just like before, a user with a default username and generated password is added, which can be used to log in. All of that is to say, endpoint security is one area that might get heavily refactored and redesigned in the future once CAS upgrades to Spring Boot v2. This would basically affect CAS configuration in the way that enabled or sensitive properties are defined; they might get removed or renamed, etc. There will be follow-up announcements and notes on the subject once the upgrade is available in due time and for now. Monitors CAS monitors may be defined to report back the health status of the ticket registry and other underlying connections to systems that are in use by CAS. Spring Boot offers a number of monitors known as HealthIndicators that are activated given the presence of specific settings (i.e. spring.mail.*). CAS itself provides a number of other monitors based on the same component whose action may require a combination of a particular dependency module and its relevant settings. As you saw in the output of the health endpoint, the default monitors report back brief memory and ticket stats. As an exercise, we shall configure CAS to monitor and report health information on the status of a mail server (the monitor is provided by Spring Boot natively) and we may also let CAS monitor the status of an LDAP server provided where the monitor is this time brought to you by CAS. Mail Server Monitor First, let’s get the mail server configured in CAS: spring.mail.host=localhost spring.mail.port=25000 spring.mail.testConnection=true With the above settings, at runtime CAS begins to create and bootstrap components that need to deal with a mail server and just as well, a special health monitor will get auto-configured to watch the server status and report back results via the health endpoint. Saving LivesThis is the power of auto-configuration, saving you time and energy and abstracting you away from all the confusing internal details. Talk about improving productivity and saving lives, the entire configuration of a mail server connector as well as its relevant monitor is done using just a few simple settings! So, let’s get us a health report: $ curl -u wade:de@dp00L https://login.example.org/cas/status/health | jq …and we shall receive the same sort of report except for this time we have a small blob for mail: ... \"mail\": { \"status\": \"UP\", \"location\": \"localhost:25000\" }, ... …and if you shut the server down, you might receive: ... \"mail\": { \"status\": \"DOWN\", \"location\": \"localhost:25000\", \"error\": \"com.sun.mail.util.MailConnectException: Couldn't connect to host, port: localhost, 25000; timeout -1\" }, ... LDAP Monitor First, let’s add the following dependency to ensure CAS can connect to an LDAP server: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-ldap-monitor&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; …and let’s teach CAS where our LDAP server lives: cas.monitor.ldap.ldapUrl=ldap://localhost:389 cas.monitor.ldap.useSsl=false Use What You NeedDo NOT copy/paste the entire collection of LDAP settings, etc into your CAS configuration; rather pick only the properties that you need. If you do not know what a setting does or means, it's generally safe to ignore it and trust the defaults. This is similar to ordering food; if you have never tried jellyfish, it would be fairly adventurous or dangerous to put that in your burger! Go with what you know and adjust as necessary. So, once again let’s get us a health report: $ curl -u wade:de@dp00L https://login.example.org/cas/status/health | jq …and we shall receive the same sort of report except for this time we have a small blob for pooledLdapConnectionFactory: ... \"pooledLdapConnectionFactory\": { \"status\": \"UP\", \"message\": \"OK\", \"activeCount\": 0, \"idleCount\": 3 }, ... Additional monitors and health indicators may get added in future CAS versions. Consult the CAS documentation for more info. What About…? CAS WAR Overlays CAS Multifactor Authentication with Duo Security CAS 5 LDAP AuthN and Jasypt Configuration CAS 5 SAML2 Delegated AuthN Tutorial CAS User Interface Customizations CAS Multifactor Authentication with Google Authenticator So… It’s important that you start off simple and make changes one step at a time. Once you have a functional environment, you can gradually and slowly add customizations to move files around. I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/06/15/cas53-admin-endpoints-security/"
  },

  
  
  
  {
    "title": "Apereo CAS - Custom Authentication &amp; Attribute Sources",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. While authentication support in CAS for a variety of systems is somewhat comprehensive and complex, a common deployment use case is the task of designing custom authentication schemes. This post: Describes the necessary steps needed to design and register a custom authentication strategy (i.e. AuthenticationHandler). Provides an implementation overview of designing customized attribute repository sources (i.e. IPersonAttributeDao) to fetch user claims. Audience This post is intended for Java developers with a basic-to-medium familiarity with Spring, Spring Boot, and Spring Webflow. This is NOT a tutorial to be used verbatim via copy/paste. It is instead a recipe for developers to extend CAS based on specialized requirements. This tutorial specifically requires and focuses on: CAS 5.3.x Java 8 Maven WAR Overlay Customized Authentication The overall tasks may be categorized as such: Design the authentication handler Register the authentication handler with the CAS authentication engine. Tell CAS to recognize the registration record and authentication configuration. CollaborateBefore stepping into a development mode, consider whether your choice of authentication handler or attribute repository implementation may be contributed back to CAS as a first-class feature, specially if the system with which you are interfacing is somewhat mainstream, robust and in reasonable demand. Design Authentication Handlers The first step is to define the skeleton for the authentication handler itself. This is the core principal component whose job is to declare support for a given type of credential only to then attempt to validate it and produce a successful result. The core parent component from which all handlers extend is the AuthenticationHandler interface. With the assumption that the type of credentials used here deal with the traditional username and password, noted by the infamous UsernamePasswordCredential below, a more appropriate skeleton to define for a custom authentication handler may seem like the following: public class MyAuthenticationHandler extends AbstractUsernamePasswordAuthenticationHandler { ... protected HandlerResult authenticateUsernamePasswordInternal(final UsernamePasswordCredential credential, final String originalPassword) { if (everythingLooksGood()) { return createHandlerResult(credential, this.principalFactory.createPrincipal(username), new ArrayList&lt;&gt;()); } throw new FailedLoginException(\"Sorry, you have failed!\"); } ... } Note that: Authentication handlers have the ability to produce a fully resolved principal along with attributes. If you have the ability to retrieve attributes from the same place as the original user/principal account store, the final Principal object that is resolved here must then be able to carry all those attributes and claims inside it at construction time. The last parameter, new ArrayList&lt;&gt;(), is effectively a collection of warnings that are eventually worked into the authentication chain and conditionally shown to the user. Examples of such warnings include password status nearing an expiration date, etc. Authentication handlers also have the ability to block authentication by throwing a number of specific exceptions. A more common exception to throw back is FailedLoginException to note authentication failure. Other specific exceptions may be thrown to indicate abnormalities with the account status itself, such as AccountDisabledException. Various other components such as PrincipalNameTransformers, PasswordEncoders and such may also be injected into our handler if need be, though these are skipped for now in this post for simplicity. Register Authentication Handlers Once the handler is designed, it needs to be registered with CAS and put into the authentication engine. This is done via the magic of @Configuration classes that are picked up automatically at runtime, per your approval, whose job is to understand how to dynamically modify the application context. So let’s design our own @Configuration class: package com.example.cas; @Configuration(\"MyAuthenticationEventExecutionPlanConfiguration\") @EnableConfigurationProperties(CasConfigurationProperties.class) public class MyAuthenticationEventExecutionPlanConfiguration implements AuthenticationEventExecutionPlanConfigurer { @Autowired private CasConfigurationProperties casProperties; @Bean public AuthenticationHandler myAuthenticationHandler() { final MyAuthenticationHandler handler = new MyAuthenticationHandler(); /* Configure the handler by invoking various setter methods. Note that you also have full access to the collection of resolved CAS settings. Note that each authentication handler may optionally qualify for an 'order` as well as a unique name. */ return h; } @Override public void configureAuthenticationExecutionPlan(final AuthenticationEventExecutionPlan plan) { if (feelingGoodOnASundayMorning()) { plan.registerAuthenticationHandler(myAuthenticationHandler()); } } } Register Configuration Now that we have properly created and registered our handler with the CAS authentication machinery, we just need to ensure that CAS is able to pick up our special configuration. To do so, create a src/main/resources/META-INF/spring.factories file and reference the configuration class in it as such: org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.example.cas.MyAuthenticationEventExecutionPlanConfiguration Note that the configuration registration step is not of CAS doing. It’s a mechanism provided to CAS via Spring Boot and it’s an efficient way to pick up and register components into the runtime application context without the additional overhead of component-scanning and such. At runtime, CAS will try to automatically detect all components and beans that advertise themselves as AuthenticationEventExecutionPlanConfigurers. Each detected AuthenticationEventExecutionPlanConfigurer is then invoked to register its own authentication execution plan. The result of this operation at the end will produce a ready-made collection of authentication handlers that are ready to be invoked by CAS in the given order defined if any. Customized Attribute Repository Sometimes the method of authentication at hand is unable to produce user attributes, or perhaps you may want to fetch user claims and attributes from a variety of other sources and combine them with the what’s fetched from the authentication source. In either scenario, CAS provides a separate component called Attribute Repository whose task to establish a link between CAS and the real attribute source and its execution is simply tied to the authentication flow somewhat invisibly. There are a lot of attribute repository options supported in CAS by default, and if support for your particular attribute source is absent in CAS, you can certainly build support for that system using the following instructions. Design Attribute Repository Attribute repository implementations need to be based on top of the Person Directory project, which is a toolkit for resolving persons and attributes from a variety of underlying sources. It consists of a collection of IPersonAttributeDaos that retrieve, cache, resolve, aggregate and merge person attributes. The following represents a simple outline of a given attribute repository implementation: package com.example.cas; public class FancyPersonAttributeDao extends BasePersonAttributeDao { private final IUsernameAttributeProvider usernameAttributeProvider = new SimpleUsernameAttributeProvider(); @Override @SneakyThrows public IPersonAttributes getPerson(final String uid) { /* Stuff happens to contact the downstream system and fetch attributes for [uid]... */ return new CaseInsensitiveNamedPersonImpl(uid, attributes); } @Override public Set&lt;IPersonAttributes&gt; getPeople(final Map&lt;String, Object&gt; map) { return getPeopleWithMultivaluedAttributes(stuffAttributesIntoList(map)); } @Override public Set&lt;IPersonAttributes&gt; getPeopleWithMultivaluedAttributes(final Map&lt;String, List&lt;Object&gt;&gt; map) { final Set&lt;IPersonAttributes&gt; people = new LinkedHashSet(); final String username = this.usernameAttributeProvider.getUsernameFromQuery(map); final IPersonAttributes person = this.getPerson(username); if (person != null) { people.add(person); } return people; } @Override public Set&lt;String&gt; getPossibleUserAttributeNames() { ... } @Override public Set&lt;String&gt; getAvailableQueryAttributes() { ... } } Register Attribute Repository Once the repository is designed, it needs to be registered with CAS and put into the runtime engine. This is done via the magic of @Configuration classes that are picked up automatically at runtime, per your approval, whose job is to understand how to dynamically modify the application context. To do this, we can reuse the configuration class as above to declare our IPersonAttributeDao bean: @ConditionalOnMissingBean(name = \"fancyPersonAttributeDao\") @Bean public IPersonAttributeDao fancyPersonAttributeDao() { return new FancyPersonAttributeDao(...); } Note that each attribute repository implementation may be assigned a specific order which is a numeric weight that determines its execution position once attribute resolution kicks into action. This is a bit you can usually ignore, but it becomes rather important if you decide to design multiple repository implementations whose execution depends on one another’s results. (i.e one repository might need an attribute value from another before it can run its own query). So, once defined we can register it with CAS inside the same configuration class: @ConditionalOnMissingBean(name = \"fancyAttributeRepositoryPlanConfigurer\") @Bean public PersonDirectoryAttributeRepositoryPlanConfigurer fancyAttributeRepositoryPlanConfigurer() { return new PersonDirectoryAttributeRepositoryPlanConfigurer() { @Override public void configureAttributeRepositoryPlan(final PersonDirectoryAttributeRepositoryPlan plan) { if (mustRegisterAttributeRepositoryForTheWin()) { plan.registerAttributeRepository(fancyPersonAttributeDao()); } } }; } Of course, if you decide to move the definition and registration steps into a separate @Configuration class, then the location of that component will need to be taught to the runtime using the same src/main/resources/META-INF/spring.factories file noted above. What About…? CAS Multifactor Authentication with Duo Security CAS 5 LDAP AuthN and Jasypt Configuration CAS 5 SAML2 Delegated AuthN Tutorial CAS 5 Linking Accounts with Delegated AuthN CAS Multifactor Authentication with Google Authenticator So… It’s important that you start off simple and make changes one step at a time. Once you have a functional environment, you can gradually and slowly add customizations to move files around. I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/06/12/cas53-authn-handlers/"
  },

  
  
  
  {
    "title": "Apereo CAS - User Interface Customizations",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Overview When it comes to implementing CAS user interface customizations, there are many options and strategies one can use to deliver a unique user experience. There are ways one can customize the default views to overlay changes top of provided HTML files. These views may then be customized and loaded from a variety of locations, and just as well, could be themed using both static and dynamic strategies either globally or on a per-application basis. In this post, we shall review such customization strategies at a high-level, and also touch upon developer tools and methods that allow the changes to quickly go into effect and get deployed. Our starting position is based on the following: CAS 5.3.0 Java 8 Maven Overlay Setup Let’s assume that application registration records are going to be managed as flat JSON files: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-json-service-registry&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; Next, you must teach CAS how to load JSON registration records from disk. This is done in the cas.properties file: cas.serviceRegistry.initFromJson=false cas.serviceRegistry.json.location=file:/etc/cas/services …where a sample ApplicationName-1001.json would then be placed inside /etc/cas/services: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://app.example.org\", \"name\" : \"ApplicationName\", \"id\" : 1001, \"evaluationOrder\" : 10 } Fairly simple, thus far. Now, let’s customize the user interface. Overlaying Views CAS application views are found at src/main/resources/templates which is a location within the CAS web application itself. In order to modify the CAS HTML views, each view file first needs to be brought over into the overlay. You can use the build.sh listviews command to see what HTML views are available for customizations. Note that CAS views are broken up into smaller fragments, allowing you to customize and change specific portions of a particular page if needed. At any rate, once the file is chosen simply use build.sh getview $NAME to bring the $NAME view into your overlay: $ build.sh getview footer.html Exploded the CAS web application file. Searching for view name footer.html... Found view(s): /cas-overlay-template/target/cas/WEB-INF/classes/templates/fragments/footer.html Created view at /cas-overlay-template/src/main/resources/templates/fragments/footer.html /cas-overlay-template/src/main/resources/templates/fragments/footer.html Now that you have the footer.html brought into the overlay, you can simply modify the file at cas-overlay-template/src/main/resources/templates/fragments/footer.html to introduce your own footer-related changes, and then get the CAS web application deployed to finesse. Deploying Views The quickest way to test such changes is by using the bootrun command: $ build.sh bootrun This command simply runs the CAS web application in an isolated sandboxed mode where local resources such as HTML, CSS, Javascript and other components are watched and reloaded dynamically when changes are detected. In our above example, you can continue to make changes to the footer.html file and keep refreshing the browser to see the change in action. The CAS WatchFiles must exist in the overlay before they can be watched. If you add a new local resource into the overlay, you may need to run the bootrun command again so the file becomes watchable. Note that view definitions and files are by default cached where the file content is processed and rendered once and then cached for maximum performance. If you wish for changes to be picked up automatically, you do need to disable the cache via the following setting in your cas.properties file: spring.thymeleaf.cache=false Externalized Views Spring Boot The location of CAS views is by default expected to be found at src/main/resources/templates which is the sort of behavior controlled and provided by Spring Boot. This location can be controlled using the following setting: spring.thymeleaf.prefix=classpath:/templates/ This instructs CAS to locate views at the specified location. This location can be externalized to a directory outside the cas web application. Via this option, all CAS views are expected to be found at the specified location and there is no fallback strategy. (Note that multiple prefixes may be specified in comma-separated syntax). CAS As a native CAS feature, Views and HTML files also may be externalized outside the web application conditionally and individually, provided the external path via CAS settings is defined. If a view template file is not found at the externalized path, the default one that ships with CAS will be used as the fallback. cas.view.templatePrefixes[0]=file:///etc/cas/templates With the above setting, I can try the following command to let CAS pick up the footer.html file from the above location: mv src/main/resources/templates/fragments /etc/cas/templates Of course, changes should continue to get picked up and deployed dynamically just like before! RESTful Views CAS views may also be 100% externalized using a REST API of your own implementation. You will be tasked to design an API endpoint which CAS may contact in order to resolve a particular view specified using a request header. Upon a successful 200 status result, the response body of the endpoint is expected to contain the HTML view that will be rendered by CAS in the browser. To activate RESTful resolution of views, specify the URL endpoint in your CAS properties: cas.view.rest.url=https://rest.somewhere.org/userinterface Default Service URL In the event that no service is submitted to CAS, you may specify a default service URL to which CAS will redirect. Note that this default service, much like all other services, MUST be authorized and registered with CAS and is taught to CAS using the following setting: cas.view.defaultRedirectUrl=https://www.github.com Of course, you can also the opposite of this behavior which is to disallow CAS to accept authentication requests if no service parameter is provided: cas.sso.allowMissingServiceParameter=false Localization The CAS Web application includes a number of localized message files for a variety of languages. While the user interface reacts dynamically as locale is detected automatically, you may forcefully switch the locale and localize the contents of the page using the locale parameter. For example, the following URL: https://cas.server.edu/login?locale=it …allows CAS to render the page using the Italian language. RememberNote that not all languages are complete and accurate across CAS server releases as translations are entirely dependent upon community contributions. For an accurate and complete list of localized messages, always refer to the English language bundle. The default language bundle is for the English language and is thus called messages.properties found at src/main/resources which you may need to pull into your own overlay but there may be an easier option. If there are any custom messages that need to be presented into views, they may also be formatted under custom_messages.properties files which allow you to both defined custom messages as well as those by CAS that need to be overwritten. So this means I can simply create the language bundle for custom changes: touch src/main/resources/custom_messages.properties …and then add the following messages: # CAS provided message cas.login.resources.contribguide=Contribute &amp; Engage # Custom message my.custom.messaage=Hello, World! The first key is picked and used by CAS automatically since it’s referenced in the main login view. The second key, however, is a custom one specific to the deployment at hand that needs to be pulled into the CAS overlay and relevant views. For simplicity, let’s modify the same footer.html file we externalized to display this text: ... &lt;footer th:fragment=\"footer\" class=\"footer\" role=\"contentinfo\"&gt; &lt;div class=\"container\"&gt; &lt;span id=\"copyright\" th:utext=\"#{copyright}\"&gt;&lt;/span&gt; &lt;span th:utext=\"#{my.custom.messaage}\"&gt;This is the text&lt;/span&gt; &lt;/div&gt; &lt;/footer&gt; ... Now, if CAS is actively rendering the footer.html view then the text linked to the my.custom.message is displayed. But surely, you can view the HTML page directly inside a browser window without running CAS in which case you get the sample dummy text This is the text. By default, message bundles are expected to be found at src/main/resources and are cached just like the views. Let’s make sure the cache is disabled so that our changes to the message bundle can be picked up automatically: cas.messageBundle.cacheSeconds=0 Themes CAS deployers are now able to switch the themes based on different services. For example, you may want to have different login screens (different styles) for staff applications and student applications. Or, you want to show two layouts for daytime and night time. This document could help you go through the basic settings to achieve this. Themes are generally defined statically either embedded with the CAS web application or externalized outside, and there are a number of strategies one can use to activate, trigger and switch to a theme. Static Themes CAS is configured to decorate views based on the theme property of a given registered service in the Service Registry. The theme that is activated via this method will still preserve the default views for CAS but will simply apply decorations such as CSS and Javascript to the views. The physical structure of views cannot be modified via this method. To achieve this, add a dracula.properties placed to the root of src/main/resources folder. Contents of this file should match the following: cas.standard.css.file=/themes/dracula/css/cas.css cas.javascript.file=/themes/dracula/js/cas.js cas.admin.css.file=/themes/dracula/css/admin.css Once you have created the above /themes/dracula directory structure with your own CSS and Javascript files, activate the theme for a relevant application in the registry: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://app.example.org\", \"name\" : \"ApplicationName\", \"id\" : 1001, \"evaluationOrder\" : 10, \"theme\": \"dracula\" } To see the theme in action, navigate to https://sso.example.edu/cas/login?service=https://app.example.org. Themed Views CAS can also utilize a service’s associated theme property to selectively choose which set of UI views will be used to generate the standard views (i.e. casLoginView.html, etc). This is especially useful in cases where the set of pages for a theme that is targeted for a different type of audience are entirely different structurally, such that simply using a simple theme is not practical. So far, we have only seen basic CSS and Javascript files associated with a theme but what if you wanted the dracula theme activated for a service to present a different footer? Surely, the capabilities of a theme must go beyond CSS and Javascript, right? Is that possible? Yes. Views associated with a particular theme by default are expected to be found at src/main/resources/templates/&lt;theme-id&gt;. For example, in addition, the CSS and Javascript files for the dracula theme, you can clone the default set of CAS views into a new directory at src/main/resources/templates/dracula. When CAS begins to render the UI for https://app.example.org, it would then look inside src/main/resources/templates/dracula to find the requested view (i.e. casLoginView.html) allowing you to control the HTML view on a per-application basis. A themed view will only be used if and once found; otherwise, the defaults will continue to run as expected. View vs FragmentNote that from a CAS and/or Thymeleaf perspective, there is a difference between a full view and a fragment. A view generally contains the full outline of a CAS page and may be composed of several smaller reusable fragments, typically found inside the fragments directory. When working with themes, you are tasked with theming the actual view such as casLoginView.html by pulling that file into the right location in the overlay. Attempting to only theme a fragment such as footer.html will not be successful. Note that CAS views and theme-based views may both be externalized out of the web application context. When externalized, themed views are expected to be found at the specified path via CAS properties under a directory named after the theme name. For instance, if the external path for CAS views is /etc/cas/templates, view template files for theme dracula may be located at /etc/cas/templates/dracula/. Dynamic Theme Selection So far, we have been assigning themes to CAS services rather statically using the theme property but we can certainly take this to the next step and attempt to trigger themes based on a variety of conditions picked at runtime. Options for dynamic theme triggers are available based on Groovy scripts and/or REST endpoints. Let’s try one with a Groovy script as the trigger. First, let’s widen the definition of our service to be a slightly more forgiving and assign the groovy script as the theme: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://.+.example.org\", \"name\" : \"ApplicationName\", \"id\" : 1001, \"evaluationOrder\" : 10, \"theme\": \"file:///etc/cas/config/themes.groovy\" } The groovy script is tasked with the responsibility of figuring out the theme name. Of course, whatever the end result, it goes without saying that the theme must itself have been defined elsewhere since we are only controlling the switch here. The script more or less would match the following: import java.util.* def String run(final Object... args) { def service = args[0] def registeredService = args[1] def queryStrings = args[2] def headers = args[3] def logger = args[4] /* Stuff happens... */ return \"dracula\" } In the above script, you have access to the service object that represents the requesting application (i.e. service.id would get you the service URL) as well as the current request query strings and headers and of course, a pointer to the entire body of the registered service definition just in case you need to run some additional checks or control the behavior even more dynamically via CAS custom properties. So… I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Happy Coding, Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/06/10/cas-userinterface-customizations/"
  },

  
  
  
  {
    "title": "CAS Multifactor Authentication with Google Authenticator",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. A number of CAS deployments that intend to turn on multifactor authentication support tend to do so via Google Authenticator. This is a quick and simplified guide to demonstrate an approach to that use case along with some additional explanations regarding specific multifactor triggers and bypass options supported in CAS today. Our task list is rather short: Configure LDAP authentication with CAS Trigger Google Authenticator for users who belong to the mfa-eligible group, indicated by the memberOf attribute on the LDAP user account. Design and explore bypass options that would override the above trigger where needed. Environment CAS 5.3.x CAS Maven WAR Overlay (The 5.3 branch specifically) Configuring Authentication Prior to configuring multiple factors of authentication, we need to first establish a primary mode of validating credentials. To kill two birds with one stone [1], we are going to o address yet another common use case and keep things simple by sticking with LDAP authentication. The strategy here, as indicated by the CAS documentation, is to declare the intention/module in the build script and then configure the relevant cas.authn.ldap[x] settings for the directory server in use. Most commonly, that would translate into the following settings: cas.authn.ldap[0].type=AUTHENTICATED cas.authn.ldap[0].ldapUrl=ldaps://ldap1.example.org cas.authn.ldap[0].baseDn=dc=example,dc=org cas.authn.ldap[0].searchFilter=cn={user} cas.authn.ldap[0].bindDn=cn=Directory Manager,dc=example,dc=org cas.authn.ldap[0].bindCredential=... Note that the method of authentication, whether on its own or using separate attribute repositories and queries must have the ability to resolve the needed attribute which will be used later by CAS to trigger multifactor authentication. For this context, the simplest way would be to let LDAP authentication retrieve the attribute directly from the directory server. The following setting allows us to do just that: cas.authn.ldap[0].principalAttributeList=memberOf At this point in the authentication flow, we have established an authenticated subject that would be populated with fetched attribute memberOf. Configuring Google Authenticator Here, our task is to enable Google Authenticator in CAS. Practically, similar to the LDAP authentication configuration, this involves declaring the right module in the build and then providing specific Google Authenticator settings to CAS properties. Things such as the issuer, label, etc. Most commonly, the required settings would translate into the following: cas.authn.mfa.gauth.issuer=CAS cas.authn.mfa.gauth.label=CASLabel At this point, we have enabled Google Authenticator and we just need to find a way to instruct CAS to route the authentication flow over to Google Authenticator in the appropriate condition. This is where triggers come into place. Configuring Multifactor Authentication Triggers The entire purpose of a trigger here is to detect a condition by which the authentication flow should be rerouted. There are a large number of triggers supported by CAS, all of which kick into action and behave all the same regardless of the multifactor authentication provider. Our task here is to build a special condition that activates multifactor authentication if any of the values assigned to the attribute memberOf contain the value mfa-eligible: cas.authn.mfa.globalPrincipalAttributeNameTriggers=memberOf cas.authn.mfa.globalPrincipalAttributeValueRegex=mfa-eligible Notice that the conditions above do not indicate anything about Google Authenticator. If the above condition holds true, how does CAS know that the authentication flow should be routed to Google Authenticator? Per the CAS documentation: Trigger MFA based on a principal attribute(s) whose value(s) matches a regex pattern. Note that this behavior is only applicable if there is only a single MFA provider configured since that would allow CAS to know what provider to next activate. In other words, if the above condition holds true and CAS is to route to a multifactor authentication flow, that would obviously be one supported and provided by Google Authenticator since that’s the only provider that is currently configured to CAS. Of course, if there are multiple providers available at runtime (i.e. U2F FIDO, YubiKey, etc) then we would need massage the condition since the automatic detection of the multifactor provider would not be immediately obvious…and that sort of thing would be outside the scope of this tutorial. Google Authenticator Device Registration Per the CAS documentation, you need to decide the type of registry that would hold onto devices registered with CAS, authorized to use Google Authenticator. A more common use case here would be to use a relational database to manage issued tokens and devices. There is very little for you to do here, since the device registration flow is built into CAS by default, allowing new devices to register themselves with the system by scanning a QR code and holding on the scratch codes that are produced by CAS. Multifactor Authentication Bypass Once the above conditions determine that Google Authenticator may be activated as the next step in the authentication flow, CAS presents bypass rules are then consulted to calculate whether the provider should ignore the request and skip MFA conditionally. There are a variety of strategies you may choose to bypass multifactor authentication, one of which is a more static strategy of defining the ignore rule at the service policy level: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"^(https|imaps)://.*\", \"id\" : 100, \"multifactorPolicy\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceMultifactorPolicy\", \"bypassEnabled\" : \"true\" } } A more dynamic strategy, of course, would be to calculate the end result via a Groovy script. The outcome of the script, if true indicates that multifactor authentication for the requested provider should proceed. Otherwise false indicates that multifactor authentication for this provider should be skipped and bypassed. The path to the groovy script must surely be taught to CAS as a setting: cas.authn.mfa.gauth.bypass.type=GROOVY cas.authn.mfa.gauth.bypass.groovy.location=file:/etc/cas/config/MultifactorBypass.groovy …and a MultifactorBypass.groovy script would be: import java.util.* def boolean run(final Object... args) { def authentication = args[0] def principal = args[1] def registeredService = args[2] def provider = args[3] def logger = args[4] def httpRequest = args[5] // Ignore MFA for everyone, except casuser logger.info(\"Evaluating multifactor authn bypass rules for {}\", principal) return principal.id.equalsIgnoreCase(\"casuser\") } Summary I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed [1] No birds were harmed during the production of this blog post.",
    "tags": "CAS MFA",
    "url": "/2018/06/10/cas-mfa-google-authenticator/"
  },

  
  
  
  {
    "title": "CAS 5.3.x Deployment - WAR Overlays",
    "text": "This is a short and sweet tutorial on how to deploy CAS via the WAR Overlay method. This tutorial specifically requires and focuses on: CAS 5.3.x Java 8 Need Help?If you ever get stuck and are in need of additional assistance, start by reviewing the suggestions provided here. You may also look at available support options provided here. Overlay…What? Overlays are a strategy to combat repetitive code and/or resources. Rather than downloading the CAS codebase and building it from source, overlays allow you to download a pre-built vanilla CAS web application server provided by the project itself, override/insert specific behavior into it and then merge it all back together to produce the final (web application) artifact. You can find a lot more about how overlays work here. The concept of the WAR Overlay is NOT a CAS invention. It’s specifically an Apache Maven feature and of course, there are techniques and plugins available to apply the same concept to Gradle-based builds as well.You are free to choose between Maven or Gradle. For this tutorial, I opted into the Maven WAR overlay. Once you have forked and cloned the repository locally, you’re ready to begin. NoteRemember to switch to the appropriate branch. Today, the master branch of the repository applies to CAS 5.2.x deployments. That may not necessarily remain true when you start your own deployment. So examine the branches and make sure you checkout the one matching your intended CAS version. Overlay’s Anatomy Similar to Grey’s, a Maven WAR overlay is composed of several facets the most important of which is the pom.xml file. This is a build descriptor file whose job is to teach Apache Maven how to obtain, build, configure (and in certain cases deploy) artifacts. KISSYou do not need to download Apache Maven separately. The project provides one for you automatically with the embedded Maven Wrapper. The pom.xml is composed of several sections. The ones you need to worry about are the following. Properties &lt;properties&gt; &lt;cas.version&gt;5.3.5&lt;/cas.version&gt; &lt;springboot.version&gt;1.5.16.RELEASE&lt;/springboot.version&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;app.server&gt;-tomcat&lt;/app.server&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; This is the bit that describes build settings, and specifically, here, what versions of CAS, Spring Boot, and Java are required for the deployment. You are in practice mostly concerned with the &lt;cas.version&gt; setting and as new (maintenance) releases come out, it would be sufficient to simply update that version and re-run the build. This might be a good time to review the CAS project’s Release Policy as well as Maintenance Policy. Dependencies The next piece describes the dependencies of the overlay build. These are the set of components almost always provided by the CAS project that will be packaged up and put into the final web application artifact. At a minimum, you need to have the cas-server-webapp-${app.server} module available because that is the web application into which you intend to inject your settings and customizations if any. Also, note that the module declarations are typically configured to download the CAS version instructed by the property ${cas.version}. Here is an example: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp${app.server}&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Including a CAS module/dependency in the pom.xml simply advertises to CAS your intention of turning on a new feature or a variation of a current behavior. Do NOT include something in your build just because it looks and sounds cool. Remember that the point of an overlay is to only keep track of things you actually need and care about, and no more. RememberKeep your build clean and tidy. A messy build often leads to a messy deployment, complicates your upgrade path and is a documented cause of early hair loss. Keep changes down to the absolute essentials and document their need for your deployment. If you review the configuration a year from now, you should have an idea of why things are the way they are. And What About…? There are many other pieces in the pom.xml, such as repositories, profiles, plugins, etc that I skipped. For everything else, there is MasterCard…and of course the official Apache Maven guides. Enjoy! The Build Now that you have a basic understanding of the build descriptor, it’s time to actually run the build. An Apache Maven build is often executed by passing specific goals/commands to Apache Maven itself, aka mvn. So for instance in the terminal and once inside the project directory you could execute things like: cd cas-overlay-template mvn clean …which may be a problem if you don’t have already have Apache Maven downloaded and installed. While you can do that separate install, the WAR Overlay project provides you with an embedded Apache Maven instance whose job is to first determine whether you have Maven installed and if not, download and configure one for you based on the project’s needs. So you can replace that command above with: cd cas-overlay-template mvnw clean …which may be a problem because, how are you supposed to know what commands/goals can be passed to the build? You can study them for sure, but the project provides you with a shell script that wraps itself around the Maven wrapper and provides an easy facade for you to remember commands and their use. This is the build.sh file, which you can run as such: cd cas-overlay-template ./build.sh help Usage: build.sh [copy|clean|package|run|debug|bootrun] What do these commands do? Type Description copy Copies the configuration from the local etc/cas/config directory to /etc/cas/config. See this guide to learn more. clean Deletes any previously-built and leftover artifacts from the target directory. package Runs clean and copy. Then packages the CAS web application artifact and run through the overlay to inject local customizations. The outcome is a target/cas.war file which is ready to be deployed. run Involves package and then deploys and runs the CAS web application via its own embedded server container. debug Same thing as run, except that you can remote-debug the CAS web application over port 5000. help Display available commands. listviews List the current CAS UI views that are available to the overlay and can be customized. getview Download a CAS view into the overlay and prepare it for customizations. cli Step into the command-line shell and interact with CAS. RememberDocs grow old. Always consult the overlay project's README file to keep to date. As an example, here’s what I see if I were to run the package command: ./build.sh copy package Creating configuration directory under /etc/cas Copying configuration files from etc/cas to /etc/cas/config etc/cas/config/application.yml -&gt; /etc/cas/config/application.yml etc/cas/config/cas.properties -&gt; /etc/cas/config/cas.properties etc/cas/config/log4j2.xml -&gt; /etc/cas/config/log4j2.xml [INFO] Scanning for projects... [INFO] [INFO] Using the MultiThreadedBuilder implementation with a thread count of 5 [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building cas-overlay 1.0 [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ cas-overlay --- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ cas-overlay --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /cas-overlay-template/src/main/resources [INFO] [INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ cas-overlay --- [INFO] No sources to compile [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ cas-overlay --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /cas-overlay-template/src/test/resources [INFO] [INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ cas-overlay --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ cas-overlay --- [INFO] No tests to run. [INFO] [INFO] --- maven-war-plugin:2.6:war (default-war) @ cas-overlay --- [INFO] Packaging webapp [INFO] Assembling webapp [cas-overlay] in [/cas-overlay-template/target/cas] [info] Copying manifest... [INFO] Processing war project [INFO] Processing overlay [ id org.apereo.cas:cas-server-webapp-tomcat] [INFO] Webapp assembled in [786 msecs] [INFO] Building war: /cas-overlay-template/target/cas.war [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ ... You can see that the build attempts to download, clean, compile and package all artifacts, and finally, it produces a /cas-overlay-template/target/cas.war which you can then use for actual deployments. RememberYou are allowed to pass any of Maven's native command-line arguments to the build.sh file. Things like -U or -X might be useful to have handy. Configuration I am going to skip over the configuration of /etc/cas/config and all that it deals with. If you need the reference, you may always use this guide to study various aspects of CAS configuration. Suffice it to say that, quite simply, CAS deployment expects the main configuration file to be found under /etc/cas/config/cas.properties. This is a key-value store that is able to dictate and alter the behavior of the running CAS software. As an example, you might encounter something like: cas.server.name=https://cas.example.org:8443 cas.server.prefix=https://cas.example.org:8443/cas logging.config=file:/etc/cas/config/log4j2.xml …which at a minimum, identifies the CAS server’s URL and prefix and instructs the running server to locate the logging configuration at file:/etc/cas/config/log4j2.xml. The overlay by default ships with a log4j2.xml that you can use to customize logging locations, levels, etc. Note that the presence of all that is contained inside /etc/cas/config/ is optional. CAS will continue to fall back onto defaults if the directory and the files within are not found. Keep Track It is VERY IMPORTANT that you contain and commit the entire overlay directory (save the obvious exclusions such as the target directory) into some sort of source control system, such as git. Treat your deployment just like any other project with tags, releases, and functional baselines. LDAP Authentication We need to first establish a primary mode of validating credentials by sticking with LDAP authentication. The strategy here, as indicated by the CAS documentation, is to declare the intention/module in the build script: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-ldap&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; …and then configure the relevant cas.authn.ldap[x] settings for the directory server in use. Most commonly, that would translate into the following settings: cas.authn.ldap[0].type=AUTHENTICATED cas.authn.ldap[0].ldapUrl=ldaps://ldap1.example.org cas.authn.ldap[0].baseDn=dc=example,dc=org cas.authn.ldap[0].searchFilter=cn={user} cas.authn.ldap[0].bindDn=cn=Directory Manager,dc=example,dc=org cas.authn.ldap[0].bindCredential=... To resolve and fetch the needed attributes which will be used later by CAS for release, the simplest way would be to let LDAP authentication retrieve the attributes directly from the directory server. The following setting allows us to do just that: cas.authn.ldap[0].principalAttributeList=memberOf,cn,givenName,mail Registering Applications Client applications that wish to use the CAS server for authentication must be registered with the server a-priori. CAS provides a number of facilities to keep track of the registration records and you may choose any that fits your needs best. In more technical terms, CAS deals with service management using two specific components: Individual implementations that support a form of a database are referred to as Service Registry components and they are many. There is also a parent component that sits on top of the configured service registry as more of an orchestrator that provides a generic facade and entry point for the rest of CAS without entangling all other operations and subsystems with the specifics and particulars of a storage technology. In this tutorial, we are going to try to configure CAS with the JSON service registry. Configuration First, ensure you have declared the appropriate module/intention in the build: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-json-service-registry&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; Next, you must teach CAS how to look up JSON files to read and write registration records. This is done in the cas.properties file: cas.serviceRegistry.initFromJson=false cas.serviceRegistry.json.location=file:/etc/cas/services …where a sample ApplicationName-1001.json would then be placed inside /etc/cas/services: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://app.example.org\", \"name\" : \"ApplicationName\", \"id\" : 1001, \"evaluationOrder\" : 10 } Ticketing A robust CAS deployment requires the presence and configuration of an internal database that is responsible for keeping track of tickets issued by CAS. CAS itself comes by default with a memory-based node-specific cache that is often more than sufficient for smaller deployments or certain variations of a clustered deployment. Just like the service management facility, large variety of databases and storage options are supposed by CAS under the facade of a Ticket Registry. In this tutorial, we are going to configure CAS to use a Hazelcast Ticket Registry with the assumption that our deployment is going to be deployed in an AWS-sponsored environment. Hazelcast Ticket Registry is often a decent choice when deploying CAS in a cluster and can take advantage of AWS’s native support for Hazelcast in order to read node metadata properly and locate other CAS nodes in the same cluster in order to present a common, global and shared ticket registry. This is an ideal choice that requires very little manual work and/or troubleshoot, comparing to using options such as Multicast or manually noting down the address and location of each CAS server in the cluster. Configuration First, ensure you have declared the appropriate module/intention in the build: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-hazelcast-ticket-registry&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; Next, the AWS-specific configuration of Hazelcast would go into our cas.properties: cas.ticket.registry.hazelcast.cluster.discovery.enabled=true cas.ticket.registry.hazelcast.cluster.discovery.aws.accessKey=... cas.ticket.registry.hazelcast.cluster.discovery.aws.secretKey=... cas.ticket.registry.hazelcast.cluster.discovery.aws.region=us-east-1 cas.ticket.registry.hazelcast.cluster.discovery.aws.securityGroupName=... # cas.ticket.registry.hazelcast.cluster.discovery.aws.tagKey= # cas.ticket.registry.hazelcast.cluster.discovery.aws.tagValue= That should do it. Of course, if you are working on a more modest CAS deployment in an environment that is more or less owned by you and you prefer more explicit control over CAS node registrations in your cluster, the following settings would be more ideal: # cas.ticket.registry.hazelcast.cluster.instanceName=localhost # cas.ticket.registry.hazelcast.cluster.port=5701 # cas.ticket.registry.hazelcast.cluster.portAutoIncrement=true cas.ticket.registry.hazelcast.cluster.members=123.321.123.321,223.621.123.521,... Overlay Customization If I cd into the target/cas directory, I can see an exploded version of the cas.war file. This is the directory that contains the results of the overlay process. Since I have not actually customized and overlaid anything yet, all configuration files simply match their default and are packaged as such. So as an example, let’s change something. Digging further down, I notice there exists a /target/cas/WEB-INF/classes/messages.properties file, which is the default message bundle. I decided that I am going to change the text associated with screen.welcome.instructions. RememberDo NOT ever make changes in the target directory. The changesets will be cleaned out and set back to defaults every time you do a build. Follow the overlay process to avoid surprises. First, I will need to move the file to my project directory so that Apache Maven during the overlay process can use that instead of what is provided by default. Here we go: cd cas-overlay-template mkdir -p src/main/resources cp target/cas/WEB-INF/classes/messages.properties src/main/resources/ Then I’ll leave everything in that file alone, except the line I want to change. ... screen.welcome.instructions=Speak Friend and you shall enter. ... Then I’ll package things up as usual. ./build.sh package ... [INFO] --- maven-war-plugin:2.6:war (default-war) @ cas-overlay --- [INFO] Packaging webapp [INFO] Assembling webapp [cas-overlay] in [/cas-overlay-template/target/cas] [info] Copying manifest... [INFO] Processing war project [INFO] Processing overlay [ id org.apereo.cas:cas-server-webapp-tomcat] [INFO] Webapp assembled in [1005 msecs] [INFO] Building war: /cas-overlay-template/target/cas.war [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS ... If I look at target/cas/WEB-INF/classes/messages.properties after the build, I should see that the overlay process has picked and overlaid onto the default my version of the file. RememberOnly overlay and modify files you actually need and try to use externalized resources and configuration as much as possible. Just because you CAN override something in the default package, it doesn't mean that you should. User Interface Customizations In order to modify the CAS HTML views, each file first needs to be brought over into the overlay. You can use the build.sh listviews command to see what HTML views are available for customizations. Once chosen, simply use build.sh getview footer.html to bring the view into your overlay. Exploded the CAS web application file. Searching for view name footer.html... Found view(s): /cas-overlay-template/target/cas/WEB-INF/classes/templates/fragments/footer.html Created view at /cas-overlay-template/src/main/resources/templates/fragments/footer.html /cas-overlay-template/src/main/resources/templates/fragments/footer.html Now that you have the footer.html brought into the overlay, you can simply modify the file at cas-overlay-template/src/main/resources/templates/fragments/footer.html, and then repackage and run the build as usual. Deploy You have a number of options when it comes to deploying the final cas.war file. This post should help. The easiest approach would be to simply use the build.sh run command and have the overlay be deployed inside an embedded container. What About…? CAS Multifactor Authentication with Duo Security CAS 5 LDAP AuthN and Jasypt Configuration CAS 5 SAML2 Delegated AuthN Tutorial For more content, please see this link. So… It’s important that you start off simple and make changes one step at a time. Once you have a functional environment, you can gradually and slowly add customizations to move files around. I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/06/09/cas53-gettingstarted-overlay/"
  },

  
  
  
  {
    "title": "CAS 5.3.0 RC4 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.2.0 GA was released on November 27th, 2017. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.3.0. This post intends to highlight some of the improvements and enhancements packed into the fourth release candidate in the 5.3.0 series. The in-development documentation of CAS 5.3.0 is available here. The release schedule is also available here. The release policy is available here. You can read about the previous release candidate here. Shake Well Before Use Apache Maven Gradle Minors Delegated Authentication &amp; MFA Password Management Email Notifications Interrupt Notifications SAML2 Service Providers Multifactor Authentication Trusted Devices Passwordless Authentication Custom CAS Settings AWS ElastiCache for Memcached AWS Simple Notification Service for SMS JWT Service Tickets AWS Secrets Manager RESTful View Resolution AWS S3 Buckets Command-line Shell Commands SAML 1.1 Validations Library Upgrades Get Involved Credits Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. Note that CAS releases are strictly time-based releases; they are not scheduled or based on specific benchmarks, statistics or completion of features. To gain confidence in a particular release, it is strongly recommended that you start early by experimenting with release candidates and/or follow-up snapshots. In order to start experimenting with release candidates, at any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Apache Maven In the pom.xml of the overlay, adjust the following tag to match below: &lt;cas.version&gt;5.3.0-RC4&lt;/cas.version&gt; Gradle In the gradle.properties of the overlay, adjust the following setting to match below: cas.version=5.3.0-RC4 Minors Thanks to @leleuj, validation of OAuth and OpenID Connect requests gain improvements in terms of protocol compatibility. The rendering syntax of CAS attributes in the validation response can now be controlled using CAS settings to enable inline rendering. (i.e. &lt;cas:attribute name=\"givenName\" value=\"John\"&gt;&lt;/cas:attribute&gt;) Thanks to @frett, the initialization of the login webflow is fixed to only execute once. Refreshing CAS configuration should allow for re-initialization of the service registry, if CAS is configured to populate the service registry database from JSON service files. Thanks to @NgSekLong, the validation of the OAuth client_secret parameter is made optional if it’s left undefined for the OAuth service. CAS test coverage has improved slightly with a number of additional tests where now coverage is at 67% and growing. Auditing a password change operation using the CAS password management features is fixed to correctly catalog failures. Static analysis is now turned on CAS CI builds using FindBugs by default as well as Checkstyle. The builds are also taking advantage of the OWASP Dependency Check plugin for Gradle to auto-scan libraries used by CAS and fail the build in case a relevant CVE is found in the CAS distribution. Thanks to @williame-uah, the encryptionSecretSize parameter is fixed in CAS command-line shell to remove the duplicate name. Handling LDAP account states to process warnings, etc can now be separately turned on via CAS configuration, as part of the password policy settings. Thanks to @tsschmidt, the strategy for calculating service registry file names can now be customized in a pluggable way. This in particular has a benefit of allowing the management web application to provide customized naming strategies for resources as they are tracked in source control and Git, etc. A number of internal changes to SAML2 metadata resolution in order to improve performance and memory use. Annotation processing behavior has been restored to account for CAS extensions of Log4j, as well as correctly generating configuration metadata. Thanks to @sbearcsiro, a number of bugs that affect Twitter’s OAuth1 requests and responses when dealing with delegated authentication in CAS are now fixed. Logout management in CAS is modified to be able to internally handle submitting logout notifications to multiple URLs associated with a single application. A Groovy implementation is now made available for PrincipalFactory objects that may be used inside custom configuration classes in areas where principal resolution needs unusual changes. Thanks to @tduehr, various number of improvements are applied to the CAS internal Gradle build to ensure tests can be run in categories. Thanks to @tsschmidt, the pattern to recognize domains in registered services is now improved. Thanks to @ringmaster217, the iat field in JWTs generated for OpenID Connect when tokens are introspected is fixed to be based on seconds instead of milliseconds. A series of minor improvements to the Surrogate authentication functionality when surrogate accounts are looked up from LDAP. SAML2 metadata resolution caching strategies are better improved in this release to improve performance and reduce memory use. Thanks to @fcrespel, token revocation features of CAS running in OpenID Connect mode are made more compliant with the specification. Delegated authentication can now directly build the final authenticated principal using an attribute from the provided user profile. JAAS authentication is given the ability in settings to handle password policy enforcements. Furthermore, both JAAS and Surrogate authentication are given dedicated settings to control how a CAS authenticated principal should be constructed. This behavior was typically controlled more globally before via Person Directory settings. Thanks to @sbearcsiro, delegated authentication is able to properly reconstruct the service authentication request, once the flow has returned from the provider and CAS is getting ready to produce a response. Special CipherExecutor components are added to handle signing and encryption decoding/encoding operations using RSA key-pairs. Thanks to @fcrespel, french translations of the CAS message bundles are now made up-to-date. The configuration file for JAAS-based authentications may now be loaded directly from CAS settings. When preparing SAML2 responses, the subject locality field is fixed to include the address of the CAS server instead of the service provider. Anonymous username identifiers are now set to correctly encode and digest values that may be used for persistent identifiers. Thanks to @sbearcsiro, delegated authentication to Twitter gains support to retrieve and process the profile email address. Database authentication in query mode can now process and accept named sql parameters in the SQL query. Thanks to @bdavids1, the Duo Security iframe is improved to display properly specially on mobile devices per the recommendations available here. Delegated Authentication &amp; MFA Delegating authentication events to ADFS as well as all other external identity providers are now revisited to handle multifactor authentication flows better, once the flow travels back from the identity provider to CAS after authentication. Password Management Email Notifications WATCH OUT!This is a breaking change. Review your settings and be sure to adjust. Settings that control email notifications for password reset operations are placed under a mail setting to be consistent with all other properties. As a result, the email notification operations of password reset gain small improvements to honor CC and BCC flags defined in configuration. Interrupt Notifications CAS Interrupt Notifications can now be triggered using authentication/principal attributes using regular expression patterns. Furthermore, notifications may now be skipped on a per-service basis by assigning tags and properties to the service definition. SAML2 Service Providers The following new SAML2 service providers are now supported by CAS out of the box: WarpWire BlackBaud GiveCampus RocketChat Multifactor Authentication Trusted Devices WATCH OUT!You may need to adjust the underlying schema used to store trusted device records to handle the new date type. The change affects all storage options that support keeping track of trusted device records. Handling trusted devices for multifactor authentication receives a number of fixed to handle device expiration time units better. As a result of this change, the trusted device record date is switched from LocalDate to LocalDateTime in order to support hours, minutes and seconds. Passwordless Authentication An initial draft of Passwordless Authentication is now available. This is a form of authentication in CAS where passwords take the form of tokens that expire after a configurable period of time, and are sent to users using email, text messages, etc. Custom CAS Settings In order to extend the collection of CAS settings, most adopters might have had to introduce a new configuration namespace into CAS and have it be recognized using a custom @ConfigurationProperties type of component. In this release candidate, a custom category is introduced as a Map that can house all arbitrary settings. Furthermore, the entire collection of CAS settings including the custom category of course is made available to all components, webflow states and CAS views in particular, so that views can be customized or altered using any of the defined CAS configuration properties. AWS ElastiCache for Memcached For memcached integrations, CAS is now able to provide a native module that is able to seamlessly integrate with AWS ElastiCache. This is mostly a drop-in replacement for the spymemcached. WATCH OUT!The memcached support modules in CAS no longer take the opinionated approach of presenting a memcached client library. The choices are now presented as separated modules that you are to choose and then stuff into your overlay. If you are unsure what to choose, choose spymemcached. AWS Simple Notification Service for SMS Support is now included to take advantage of AWS SNS for sending SMS messages. WATCH OUT!As par of this change, the configuration of various SMS providers is now moved into a parent cas.smsProviders category. Please review your settings and adjust. JWT Service Tickets Encryption and signing keys use to allow CAS to encode a JWT as a service ticket may now be defined on a per-service basis. Furthermore, extra test cases are added to ensure the generated JWT is not doubly encoded in base64 syntax. AWS Secrets Manager CAS configuration settings may now be managed and located using AWS Secrets Manager. RESTful View Resolution CAS views can now be resolved using an external URL in RESTful ways. AWS S3 Buckets CAS configuration properties can now also be fetched from AWS S3 buckets. Similarly, SAML metadata documents for various service providers may also be managed using AWS S3 buckets. Command-line Shell Commands CAS command-line shell receives a few additional commands in order to verify connectivity to LDAP servers and to test connections to endpoints useful for verifying SSL configuration, etc. The endpoint validation is further enhanced by @jtgasper3 to include details that can be used to troubleshoot failed https client connection. SAML 1.1 Validations SAML1.1 ticket validation is cleaned up to parse and extract the validation payload from the request body more accurately, relying less on manual parsing of input. The extraction logic also includes a small bit of caching of the request body in order to allow upstream components to process a given http request’s body for other types of functionality, essentially making the request body reusable and re-parseable for the entire transaction. Library Upgrades Amazon SDK Commons Text Mockito AspectJ JavaParser Jool CosmosDb Jackson Spring HikariCP Spring Boot Apache Tomcat Hibernate Caffeine Guava Kryo Pac4j Apache Ignite Log4j Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Credits Big thanks to all who participate in the development of this release to submit patches and contribute improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2018/05/25/530rc4-release/"
  },

  
  
  
  {
    "title": "Apereo CAS - Identity Impersonation",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Overview The Apereo CAS server has had support for impersonation for a quite a while now, starting with CAS 5.1.x. This feature usually referred to as Surrogate Authentication or sudo for the web long existed before the CAS 5 series in form of an extension and gradually and eventually found its way into the mainline distribution through community contributions, having been tested and tried in production battlegrounds. The idea behind this feature is fairly simple; sometimes you want to be someone else perhaps for the purposes of duplicating a troublesome scenario or troubleshooting a bad user experience, etc. In such scenarios, your own identity and credentials are first verified and assuming you have the authorization to impersonate someone else, you proceed to adopt that person’s identity in order to duplicate their user experience and workflow. This is a short tutorial on how to achieve said functionality. Our starting position is based on the following: CAS 5.3.0-RC4 Java 8 Maven Or Gradle WAR Overlays Our primary source for authentication is abstracted away with JAAS, and the principal store for fetching user attributes is LDAP. Overlay Setup Once you have a functional overlay build, the first step would be to prep the right number of configuration settings in order to handle authentication and attribute resolution. The following settings, summarily, should do the job: cas.authn.jaas[0].realm=CAS cas.authn.attributeRepository.ldap[0].attributes.uid=uid cas.authn.attributeRepository.ldap[0].attributes.displayName=displayName cas.authn.attributeRepository.ldap[0].attributes.cn=commonName cas.authn.attributeRepository.ldap[0].attributes.memberOf=memberOf cas.authn.attributeRepository.ldap[0].ldapUrl=ldap://... cas.authn.attributeRepository.ldap[0].useSsl=false cas.authn.attributeRepository.ldap[0].useStartTls=false cas.authn.attributeRepository.ldap[0].baseDn=dc=example,dc=edu cas.authn.attributeRepository.ldap[0].searchFilter=uid={0} cas.authn.attributeRepository.ldap[0].bindDn=... cas.authn.attributeRepository.ldap[0].bindCredential=... cas.personDirectory.principalAttribute=uid At this point, we should be able to authenticate via JAAS and subsequently fetch attributes from LDAP. We are also instructing CAS to build the final authenticated Principal identified by the uid attribute (instead of whatever the user types into the login form as the credential id). So far, so good. Impersonation Scenario Our handling of impersonated authentication attempts scenarios is rather unique. Sometimes, we know beforehand the identity of the user whom we plan to impersonate. Other times, it would be nice to be presented with a menu to choose our target impersonatee. Of course, a mere successful authentication attempt is not enough; not only do we need to be authorized to start impersonation attempts, but also we need special permissions for each impersonated user account. For the purposes of this tutorial, we shall attempt to kill both such birds with one stone; LDAP. Furthermore, we will need to establish a special sort of syntax instructing CAS to display a list of potential impersonatee accounts authorized for our use as well as one that simply bypasses that menu list and executes the requested impersonation attempt. Per CAS, we may be able to use the plus syntax which sort of goes like this: jsmith+casuser would mean: Authenticate myself, the primary user as casuser, using my own credentials. Then switch my identity and adopt that of jsmith. +casuser would mean: Authenticate myself, the primary user as casuser, using my own credentials. Then present a list of accounts authorized for impersonation attempts by me. The Setup First, let’s ensure that CAS is prepped with the baseline impersonation functionality by adding the following module: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-surrogate-webflow&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; …and since impersonated accounts and authorization rules are going to be fetched from LDAP, let’s get CAS prepped for that too: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-surrogate-authentication-ldap&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; Surely, we need to instruct CAS on how to connect to LDAP for impersonation attempts: cas.authn.surrogate.ldap.ldapUrl=ldap://... cas.authn.surrogate.ldap.baseDn=dc=example,dc=edu cas.authn.surrogate.ldap.searchFilter=uid={0} cas.authn.surrogate.ldap.bindDn=... cas.authn.surrogate.ldap.bindCredential=... cas.authn.surrogate.ldap.useSsl=false cas.authn.surrogate.ldap.useStartTls=false Impersonation Configuration We have to teach CAS to hit LDAP and fetch a list of accounts authorized for impersonation, if and when instructed by the above special syntax. This can be done using the following settings: cas.authn.surrogate.ldap.surrogateSearchFilter=(&amp;(uid={user})(memberOf=cn=edu:example:app:{surrogate})) cas.authn.surrogate.ldap.memberAttributeName=memberOf cas.authn.surrogate.ldap.memberAttributeValueRegex=cn=edu:example:app:([^,]+) Authorize Impersonation These basically tell CAS to execute an LDAP search query where uid attribute equals the identity of the primary user (i.e. casuser) and the memberOf attribute matches a value of cn=edu:example:app:{surrogate} where {surrogate} is the identity of the impersonatee provided using the special plus syntax. If a match is found, authorization is granted and CAS picks up the identity of surrogate under legitimate pretenses. In other words, if casuser is found in LDAP with a uid of casuser and a memberOf of cn=edu:example:app:jsmith, then jsmith+casuser should allow CAS to switch the primary user from casuser to jsmith. Impersonation User Menu What about the +casuser syntax? That’s where the two other settings come in. Once CAS finds the primary user (i.e. casuser) in LDAP via the specified search query uid={0}, it then begins to look at all values of the memberOf attribute and will pick out those that match the attribute value specified. Note that the value is a regular expression pattern and once matched, CAS will attempt to extract the first group in the pattern for display purposes in the final menu where casuser will get to choose an impersonate account and proceed. But, Our LDAP… If the above scenario does not exactly match your environment word for word, do not worry. You can always extend the CAS configuration and define the scaffolding of your own business logic inside the following bean: @Bean public SurrogateAuthenticationService surrogateAuthenticationService() { ... } If you find that there is value in others sharing the same set of business rules as you have for impersonation, I strongly recommend that you open up a pull request and send your changeset in. With reasonable options to activate and tweak, it would be great to support the most common impersonation authorization rules, be it from LDAP or anywhere else. So… I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Happy Coding, Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/05/07/cas-impersonation-authn/"
  },

  
  
  
  {
    "title": "Apereo CAS - Customized Settings",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Overview Starting with version 5.3.x, CAS begins to own its own configuration namespace rather more seriously, rejecting any settings that are no longer supported or recognized. While this works quite well for configuration settings that tend to get deprecated and moved about from release to release, it also has a side-effect of not allowing any custom settings to be defined by the adopter. In practice, adding custom settings to a cas namespace is likely less than ideal, as it would be best to denote localized changes using their own specific namespaces and settings. So, in this tutorial, a short overview of extending CAS to use customized properties is presented as well as an alternative simplified strategy to introduce configuration options into the runtime without dabbling into much code. Our starting position is based on the following: CAS 5.3.0-RC4 Java 8 Maven Or Gradle WAR Overlays Custom Properties: Take #1 This strategy more or less applies to any CAS 5.x deployment as more of a heavyweight approach most useful when you are about to extend the CAS configuration to alter its workings by overriding conditional beans or introducing new components and behavior into the runtime engine. You will need to start by defining your collection of settings first: @ConfigurationProperties(value = \"custom\") public class CustomConfigurationProperties { private String settingName; public String getSettingName() {        return settingName; } public void setSettingName(final String value) { this.settingName = value; } } Or, if you can afford a bit of syntactic sugar with Lombok: @Getter @Setter @ConfigurationProperties(value = \"custom\") public class CustomConfigurationProperties { private String settingName; } Next, you need to extend the CAS configuration to have your configuration settings be recognized by the runtime: @Configuration(\"SomethingConfiguration\") @EnableConfigurationProperties(CustomConfigurationProperties.class) public class SomethingConfiguration { @Autowired private CustomConfigurationProperties customProperties; } …and then, you should be able to define settings in your cas.properties file such as: custom.settingName=some-value …and have them be recognized by SomethingConfiguration in all of its inner beans that you shall design and build. Of course, this is a fair amount of work to get something so seemingly simple done. Let’s try to simplify this a bit. Custom Properties: Take #2 Starting with CAS 5.3.x, a new cas.custom.properties namespace is introduced that is able to own all arbitrary settings. An example for this new syntax would be: cas.custom.properties.customPropertyName1=customPropertyValue1 cas.custom.properties.customPropertyName2=customPropertyValue2 cas.custom.properties.customPropertyName3=customPropertyValue3 …that is to say, you can substitute anything you prefer for the customized property name and values. Additionally, all CAS-owned properties including the custom namespace of course are now accessible in CAS views and templates such that one is able to do: &lt;p th:text=\"${casProperties.custom.properties.customPropertyName1}\" /&gt; …or: &lt;p th:text=\"${casProperties.server.name`}\" /&gt; Of course, note that the above syntax only works for settings that are provided by CAS. If you need access anything that is provided by Spring Boot, such as server.port or anything that pretty much does not have the cas. prefix, then you need to fall back onto fancier strategies of working with Thymeleaf to access application beans and pull up those settings where needed. Needless to say, that likely is a futile endeavor. So… I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Happy Coding, Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/05/04/cas-custom-properties/"
  },

  
  
  
  {
    "title": "Apereo CAS - Handling Multiple Logout URLs",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Overview CAS has had support for single logout for quite a while. This feature basically means that CAS is able to invalidate client application sessions in addition to its own SSO session, assuming client applications are ready to honor and accept logout requests with special configuration. When a CAS session ends, it notifies each of the services that the SSO session is no longer valid, and that relying parties need to invalidate their own session by processing a special logout request. Remember that the callback submitted to each CAS-protected application is simply a notification; nothing more. It is the responsibility of the application to intercept that notification and properly destroy the user authentication session, either manually, via a specific endpoint or more commonly via a CAS client library that supports SLO. By default, applications are contacted by CAS using their original URL to receive the logout notification; which is simply the purified service URL used when an authentication request on behalf of the application is submitted to CAS. This tutorial focuses on ways one can customize the logout URL in more dynamic ways. This tutorial deals with: CAS 5.3.0-RC4 Java 8 Maven Or Gradle WAR Overlays Single Logout Single Logout URL In dealing with single logout operations, the URL endpoint to receive the logout notification can be customized on a per-application basis: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://\\\\w+.example.org\", \"name\" : \"Our Example Domain\", \"id\" : 1, \"description\" : \"The example domain provides examples in examplish ways\", \"logoutUrl\" : \"https://logout.example.org\" } This is, of course, the simplest option and means that if CAS has established sessions with one or more applications that qualify for the above definition, those applications will receive logout notifications at the specified URL above when the logout engine in CAS begins to process records. Many Logout URLs One should note that the logoutUrl above not only static but also singular. With configuration only, there is not a way for one to specify more than one URL in cases where that might be needed. While the service configuration above presents a rather simplified version of the feature, CAS itself provides the internal mechanics to recognize and handle a collection of logout URLs for a given application. Our task here would be to extend the configuration slightly to implement this scenario and inject the behavior into the runtime. We can start by preparing CAS with a customized configuration component that would house our customizations for this use case. Once that is done, take note of the following bean definition posted in CasCoreLogoutConfiguration.java today: @ConditionalOnMissingBean(name = \"singleLogoutServiceLogoutUrlBuilder\") @Bean public SingleLogoutServiceLogoutUrlBuilder singleLogoutServiceLogoutUrlBuilder() { return new DefaultSingleLogoutServiceLogoutUrlBuilder(this.urlValidator); } Note how the bean is marked as conditional, meaning it will only be used by CAS if an alternative definition by the same is not found. So, in order for CAS to pick up our own alternative implementation, we are going to provide that bean definition in our own configuration class as such: @Bean public SingleLogoutServiceLogoutUrlBuilder singleLogoutServiceLogoutUrlBuilder() { return new CustomSingleLogoutServiceLogoutUrlBuilder(this.urlValidator); } Compile DependenciesNote that in order for the CAS overlay build to compile our changes and put them to good use, the overlay must be prepared with the required module used during the compilation phase. Otherwise, there will be errors complaining about missing symbols, etc. Now, it’s time to actually design our very own CustomSingleLogoutServiceLogoutUrlBuilder. Here is a modest example: public class CustomSingleLogoutServiceLogoutUrlBuilder extends DefaultSingleLogoutServiceLogoutUrlBuilder { ... public Collection&lt;URL&gt; determineLogoutUrl(RegisteredService registeredService, WebApplicationService service) { /* Stuff happens to determine the collection of the logout URLs given the provided service and its registered definition in the registry. */ } } That should do it. The very next time you build and deploy the changes, CAS should pick up our own bean definition and accompanying implementation class. It should be obvious that inside the class above, you have options to calculate the logout URLs as you wish since the builder object is expected to return a collection of URLs. To fully make this behavior dynamic, you may want to invest time researching service custom properties and externalize the logout function with special tags designed as properties that would then be consumed and processed in the above component. So… I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Happy Coding, Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/04/24/cas-multiple-logout-urls/"
  },

  
  
  
  {
    "title": "Apereo CAS - Access Strategy External URL Redirects",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Overview CAS has long had support for centralized authorization and access control policies on a per-application basis, I believe starting from CAS 4.2.x. These policies come in a variety of strategies with a number of options to control application access, SSO participation, the presence of a certain number of required claims before access can be granted and so on. In the event that the policy denies user access, it may often be desirable to redirect the authentication flow to a URL that would have instructions for the end-user and it might even be ideal if the construction of that URL could be customized in dynamic ways for better user experience. This tutorial specifically focuses on: CAS 5.3.0-RC4 Java 8 Maven Or Gradle WAR Overlays Delegated Authentication You may also be interested in this related blog post, detailing attribute-based access control in CAS. Use Case Given our starting position of defining a customized unauthorized redirect URL in situations where access to a CAS-enabled service is denied, you should take note of the following service definition that may be recognized as part of CAS using a JSON service registry: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://app.example.org\", \"name\" : \"Awesome Example App\", \"id\" : 1, \"description\" : \"The example application is an application that provides examples\", \"evaluationOrder\" : 100, \"accessStrategy\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceAccessStrategy\", \"enabled\" : true, \"unauthorizedRedirectUrl\": \"https://billboard.example.org\" } } It should be obvious that the unauthorizedRedirectUrl field of the configured access strategy allows one to define a URL to which CAS might redirect once service access is denied. Of course, we have not defined any particular rules that would prevent one from accessing this application via CAS so let’s do just that with a few modifications: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://app.example.org\", \"name\" : \"Awesome Example App\", \"id\" : 1, \"description\" : \"The example application is an application that provides examples\", \"evaluationOrder\" : 100, \"accessStrategy\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceAccessStrategy\", \"enabled\" : true, \"unauthorizedRedirectUrl\": \"https://billboard.example.org\", \"requiredAttributes\" : { \"@class\" : \"java.util.HashMap\", \"userAccessLevel\" : [ \"java.util.HashSet\", [ \"system\" ] ] } } } With the above changes, CAS will prevent access to our example application if the authenticated user does not have a claim userAccessLevel with a possible value of system. If access is rejected, CAS should try to redirect the flow back to https://billboard.example.org. Fairly simple. However, one issue remains which is the ability to customize the redirect URL in more dynamic ways, depending on the properties of the service definition, etc. The URL might need special query parameters, or different encoding semantics, etc. How could that be done? Dynamic Unauthorized URLs We can start by preparing CAS with a customized configuration component that would house our customizations for this use case. Once that is done, take note of the following bean definition posted in CasSupportActionsConfiguration.java today: @RefreshScope @Bean @ConditionalOnMissingBean(name = \"redirectUnauthorizedServiceUrlAction\") public Action redirectUnauthorizedServiceUrlAction() { return new RedirectUnauthorizedServiceUrlAction(servicesManager); } Note how the bean is marked as conditional, meaning it will only be used by CAS if an alternative definition by the same is not found. So, in order for CAS to pick up our own alternative implementation, we are going to provide that bean definition in our own configuration class as such: @Bean public Action redirectUnauthorizedServiceUrlAction() { return new MyRedirectUnauthorizedServiceUrlAction(servicesManager); } Compile DependenciesNote that in order for the CAS overlay build to compile our changes and put them to good use, the overlay must be prepared with the required module used during the compilation phase. Otherwise, there will be errors complaining about missing symbols, etc. Now, it’s time to actually design our very own DynamicRedirectUnauthorizedServiceUrlAction. Here is a modest example: public class MyRedirectUnauthorizedServiceUrlAction extends RedirectUnauthorizedServiceUrlAction { ... @Override protected URI determineUnauthorizedServiceRedirectUrl(RequestContext context) { final URI redirectUrl = WebUtils.getUnauthorizedRedirectUrlIntoFlowScope(context); final Event currentEvent = context.getCurrentEvent(); final AttributeMap eventAttributes = currentEvent.getAttributes(); final PrincipalException error = (PrincipalException) eventAttributes.get(\"error\", PrincipalException.class); final UnauthorizedServiceForPrincipalException serviceError = (UnauthorizedServiceForPrincipalException) error.getHandlerErrors().get(UnauthorizedServiceForPrincipalException.class.getSimpleName()); LOGGER.info(\"Calculating URL for service {} &amp; principal {} with attributes {}\", serviceError.getRegisteredService().getName(), serviceError.getPrincipalId(), serviceError.getAttributes()); /* Calculate the required URI, or simply return the default... */ return redirectUrl; } } That should do it. The very next time you build and deploy the changes, CAS should pick up our own bean definition and accompanying implementation class. It should be obvious that inside the class above, you have options to calculate the unauthorized redirect URL as you wish while having access to the underlying service definition object, the authenticated principal, and any retrieved attributes. So… I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Happy Coding, Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/04/23/cas-access-strategy-url-redirects/"
  },

  
  
  
  {
    "title": "Apereo CAS - Linking Accounts with Delegated Authentication",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Overview In the event that CAS is configured to delegate authentication to an external identity provider, it may be necessary to link the received profile from the identity provider to an internal account found in LDAP, SQL databases or any other systems. In this tutorial, we will focus on how to establish the authenticated subject based on this secondary lookup, using an identifier that is provided by the identity provider. This tutorial specifically focuses on: CAS 5.3.0-RC4 Java 8 Maven WAR Overlay Delegated Authentication Use Case Our starting position is a CAS server that is configured to hand off the authentication flow to an external identity provider described here. Once the response from the identity provider is validated and a profile response has been collected, CAS will get access to a profile identifier plus a number of attributes that may have been released by the provider depending on the semantics of the protocol in question. In building the authenticated subject and linking that to the SSO session, CAS by default has options to either use what is called a typed id which is translated as [InternalProviderName]+[Separator]+[ProfileId] or simply the profile id itself. This means that when the SSO session is established, the CAS authenticated subject will be communicated to all integrated applications using one of those two options. Of course, you may run into scenarios where neither id would actually make that much sense. For example, the internal identity may be a seemly pseudorandom integer that would not be all that practical for other applications. The better scenario as an option would be for CAS to simply look up the real record associated with that internal id, (assuming linking between the two records is made available already), and build the principal identifier and attributes according to the data store internal to CAS. This is tutorial on how to do just that. Setup Assuming delegated authentication is configured in CAS using any of the supported identity providers, our job here is put together code that massages the principal construction in CAS once the flow travels back from the identity provider over to CAS. To do this, we are going to take advantage of CAS PrincipalFactory components whose job is to build authenticated subjects, or Principals. Most if not all of authentication strategies in CAS are preconfigured with their own instance of a PrincipalFactory that would know how to translate a authenticated successful response into a Principal object CAS can understand. So start to prepare CAS with a customized configuration component that would house our specific choice of the PrincipalFactory used in delegation scenarios. Once that is done, take note of the following bean definition posted in Pac4jAuthenticationEventExecutionPlanConfiguration today: @ConditionalOnMissingBean(name = \"clientPrincipalFactory\") @Bean public PrincipalFactory clientPrincipalFactory() { return PrincipalFactoryUtils.newPrincipalFactory(); } Note how the bean is marked as conditional, meaning it will only be used by CAS if an alternative definition by the same is not found. So, in order for CAS to pick up our own alternative implementation, we are going to provide that bean definition in our own configuration class as such: @Bean public PrincipalFactory clientPrincipalFactory() { return PrincipalFactoryUtils.newPrincipalFactory(); } Compile DependenciesNote that in order for the CAS overlay build to compile our changes and put them to good use, the overlay must be prepared with the required module used during the compilation phase. Otherwise, there will be errors complaining about missing symbols, etc. Once you have the build compiling correctly, our next task would be to alter the body of our own clientPrincipalFactory bean definition to do what it needs, which is the establishment of the CAS principal based on provided ids, attributes, etc. You can certainly provide your own implementation of PrincipalFactory. What might be easier is if you were given the ability to change the implementation dynamically without having to rebuild CAS every time minor changes are required. To do this, aside from the default implementation of PrincipalFactory, CAS provides a built-in option to externalize all that logic to a Groovy script. The construction of that option would more or less look like this: @Autowired private ResourceLoader resourceLoader; @Bean public PrincipalFactory clientPrincipalFactory() { Resource script = resourceLoader.getResource(\"file:/etc/cas/config/CustomPrincipalFactory.groovy\"); return PrincipalFactoryUtils.newGroovyPrincipalFactory(script); } …and of course, our Groovy script found at /etc/cas/config/CustomPrincipalFactory.groovy would have the following structure: import org.apereo.cas.authentication.principal.* import org.apereo.cas.authentication.* import org.apereo.cas.util.* def run(Object[] args) { def id = args[0] def attributes = args[1] def logger = args[2] return new SimplePrincipal(id, attributes) } Now when CAS begins to construct the final authenticated principal, this Groovy script will be invoked to receive the identifier of the received response from the identity provider, any attributes that were submitted and extracted by CAS as a Map as well as a convenient logger object. Next, you can code in additional logic to contact the necessary systems and execute queries based on the id to collect the real record linked to that id or any of the provided attributes and ultimately, return an object of type SimplePrincipal that would carry the authenticated subject and its claims. So… I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Happy Coding, Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/04/20/cas-delegated-authn-account-linking/"
  },

  
  
  
  {
    "title": "Nominate awesome fits for the Apereo board",
    "text": "Are you a representative of a Member Organization in good standing contemplating whom to nominate for the available Apereo board of directors seats? Here are some ideas. Until 1700 Eastern on April 20th 2018, it’s not too late to widen the pool. (I haven’t checked with most people listed here to see if they’d actually be willing to serve - the point of this post is to provoke thought on who you would like to see serving on this board and why, thoughts on what characteristics would make for excellent board leadership and round out the perspectives available in Apereo.) (As often I speak here only wearing my individual contributor hat.) Vicky Brasseur With experience serving on the Open Source Initiative board, as an author and moderator on opensource.com, and as a professional software engineer, Vicky would be a valuable voice on the Apereo Board. Vicky has literally written the book on contributing to open source software. If Apereo can’t draw in Vicky’s attentions gratis through board service, I advocate Apereo hiring Vicky’s significant expertise through her consulting services. Audrey Watters Audrey is a very important voice of EdTech skepticism. It would be helpful to have her at the table. Karen Sandler Karen is executive director of the Software Freedom Conservancy. Karen would bring legal experience, including with the Conservancy’s perspective on the necessity of ICLAs experience directing a non-profit foundation with an annual budget on the same order of magnitude as Apereo experience in diversity and inclusion especially through her Outreachy work Apereo might learn much from Conservancy perspective. Tim Vertein My colleague Tim is a thoughtful, productive, effective professional with a proven commitment to the university and to serving university participants well. He’d make a great Apereo Board director for many of the same reasons he’d make a great Apereo fellow. Misagh Moayyed Misagh is the Apereo CAS project PMC chair. I think Apereo at the Board level has unrealized opportunity to better consider the perspective and experiences of the people working in Apereo projects. The disconnect between (relatively closed) Board governance and “100% open” projects might be alleviated through bringing those perspectives closer to the governance. Misagh has distinguished himself through thoughtful stewardship of the Apereo CAS project, one of the more successful Apereo projects in breadth of adoption, quantity of contributors, and in engineering attention to enabling divergent local configuration of a shared open source software product. Shane Curcuru Apereo sometimes tries to take Apache’s lead and presumably could do so even better informed by a board director who has experience and achievement in the Apache Software Foundation context, evident from Apache committership, Apache PMC membership, Apache Board Director experience, and Apache Foundation Membership. (Membership in the Apache Software Foundation is a big deal. You can’t buy it.) Membership in The Apache Software Foundation is a privilege and is by invitation only. Shane specifically has experience with Apache incubation and community development, both especially relevant to Apereo’s challenges. If Apereo can’t draw in Shane’s attentions gratis through Board service, I advocate Apereo hiring Shane’s significant expertise under the auspices of his open source community engagement consultancy, Punderthings Consulting. Pat Masson Pat is General Manager of the Open Source Initiative. Pat has experience with higher education and particularly with Apereo. The OSI’s experience is also relevant in that it has a successful individual membership program. As Apereo bootstraps its own individual membership program OSI’s experience might help catapault this to sustainability. Ben Balter Ben is a lawyer with an important perspective on tradeoffs in contributor license agreement rigor. Also, Ben’s experience in federal government service might be a helpful public service perspective on the board. Tim Carroll Tim is a current Apereo board member whose term is ending and who is available for re-nomination. It might be a fine thing to re-nominate Tim. He seems a voice of pragmatism on the board. On the public record, Tim shared an article on the open@ list engaged regarding the failed 2016 attempt to unburden Apereo ICLA policy. (I wish that had succeeded, but engagement was still better than not engaging with the issue). engaged regarding a proposal to create an open parallel to the closed projects@ email list (advocating using existing open@ for this purpose) voiced a way to un-stick a potential incubation Of the 8 Apereo board meetings in the past year for which minutes are available, 6 show Tim as attending (75%). Charles Severance Dr. Chuck is the Apereo Sakai project PMC chair. He also has experience serving as an Executive Director of an open source foundation and as a board member. This combination of executive, governance, and working-in-the-open-source-project perspectives could be highly valuable on the board. Bryan Ollendyke Bryan is tremendously passionate about Apereo-incubating ELMS:LN, about openness and about improving higher education and about the quality of community interactions. Bryan’s work is well-regarded. The energy, passion, sense of urgency, and bias for action he brings might in itself make his board term very worthwhile. A registrar Apereo ought to be adding tremendous value to the work of university registrars. What are the not-yet-realized opportunities in this space and would bringing a registrar’s perspective closer to the governance help? Another CIO Apereo ought to be adding tremendous value and leverage to the work of university CIOs, broadening the viable tactical and strategic options and having the side effect of pressuring proprietary and SaaS vendors to better serve education (out of a healthy concern about the alternatives available to universities). What are the not-yet-realized opportunities in this space and would bringing another CIO’s perspective closer to the governance help to realize those opportunties? Apereo Fellows I’d expect any of the Apereo Fellows would bring an informed perspective to the board. Others What experiences and perspectives would you like to see more of on the Apereo board? Who might bring those to bear? Is there an opportunity for that to happen? /Andrew Petro as individual contributor",
    "tags": "Apereo",
    "url": "/2018/04/20/nominate-to-board/"
  },

  
  
  
  {
    "title": "Apereo CAS - Test-Driving Feature Modules",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Overview Following up on my previous blog post on changing CAS source code in an overlay, in this exercise we are going to more or less repeat the same experience except that this time, we will be addressing the changes and workload from the perspective of the CAS codebase. This quick walkthrough effectively aims for the following objectives: A quick development environment setup using IntelliJ IDEA. Building and running the CAS web application using Gradle. Changing feature modules and testing out behavior. Stepping into the code using a debugger. Development Environment Follow the instructions posted here to obtain the CAS source code. Remember to indicate the relevant branch in the commands indicated to obtain the right source code for the CAS version at hand. In this tutorial and just like before, the branch to use would be 5.2.x. To understand what branches are available, see this link. Your CAS version is closely tied to the branches listed in the codebase. For example, if you are deploying CAS 5.1.8, then the relevant branch to check out would be 5.1.x. Remember that branches always contain the most recent changeset and version of the release line. You might be deploying 5.1.8 while the 5.1.x might be marching towards 5.1.10. This requires that you first upgrade to the latest available patch release for the CAS version at hand and if the problem or use case continues to manifest, you can then check out the appropriate source branch and get fancy [1]. Keep UpIt is STRONGLY recommended that you keep up with the patch releases as they come out. Test early and have the environment on hand for when the time comes to dabble into the source. Postponing patch upgrades in the interest of time will eventually depreciate your lifespan. To set up the project in IntelliJ IDEA, it might be preferable to run ./gradlew idea at the root of the project. This will attempt to generate the needed project files beforehand, allowing the development environment setup to proceed without many delays. Note that similar tasks are available for eclipse, etc. Running CAS The CAS web application itself can be started from the command-prompt using an embedded Apache Tomcat container. In fact, this process is no different than deploying CAS using the same embedded Apache Tomcat container which means you will need to follow the instructions posted here in the way that certificates and other configurations are needed in /etc/cas/config, etc to ensure CAS can function as you need it. All features modules and behavior that would be stuffed into the web application artifact continue to read settings from the same location, as they would be when activated from an overlay. The process is exactly the same. I use the following alias in my bash profile to spin up CAS using an embedded Apache Tomcat container. You might want to do the same thing, or create the equivalent script for other operating systems to reduce time and keystrokes: alias bc='clear; cd ~/Workspace/cas/webapp/cas-server-webapp-tomcat; \\ ../../gradlew build install bootRun --configure-on-demand --build-cache --parallel \\ -x test -x javadoc -x check -DenableRemoteDebugging=true --stacktrace \\ -DskipNestedConfigMetadataGen=true -DskipGradleLint=true -DskipSass=true \\ -DskipNodeModulesCleanUp=true -DskipNpmCache=true -DskipNpmLint=true' Then, I simply execute the following in the terminal: &gt; bc To understand the meaning and function behind various command-line arguments, please see instructions posted here. You may optionally decide to tweak each setting if you are interested in a particular build variant, such as generating javadocs, running tests, etc. One particular flag of interest is the addition of enableRemoteDebugging, which allows you, later on, to connect a remote debugger to CAS on a specific port (i.e. 5000) and step into the code. Bootiful CASAt this time, the availability of the bootRun task running from inside IntelliJ IDEA is not possible. Testing Modules Per instructions posted here, the inclusion of a particular build module in the build.gradle of the CAS web application should allow the build process to automatically allow the module to be packaged and become available. Since the CAS web application we are running is supported by Apache Tomcat, the reference to the CAS reCAPTCHA module can be included right there. Alternatively, you may also include the reference in the webapp.gradle file, which is the common parent to build descriptors that do stuff with the CAS web application. Making changes in this file will ensure it to be included by default in the generic CAS web application, regardless of how it is configured to run, which means you need to be extra careful about the sort of changes you make, what is kept and what is checked in here. That said, the webapp.gradle is usually where I myself put the module references in and I try to be extra careful to not keep them in the same file when I check changes in for review, etc. So for reference and our task at hand, the webapp.gradle file would look like the following: dependencies { ... implementation project(\":support:cas-server-support-captcha\") ... } Note the reference locates the module using its full path. The next time you run bc, the final CAS web application will have enabled reCAPTCHA functionality when it’s booting up inside Apache Tomcat. The remaining tasks are super similar to the earlier post; we locate the ValidateCaptchaAction component and make the relevant change there. We then run bc to run CAS locally again to test the change and lather-rinse-repeat until the desired functionality is there. Once done, you may the commit the change to a relevant branch (of your fork, which is something you should have done earlier when you cloned the codebase) and push upstream (again, to your fork) in order to prepare a pull request and send in the change. Debugging CAS One of the very useful things you can include in your build is the ability to allow for remote debugging via -DenableRemoteDebugging=true. Both IntelliJ IDEA and eclipse allow you ways to connect to this port remotely and activate a debugger in order to step into the code and troubleshoot. This is hugely useful, especially in cases where you can make a change to a source file and rebuild the component live and hot, reloading the .class file and allowing the changes to kick in the very next time execution passes through without restarting Tomcat. Depending on how significant the change is, this should save you quite a bit of time. So… I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Happy Coding, Misagh Moayyed [1] There are ways to get around this limitation, by specifically downloading the source code for the exact CAS version at hand. I am skipping over those since they only lead to complications, suffering and further evil in most cases.",
    "tags": "CAS",
    "url": "/2018/04/05/cas-codebase-feature-build/"
  },

  
  
  
  {
    "title": "Feedback on draft Apereo strategy",
    "text": "In which I comment on the draft strategic plan Apereo articulated for 2018. As often: I am speaking here wearing only my individual contributor hat. Feedback on Apereo strategy: focus on revenue to achieve sustainability TL;DR: Emphatically focus on recurring revenue to achieve sustainability. Aggressively defer everything not focused upon this. Context Apereo strategic plan Apereo failed to secure enough recurring revenue to retain a full-time position supporting Sakai (Sakai-specific funding) and more generally roughly broke even on recurring membership revenue. Vision (what future state are we trying to bring about?) TL;DR: Most higher education institutions will collaboratively develop, maintain, and locally implement free and open source software solutions meeting its needs, at all scales, and in all ways, doing this through and facilitated by Apereo. Unpacking this: Higher education will collaboratively develop, maintain, and locally implement free and open source software solutions meeting the needs of higher education. These will be directly valuable (delivering effective user experiences to higher education constituents is awesome) and will be indirectly valuable in the pitfalls they avoid, the choices they afford, and the effect they have on the proprietary software offered to higher education through inspiration and through competition. Higher education will do this at all scales, for example both at the handy little WordPress plug in end of things and the comprehensive lecture capture solution or learning management system or ERP end of things. Higher education will do this in all ways, and notably, not just through coding. The activities of collaboration and maintenance of effective free and open source software solutions meeting the needs of higher education are so very much more than just coding or even of developing novel software solutions. There’s value in communities of practice, in context for understanding higher-education-specific perspectives on more general open source software solutions, in exerting higher-education-serving influences on open source software projects with wider contexts beyond higher education. To give an example: apparently WordPress powers more than 30% of the Web, including a great many sites in and around higher education. Higher education doesn’t need its own WordPress-like thing. But higher education may very well have particular needs for plugins for WordPress, for ways of using WordPress, for problems to solve with WordPress, for experiences to share. There’s a there there in the “in higher education” part of “Using WordPress in higher education”. Higher education might particularly need WordPress plugins to fulfill accessibility and usability expectations, and might particularly need clarity about what WordPress implementation choices are and are not consistent with higher education’s especial needs to provide accessibility. There’s worthwhile work to be done and insights to share to facilitate higher education success in leveraging WordPress. Apereo will be the organization that enables higher education to succeed at this collaborative development, maintenance, and local implementation. Apereo will be the context for this work, particularly facilitating the cross-institutional aspects of this and the natural handoff of participation from institutions to institutions as time and circumstances evolve. Apereo will deliver identifiable value to higher education, value to any given member institution in excess of the membership fees borne by that institution. To give an example: Sakai is a free and open source by for and about higher education learning management system. Such a thing should very much exist and be a viable option. It does and is. Sakai deserves significant sustaining resources. The preeminent actually open source learning management system for higher education ought to be tremendously supported. Apereo qua Apereo should be adding lots of value to this. Most higher education institutions will be Apereo members, because most higher education institutions will be (already are) making significant use of free and open source software solutions and that use will be more effective and more confident because of the value Apereo is adding to it. If they’re not using Sakai as a learning management system or OpenCast for lecture capture or an open source ERP, they’re most certainly using WordPress or Drupal somewhere or are generating and transforming CSV files representing institutional data or integrating across SaaS vendor products or educators are using open source text editors to author lesson plans or… There’s tremendous breadth of opportunity for higher education to benefit from open source, so there’s tremendous breadth of opportunity for Apereo to add value to higher education’s benefiting from open source. Strategy: (how are we going to get to achieve this vision?) First and foremost, Apereo must achieve critical mass of recurring revenues (membership fees) to achieve sustainability. There are all sorts of opportunities to add value to collaborative open source in higher education. But to meaningfully pursue these, to meaningfully impact the world over the longer term, Apereo needs to exist with enough substance to be able to, well, do things. The thing about unsustainable things is that they’re really hard to sustain. Working towards the vision will require sustained effort for many years (forever?) and so achieving sustainability is essential. So here’s the strategy: Increase revenue Use all available resources, including revenue, to further increase revenue. Increase revenue Apply staff and other efforts to provide members a positive return on their membership investment. Apereo must deliver recognizable value to the members, value enough that the members are saying “Sure am happy to be paying for that membership, because we’re clearly getting more out of Apereo than we’re paying into it.” This will stabilize and retain revenue. Increase revenue through the increased memberships as more and more of higher education sees Apereo as a source of value very much worth sustaining. Increase revenue through (carefully targeted?) increased membership fees as more Apereo members are realizing more value from their Apereo membership. Use the increased revenue to add more value to higher education. Use the increased value to higher education to secure more revenue. Repeat until the vision is achieved (in practice, forever). The most important challenge here is that at the early end of this strategy Apereo is adding less value to higher education and so revenue, in the form of memberships, are harder to secure, whereas at the later end of this strategy Apereo is adding more value to higher education and so revenue, in the form of memberships, is easier to secure. The most existential risk is in the early phases. So the thing to do is to focus on escaping the early phases. So here’s what this strategy means: Focus entirely on things that will increase revenue (membership). Defer everything that won’t affect revenue (membership). Considering incubating a new open source software project? Is that project going to bring in more membership revenue? Yes? Pull it in. No? Hold off. Having a presence anywhere? Is that presence going to bring in more members, or is it necessary to retain existing members? No? Don’t go. Is securing ICLAs going to bring in new or retain members? Great, do it, more members are absolutely essential to sustainability. It’s not going to impact membership? Suspend the whole program. Is re-licensing a project from a New BSD license to an Apache2 license going to bring in more members, or is it necessary to retain existing members? Yes? Great, undertake that hassle. No? Defer it. Considering a partnership? Neat. Will it increase recurring membership revenue? Go for it. It won’t? It’s a distraction, defer it. Apereo cannot afford to do anything that isn’t increasing recurring revenue. Doing anything that isn’t increasing recurring revenue has the opportunity cost of not doing something more likely to increase revenue. Intentionally navigating these tradeoffs is essential to maximizing Apereo’s odds of having a meaningful influence a decade from now. This is painful. Opportunities that by other measures would be worthwhile must be foregone. But this is how to get to sustainability, and without sustainability, nothing else Apereo does is going to matter much over the long term. The idea isn’t to never do anything other than pursue recurring revenue. The idea is prioritize pursuing recurring revenue until recurring revenue is sufficient to afford the luxury of applying resources to pursue the organizational mission. Feedback on Apereo draft With this vision (higher education succeeding wildly by collaboratively meeting its needs through free and open source software) and strategy (achieve critical mass to enable Apereo adding value and doing so sustainably) in mind, here’s my feedback on Apereo’s draft strategic themes: 1. Membership, Financial Health and Fundraising In 2018 Apereo will focus on recruiting adopters of Apereo software and other educational and commercial organisations into an expanded foundation membership. Yes, do that. All of higher education should be Apereo members. Get far enough towards that to achieve sustainability. Consider reviving the individual membership program. Consider ways to price discriminate so that institutions that can pay more do. 2. Foundation Services &amp; New Ideas 2018 will see a review of key Apereo services to support the community, together with the elaboration of a process for introducing new services and areas of activity, and reviewing - and potentially retiring old ones. If adding a service will yield more members or is necessary to retain members, do it. If it won’t affect membership, defer it or suspend it. One kind of service that might widen memberships are those that affect breadth. A better implementation of more active discussion lists or chat might enable Apereo to widen scope into e.g. higher education knowledge sharing around WordPress plugins. Become the place for higher education to talk WordPress, to collaborate, to share – and maybe Apereo could reach 500 more people across 100 more institutions. Pull in 10% of those institutions as members and maybe we’re getting somewhere. Curtail services offered to non-members who aren’t going to become members. Look for opportunities to expand into spaces and activities that will increase membership with low or no additional infrastructure and services commitments. Job posting board reserved for members? Maybe members would value being able to post opportunities (presumably, about working with open source for the institution) to a context that reaches IT professionals likely to have experience with higher education and with open source? Speakers or consultants directory? Maybe members would value more ready leads on expertise about open source in higher education. Institutional project matching service? Maybe members would value leads on what others have experienced with specific open source technologies or attempting to leverage open source for specific kinds of projects. These may be terrible ideas. The lens for evaluating them is whether they will retain and increase membership revenue. 3. Software Community Health Apereo will explore the potential for a light-touch framework for expressing and communicating the health of constituent software communities during the course of 2018, as a contribution to greater transparency and adoption. This doesn’t sound like it will attract or retain membership revenues. If this isn’t going to bring in more members and it’s not essential to retain existing members, defer it. Apereo just can’t afford this. The constituent software communities are however healthy they are. They’ll do what they can do, or not, to determine and communicate health. There are some badging, checklisting, health assessing efforts afoot more generally in open source. That’ll have to be good enough. 4. Communications, Outreach and Engagement Apereo will expand its communications efforts across three principle audience axes - specific to role (CIO, Faculty, Learning Technologist, Student, Researcher), to interest area (specific software, theme or topic), and geographical region or country. Cut this down to only the communication efforts that will attract and retain members. That probably means focusing on helping CIOs to see value and urgency in Apereo membership, maybe targeting institutions that have already adopted Apereo software significantly (so, most likely to care) and in regions likely to be able to afford an Apereo membership (so, more likely to impact overall revenue more). It’s not that other kinds of communication aren’t valuable. It’s that Apereo can’t afford it until it can. Above-campus or cloud-based service provision, and its interaction with open source software, is a theme of specific interest that will be assigned priority in the coming year, particularly in terms of approaches taken in different parts of the world. If there’s any way to defer this, defer it. It sounds like a distraction from securing memberships. Communications and outreach is a critical enabler of objectives around membership and financial health. In particular community members will be encouraged and equipped to represent their engagement in Apereo activities, and use of Apereo software, as they engage with other associations they are active within - EDUCAUSE, AXIES, ALT etc. This sounds promising. The Foundation will continue to support a range of global, regional and individual software community events over the course of the coming year, seeking economies of scale by combination or linkage where appropriate, and working with partner organisations to increase effectiveness and reduce costs. Do as little of this as Apereo can get away with and leverage it as much as possible to draw in more members and retain existing members. 5. Partnerships Apereo will continue to seek partnerships with organisations with missions that overlap its own, or are complimentary. Pursue new and invest in existing partnerships only insofar as these will pull in more members and retain existing members. Consider reworking existing partnerships. For example, every French university should be an Apereo member. Apereo cannot afford to forgo this revenue, and ESUP cannot afford not to support Apereo in this way over the longer term in order to make the open source software ESUP relies upon more sustainable. We will act to promote LAMP as a solution for smaller institutions, and deepen our collaboration with ESUP-Portail, as it continues to grow the adoption of, and contribution to, an increasing range of Apereo software in France. Only do this if it’s going to increase membership. Investing in LAMP and ESUP should be through the lens of expected recurring revenue returns on that investment. 6. Development Opportunities and Recognition Programs It is appropriate that we review progress so far to encourage and resource further development, and additional strands of these [recognition] activities. 2018 will also see the exploration of a series of developmental activities for Apereo community participants, beginning to unlock the potential for further sharing of expertise across the broad community. Apereo can’t afford this. I imagine no institution became or remained a member because of an Apereo fellowship or an ATLAS award. (The Fellowship program in particular seems to have an interesting track record of fellows exiting Apereo contexts soon after their fellowship). by Andrew Petro as individual contributor",
    "tags": "Apereo",
    "url": "/2018/04/04/apereo-strategy/"
  },

  
  
  
  {
    "title": "Apereo CAS Best [Mal]Practice - Supercharged Overlays",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Overview There are a number of tutorials and overviews that describe the purpose and anatomy of a CAS Overlay. What is often left unsaid in these posts is the note that a CAS overlay, regardless of how it is orchestrated by your favorite hipster build tool of the week, can be used to override any and all CAS components that are configured and available at runtime where this not only includes somewhat static configuration such as property files, HTML views, and YAML configuration but also Java classes, solid source code and beyond. This brief walkthrough aims to uncover the magical ways one can tap into and alter the CAS source code from an overlay perspective, without quite dealing with the CAS codebase, for good and evil…but mostly evil. Why The most immediate question to address is along the lines of… Why would anyone ever want to do this? It more or less comes down to the following categories of rationale: There may be cases where analysis and troubleshooting of a CAS feature are not quite possible by simply reviewing DEBUG logs or changing configuration. You may need to access the source code to put in additional diagnostic information, include extra conditions to validate values, enforce availability of systems, etc. Likewise, there may be requirements whose implementation may need tapping into an internal CAS component for a change in behavior. This is the case where things work as intended, but not quite the way you envision the change to execute for your deployment. So you step in to change a false to true, remove an extra condition or add minimal behavior to support a new syntax for a configuration value, rename a field, etc. In almost all cases the changes that go into the overlay, specifically dealing with core components, are decent candidates for contributions and pull requests and ultimately should be removed from the overlay. Why Not Any time you are about to tap into CAS internals, you should pause and reconsider alternative approaches and subsequently the overall maintenance strategy of the change, especially if the reason for the change has to do with the second category of modifications noted above. Depending on scope and component, the change may not be forward-compatible at all, the original component may be heavily refactored or removed in future versions without mercy, the feature may get removed entirely and you may be forever left with local customizations that require maintenance and care for every build and future upgrade. This is the power of open-source where modifications come freely with code at hand…with the understanding that “You can do things on your own, but then, you would [mostly] be on your own”. Though put in somewhat extreme terms, consider this a best malpractice that if your CAS deployment overlay contains any .java code, chances are you are doing something wrong. There should be better routes and strategies on how to deliver the same end result and those should not solely and exclusively belong to your deployment. You are not that special. Given timeline and budget if you find no other strategy, always label the changes to be temporary and work as hard as you can to remove it. I could not tell you how many times I have been involved in deployments where the prospect has made significant modifications to CAS internals and… Has no clue how the changes work. …or the person responsible for the changes is no longer with the organization. …or there is no documentation and rationale for the now-outdated change. …or the organization has completely lost the original source code. …or the change is implemented in such a way that is not sustainable without major editorials. …or the change opens up the deployment to a security vulnerability. …or the change prevents the deployment from gaining a fix for a security vulnerability. etc. A Pinch of SaltOf course, there are reasonable exceptions here especially in areas where there are documented and/or recommended approaches to customizations and extending system behavior. The point is, consider all alternatives before stepping into a development mood. Having Said That Let’s consider a quick hypothetical use case with CAS 5.2.x and its support for Google reCAPTCHA. Suppose that you have an overlay that is adequately prepped with relevant intention modules and properties to make reCAPTCHA work. Things have been running just fine. Then comes a change in protocol from Google that changes the validation response to include the now-renamed field successful instead of the old success. The reCAPTCHA module in CAS obviously has not had a chance to catch up to this change and is still looking out for success in the validation response and begins to error out. What to do? Step #1: Identify the need to tap into the source code. Step #2: Rename the flag in the right .java component. Step #3: Build and test the behavior. A quick analysis of the reCAPTCHA module in CAS reveals src/main/java/org/apereo/cas/web/flow/ValidateCaptchaAction.java that in fact handles the validation by checking for the value of the success field in the response. Here is the relevant code snippet: ... final String response = in.lines().collect(Collectors.joining()); LOGGER.debug(\"Google captcha response received: [{}]\", response); final JsonNode node = READER.readTree(response); if (node.has(\"success\") &amp;&amp; node.get(\"success\").booleanValue()) { ... } ... The above snippet attempts read and transform the response into a JSON object, checking for the trueness of the success field. How do we apply the source code change in the overlay to now examine for successful? Overlay The Code In the root directory of the overlay project, (assuming a Maven overlay), run the following commands: # Create the directory path to match the component's package name mkdir -p src/main/java/org/apereo/cas/web/flow # Download the source file for the CAS version wget https://raw.githubusercontent.com/apereo/cas/5.2.x/support/cas-server-support-captcha /src/main/java/org/apereo/cas/web/flow/ValidateCaptchaAction.java \\ -P src/main/java/org/apereo/cas/web/flow/ # Run a sanity build to ensure the overlay is functional ./mvnw clean package RememberAll source code that is put into the overlay must be housed inside the src/main/java directory, followed by the exact path to the component noted by its package name. If the package name, for instance, is org.apereo.cas.support.web.flow, then the full path for the overlaid component would be src/main/java/org/apereo/cas/support/web/flow. All source code is compiled and placed inside the WEB-INF/classes parent directory. Notice there are a number of failures now reported by the Maven build complaining about missing symbols. This is due to the fact that the build is now trying to compile our downloaded version of ValidateCaptchaAction.java which itself depends on a number of other components and libraries that must be available at compile-time for the task to succeed. So we need to locate what and where the missing items are and get them added to the build script. Add Dependencies Modify the pom.xml to include the following: ... &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-captcha&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-web&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-webflow&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-configuration&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; ... Good Dependency HuntingTo know which dependencies and versions should be included when the build reports back errors on missing symbols, you will need to become familiar with the CAS codebase and the dependencies upon which this particular module (i.e. reCACAPTCHA) depends, both locally and globally. At this point, the code itself is the best documentation you could have available. Now we run the build again: # Run a sanity build to ensure the overlay is functional ./mvnw clean package …and the build should proceed normally. Great! Let’s make the change now. Make The Change Our next step is to find our Java code snippet above and make the following change: ... final String response = in.lines().collect(Collectors.joining()); LOGGER.debug(\"Google captcha response received: [{}]\", response); final JsonNode node = READER.readTree(response); if (node.has(\"successful\") &amp;&amp; node.get(\"successful\").booleanValue()) { ... } ... Rebuild and deploy. Things should now work as expected with the above change. Cool, eh? Wait…How? The short and simplified answer is that similar to how static content is overlaid and then preferred over what’s provided by default, local source code components are also made available in a similar fashion on a classpath route that is slightly prioritized over what is buried in some CAS .jar file. Due to this trick, when the runtime begins to locate the compiled ValidateCaptchaAction.class file, it scans the specialized classpath route first and thus finds our overlaid copy of it, deferring the default for later use. If you end up deleting the ValidateCaptchaAction.java from the overlay and thus removing its binary brother from the packaged build, the runtime will simply fall back onto what is provided by the cas-server-support-captcha module. So, Now What? As you can see, there are inherent dangers in this approach: The original contents of ValidateCaptchaAction could change from CAS version to version, thus invalidating your local copy of it. Your build is now that more complicated with the inclusion of a handful of extra modules to make a simple one-liner change work. Any of the now-included modules can be renamed or removed from CAS version to version, thus making your build dysfunctional in the future. …and just to demonstrate the problem, our change as it is most often the case, is completely undocumented! Without comparison against the original source file, it is entirely unclear why this source file exists in an overlay which would make it difficult for the next person in line to pick up the maintenance effort, two years into the deployment. But there is light at the end of the tunnel. Now that you have made a reasonable change and are satisfied with its behavior, the next best course of action would be to remove the file altogether (and every other change you made along with it) and contribute the fix back to the CAS codebase. This is NOT the sort of change that should be specialized for any single deployment and in the interest of “It Should Just Work”, the behavior of ValidateCaptchaAction should just do the correct thing by default, removing any learning curve or need for one to make changes. As a follow-up to this blog post, I will outline how the change can be developed and tested from the perspective of the CAS codebase itself. Stay tuned! Finale I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Happy Coding, Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/04/01/cas-overlays-supercharged/"
  },

  
  
  
  {
    "title": "CAS 5.3.0 RC3 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.2.0 GA was released on November 27th, 2017. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.3.0. This post intends to highlight some of the improvements and enhancements packed into the third release candidate in the 5.3.0 series. The in-development documentation of CAS 5.3.0 is available here. The release schedule is also available here. The release policy is available here. You can read about the previous release candidate here. Shake Well Before Use Apache Maven Gradle Minors SAML Service Provider Metadata via REST OAuth2 Audits SAML2 Service Providers Couchbase 5 Compatibility Couchbase Authentication Attributes Registered Service Access Strategy Audits Impersonation Audits Delegated Authentication Access Strategy Audits Audit API Improvements Impersonation Groovy Access Strategy X.509 Authentication via Request Headers CAS Protocol Behavior Bootstrap 4 Google Authenticator Multifactor Account Registration Multifactor Trusted Devices YubiKey Account Public ID Encryption Service Registry Multiplicity Embedded Apache Tomcat Session Clustering Delegated Authentication Non-Sticky Sessions Library Upgrades Get Involved Das Ende Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. In order to start experimenting with release candidates, use the following strategies. At any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Apache Maven In the pom.xml of the overlay, adjust the following tag to match below: &lt;cas.version&gt;5.3.0-RC3&lt;/cas.version&gt; Gradle In the gradle.properties of the overlay, adjust the following setting to match below: cas.version=5.3.0-RC3 Minors CAS integration tests for Couchbase, DynamoDb and InfluxDb are now automated/enabled via relevant Docker images running as part of Travis CI. Thanks to @frett, TGC domain names are once more sanitized; an oversight that snuck into CAS after adopting Project Lombok. Thanks to @luis100, delegating authentication to SAML IdPs now is able to handle urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST bindings. Thanks to @tsschmidt, loading CAS configuration properties is now made conditional. Thanks to @sbearcsiro, overflows when calculating ticket expirations in MongoDb are now prevented. Thanks to @frett, multifactor authentication triggers based on principal/authentication attributes are now allowed to proceed in the absence of a service parameter. CAS builds managed by Travis CI are now broken into multiple jobs using a matrix to account for faster execution times. SNAPSHOT releases tend to publish around the 30 minute mark! Thanks to @dodok1, multiple RADIUS servers can now be specified in CAS properties, separated by comma. Thanks to @fmartelli, delegated SAML2 authentication gains a new settings to allow for the specification of the AttributeConsumingServiceIndex exposed by Pac4j. CAS proxy-granting ticket definitions are now correctly registered in the ticket catalog. Thanks to @sbearcsiro, a number of time units in CAS are now corrected to properly recognize seconds instead of milli-seconds. CAS configuration metadata is corrected to properly generate the needed JSON metadata based on configuration settings. Thanks to @sbearcsiro, the embedded Apache Tomcat instance is tweaked using a Customizer component provided by Spring Boot so that CAS implementations can override the factory themselves (eg to enable JNDI) whilst also benefitting from the CAS tomcat configuration properties. Specification of required authentication handlers for a service now does not intefere with the execution of multifactor authentication. Thanks to @hdeadman, the OpenID Connect discovery profile is now able to properly render all settings, and should be able to list all grant types supported by CAS. Thanks to @frett, the REST API responsible for generating service tickets can now correctly audit the authentication object. Thanks to @sbearcsiro, the embedded tomcat configuration is refactored and moved into its own component. OAuth codes issued by CAS running as an OpenID Connect provider are now strictly scoped to the requesting service when exchanged for access tokens. Thanks to @swlyons, the table names for the DynamoDb Ticket Registry can now be customized in CAS settings. SAML Service Provider Metadata via REST SAML2 service provider metadata can now be fetched from more traditional REST endpoints, as an alternative to deploying an MDQ server. See this guide for more info. OAuth2 Audits Thanks to @dima767, OAuth2 and OpenID Connect interactions (authentication requests and user profile responses) with CAS are now sent to the audit log. SAML2 Service Providers The following new SAML2 service providers are now supported by CAS out of the box: Concur Solutions PollEverywhere Couchbase 5 Compatibility Thanks to @dima767, CAS integration tests for service/ticket registries are now verified and made functional against Couchbase 5. Additional test cases are also added to verify Couchbase authentication. Couchbase Authentication Attributes Similar to above, authenticating credentials against a Couchbase data store in CAS now gains the ability to also fetch attributes as part of the returned data row. Registered Service Access Strategy Audits Thanks to @dima767, service access strategy events are now sent to the audit log in the event that the principal does not carry enough attributes to be granted access. Impersonation Audits Thanks to @dima767, CAS impersonation attempts. that were put through the access strategy rules are now audited as well. Delegated Authentication Access Strategy Audits While delegating authentication to an external identity provider, access strategy events that enforce the usage of the external identity provider are now sent to the audit log. Audit API Improvements In collaboration with @dima767, CAS components that are typically not managed as Spring @Beans are now put through a mini framework so that can become eligible for auditing purposes. The API changes in this area, while non-intrusive, allow CAS to audit the likes of the services access strategy events noted above. Impersonation Groovy Access Strategy Impersonation features of CAS gain access to a Groovy option to execute authorization rules for surrogate authentication. X.509 Authentication via Request Headers Thanks to @hdeadman, X509 authentication now optionally gains the ability to extract the certificate from a request header. CAS Protocol Behavior Certain aspects of the CAS protocol such as proxy or renewed authentication can be controlled via CAS settings. Bootstrap 4 Thanks to @mindblender, CAS user interfaces begin to take advantage of Bootstrap v4 and FontAwesome v5. The thymeleaf templates are also transformed to be easier to maintain as natural/native views. Google Authenticator Multifactor Account Registration Multifactor athentication provided by Google Authenticator in CAS has the ability to register users and devices as part of the authentication flow. In this release candidate, device registration records are by default signed/encrypted before they are stored in the registration store. WATCH OUT!This may be a breaking change. While the setting is on by default, you can certainly disable the signing/encryption operations of CAS that deal with device registration. Multifactor Trusted Devices Thanks to @frett, Multifactor Trusted Devices support has been extended to support custom device fingerprinting strategies. WATCH OUT!This may be a breaking change. Adding custom device fingerprint support necessitated a schema update for trust records. Furthermore, this feature gains the ability to determine device fingerprints in order to distinguish trusted devices from each other. YubiKey Account Public ID Encryption Thanks to @dima767, the YubiKey authentication facility gains the ability to store account’s public key in target destination stores in the encrypted form Service Registry Multiplicity Interal improvements are in place to allow each module the capablity of hosting its own service registry, making CAS effectively able to work with more one service registry at the same time. In theory, this provides the option of having, for instance, both JSON and YAML service registries work together. The real motivation for this change is to allow the introduction of internal immutable service registries that may be ephemeral, specially in view of how CAS handles multiple protocol support with callback services that were, before this change, expected to be inserted and found in the service registry. Embedded Apache Tomcat Session Clustering The embedded Apache Tomcat is now altered slightly using options to allow for session clustering and replication. Delegated Authentication Non-Sticky Sessions Delegated authentication in CAS has been re-designed in certain areas to remove the requirement of sticky sessions specially in clustered deployments. The internal changes to accomodate this behavior are rather significant, so please be sure to test and contribute back lest issues are discovered. This behavior is also extended to include and support delegating authentication to ADFS instances. Library Upgrades Couchbase Java Client Amazon Java SDK Mockito SemVer Swagger Disruptor Eureka Ribbon ActiveMQ InfluxDb Apache CXF JavaParser Guava Azure KeyVault Okio Yubico Authy Google Zxing Yubico U2F Maxmind Google Maps UnboundID Gradle Twilio Postgresql Driver MariaDb Driver Jose4j Bootstrap &amp; FontAwesome Apache Cassandra Driver Font Awesome Hazelcast Jackson JQuery Thymeleaf Dialect HikariCP Caffein Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Das Ende Big thanks to all who participate in the development of this release to submit patches and contribute improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2018/03/30/530rc3-release/"
  },

  
  
  
  {
    "title": "Apereo CAS - REFEDS MFA Profile with shib-cas-authn3",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. This is a short story on the birth of the shib-cas-authn3 plugin and its newfound support for the REFEDS MFA Profile. Overview Though nowadays less so, you may have an IAM deployment composed of both an Apereo CAS Server and a Shibboleth Identity Provider. The original premise for managing such a deployment dates back to days where CAS v3 had [almost] no support for the SAML2 protocol and likewise, the Shibboleth Identity Provider v2 lacked support for the CAS protocol. To accommodate all integration needs, institutions deployed both solutions and then set in pursuit of a way to close the space between the two to provide a seamless user experience. …and by seamless, I mean: How could one manage SSO sessions between the two platforms? How could one fetch and release attributes to SAML2 SPs? How could one handle single logout? How would the user interface elements behave with regards to SAML2 MDUI? … Viola! So was born the shib-cas-authn3 plugin. The plugin simply acts as a link between the two platforms, allowing authentication requests from the Shibboleth IdP to be routed “invisibly” to CAS and then back. Conceptually it sits between the two systems, (though physically it lives inside the IdP), and knows how to translate one protocol (SAML2) to another (CAS) and then does it all in reverse order on the trip back to the SAML service provider. This is a neat trick because to the SAML2 Service Provider, that fact that authentication from the IdP is delegated to somewhere else is entirely irrelevant. Likewise, the Shibboleth IdP also does not care what external authentication system handles and honors that request. All it cares about is, “I routed the request to X. As long as X gives me back the right stuff, I should be fine to resume”. Author’s Note I say nowadays less so because today, the Shibboleth IdP v3 has great support for the CAS protocol and Apereo CAS v5 has native support for the SAML2 Protocol. While “separation of concerns”, “leaving each to its own” and having “boxes and arrows” pointing back and forth and living in perfect harmony in a pretty diagram are excellent conditions to live by, it would be best to consolidate down to one system since the concerns are no longer separate and more so, they tend to cost money and strands of hair quite a bit over time. Given the right circumstances and support, the Majestic Monolith can be sweet. Handling REFEDS MFA Profile So then comes the REFEDS MFA Profile: This Multi-Factor Authentication (MFA) Profile specifies requirements that an authentication event must meet in order to communicate the usage of MFA. It also defines a SAML authentication context for expressing this… And: The MFA Authentication Context can be used by Service Providers to request that Identity Providers perform MFA as defined below and by IdPs to notify SPs that MFA was used. In more complicated terms, if a SAML SP were to specify https://refeds.org/profile/mfa as the required authentication context, the identity provider would need to translate and find the appropriate MFA solution to execute in order to satisfy that requirement and then reassuringly convey the result back to the SP. How could we do this with the Shibboleth Identity Provider, Apereo CAS server, and the shib-cas-authn3 plugin all having their bit of fun in the flow? One Solution Consider the following starting positions: Since Apereo CAS is ultimately in charge of executing authentication, it would also be the party in charge of executing multifactor authentication. Our strategy for delivering MFA in response to https://refeds.org/profile/mfa would be one backed by Duo Security, easily supported by CAS. Our task list then would be to find ways to: …communicate the requested authentication context to CAS. …translate the requested authentication context to something CAS would understand as a trigger for Duo Security MFA. …ensure the requested authentication context is satisfied by CAS, before handing off a response to the SP. Say hello to shib-cas-authn3 v3.2.4. CollaborateAs of this writing, 3.2.4 is still in beta. Download, deploy, verify and contribute back enhancements as time and DNA permits. Staring with v3.2.4, the plugin has native support for REFEDS MFA profile. The requested authentication context class that is https://refeds.org/profile/mfa is passed along from the Shibboleth IdP over to this plugin and is then translated to a multifactor authentication strategy supported by and configured in CAS (i.e. Duo Security). The CAS server is notified of the required authentication method via a special authn_method parameter by default. Once a service ticket is issued and plugin begins to validate the service ticket, it will attempt to ensure that the CAS-produced validation payload contains and can successfully assert the required/requested authentication context class. For additional info on configuring the plugin, please see the project’s README. So… I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS MFA SAML",
    "url": "/2018/02/26/shibcasauthn-duomfa-refeds/"
  },

  
  
  
  {
    "title": "Forced Authentication with Apereo CAS",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. This post summarizes a recent conversation I had with a few colleagues on strategies one may use to support forced authentication with CAS and the journey we went on to discover and diagnose a few integration issues with an application protected by mod_auth_cas. Let’s begin. The Problem Some CAS deployments present with the rather common requirement to challenge the user to re-enter credentials in some applications. To accommodate this, it’s likely that deployments may opt into creative yet non-standard solutions such as applications themselves prompting for credentials to replay them in a back-end call. This is problematic for a number of reasons: Applications present a differently styled login form. Applications directly get involved in handling user credentials. Last but most important: The only thing necessary for the triumph of evil is for good men to replay credentials. So, is there a way to force re-authentication with CAS? Forced Authentication The CAS protocol has a specific parameter dedicated to forced authentication, named as renew=true. If supplied as part of an authentication request: Single sign-on will be bypassed. In this case, CAS will require the client to present credentials regardless of the existence of a single sign-on session with CAS. If supplied as part of a validation request: Ticket validation will only succeed if the service ticket was issued from the presentation of the user’s primary credentials. It will fail if the ticket was issued from a single sign-on session. Version CaveatIf you have deployed CAS 5.2.x, you need to at least be on 5.2.3 for the renew parameter to function correctly. It goes without saying that renew=true works best if you wish to let the application make that decision when needed. Alternatively, you may also control this behavior centrally by marking the relevant application/service in the CAS service registry (JSON file, etc) such that it would not participate in SSO and would always be asked for credentials regardless of what the application says. Real Life Example Let’s say we have an application at https://secure-dev.example.org/groups/ that has SSO enabled. We need one subfolder of that app at https://secure-dev.example.org/groups/reauth/ to require re-authentication to access. So, (assuming a JSON service registry), we have one service registration record requiring SSO to cover any app on the host. Note that SSO participation is by default on and it’s perfectly good for us to practice laziness here. { @class: org.apereo.cas.services.RegexRegisteredService serviceId: ^https?://[\\w]+-dev.example.org/.* name: secure-dev.example.org id: 1200 description: Everything evaluationOrder: 1200 } We set up another service registration with a lower (i.e. processed first; think of it like the Olympics rankings) evaluation order and ssoEnabled: false to cover the subfolder: { @class: org.apereo.cas.services.RegexRegisteredService serviceId: ^https?://[\\w]+-dev.example.org/groups/reauth/.* name: secure-dev.example.org Groups Reauth id: 1200 description: Groups Reauth evaluationOrder: 1100 accessStrategy: { @class: org.apereo.cas.services.DefaultRegisteredServiceAccessStrategy ssoEnabled: false } } Our application, protected by mod-auth-cas has the following configuration: &lt;Location /groups/reauth&gt; AuthType CAS AuthName \"CAS\" CASScope /groups/reauth CASAuthNHeader SOME_LoginID CASScrubRequestHeaders On CASCookie MOD_AUTH_CAS_REAUTH Options None require valid-user Order allow, deny Allow from all &lt;/Location&gt; &lt;Location /groups&gt; AuthType CAS AuthName \"CAS\" CASScope / CASAuthNHeader SOME_LoginID CASScrubRequestHeaders On CASCookie MOD_AUTH_CAS Options None require valid-user Order allow, deny Allow from all &lt;/Location&gt; At first glance, this should do exactly as you would expect if only it weren’t for a small caveat. The Caveat If the request begins with https://secure-dev.example.org/groups/reauth/ first and then goes to https://secure-dev.example.org/groups/, the user would be prompted to log in - as expected because those locations use different cookie names. However, once logged in, the user would get caught in a redirect loop between mod_auth_cas and CAS. It turns out that there were two issues. One was that more precise location is placed first in the config: &lt;Location /groups/reauth&gt; CASCookie MOD_AUTH_CAS_REAUTH CASScope /groups/reauth/ ... &lt;Location&gt; &lt;Location /groups&gt; CASCookie MOD_AUTH_CAS CASScope / … &lt;Location&gt; This made mod_auth_cas use the last applicable CASScope directive which meant that the MOD_AUTH_CAS_REAUTH cookie was being set at Path=/ instead of Path=/groups/reauth/. This might have been fine except for the way mod_auth_cas parses the values in the Cookie header. It tokenizes the header on ; then iterates through each cookie string by matching the number of characters equal to the length of the expected cookie name defined by the CASCookie directive. If the cookie string starts with the CASCookie name, it skips the next character, assuming that it’s = and takes all remaining characters. So what was happening was that, given the cookie header Cookie: BLARG=WuzzleWuzzle;MOD_AUTH_CAS_REAUTH=foofoofoofoo;, mod_auth_cas was matching the cookie string MOD_AUTH_CAS_REAUTH=foofoofoofoo with the CASCookie name of MOD_AUTH_CAS. Finding that, it skipped the _ and returned REAUTH=foofoofoofoo as the CAS cookie value. That isn’t a valid format for a CAS cookie so it redirected back to CAS. CAS, finding a valid TGC, then performed SSO and redirected back to the service. The service ticket was never validated because mod_auth_cas checks for the presence of a cookie before it checks for the ticket parameter. Finding the invalid cookie again, it redirected back to CAS and so on until the browser threw up its hands in defeat. So, just something to look out for: When using mod_auth_cas, configuration elements that share a scope (e.g. /groups, /groups/reauth) MUST be listed in order of least to most precise. The CASCookie directives that share a scope MUST NOT be substrings of each other. Summary I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. …and of course, a very special thanks to all colleagues who took part in this post, exchanged dialogue, verified behavior and generously took the time to share their analysis and findings. Thank you. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/02/26/forcedauth-modauth-cas/"
  },

  
  
  
  {
    "title": "Apereo CAS - Dances with Protocols",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. I have been consulting on variations of a deployment strategy and use case that involves CAS acting as an identity provider while also presenting the ability to delegate authentication requests to an external identity provider and act as a proxy in between. I had the erroneous assumption that client applications integrating with CAS in proxy mode must be those that speak the CAS protocol. This meant that while CAS itself may delegate authentication requests to a variety of identity providers that speak SAML2, OAuth2 and CAS protocols, etc the client application that ultimately would receive a response from the proxying CAS server can only understand a service ticket and the particular validation payload compliant with the CAS protocol semantics. This post is an attempt at explaining my rationale with a follow-up explanation of why I was wrong. Delegated Authentication Flow The normal flow for delegated authentication is something like this: Client application submits a CAS Protocol authentication request to the CAS server. CAS Server routes the request to an external identity provider, whether manually or automatically, and processes the response. When successful, CAS Server establishes an SSO session, creates a service ticket and redirects back to the client application with that ticket. Client application validates the ticket and understands the user profile elements. Once the response is processed by the external identity provider, note that the opinion is built into the CAS authentication flow to assume the next steps to be “creating a service ticket” and “redirecting back to the calling service/application with that ticket”; details which are dictated by the CAS protocol and obviously no longer apply if the client application is a SAML SP or OAuth2 client. So… If the client application were to submit an authentication request using a protocol other than CAS, it would be only fair for the application to expect a response using the same protocol. But, how could it ever work with the CAS server always issuing service tickets and 302-redirecting back to the application? Explanation It turns out that given the CAS design, client applications can speak any type of protocol that CAS itself supports today regardless of the authentication flow. For better or worse, this feature has to do with how secondary protocols (those other than CAS itself) are implemented. All other authentication protocols supported by the CAS server happen to be clients of the CAS server itself. The SAML2 module, OAuth2 module and anything else supported in CAS accept the original authentication request at the relevant endpoint, then route that request to the CAS server turning themselves into individual tiny CAS clients. At the end of the day and just like before, the CAS server creates a service ticket and issues a request back to the calling application, which in this case happens to be itself and the relevant endpoint inside itself that is to going to pick up the request and resume. The Protocol Dance Let’s start with a client application that speaks SAML2. This client is configured in CAS as a SAML2 service provider, while CAS itself is proxying Facebook as an external identity provider. This is a bit of a complicated scenario since you have about three protocols dancing together. The effective flow would be: The SAML2 client sends an authentication request to the CAS server. The SAML2 module in CAS processes the authentication request, sees the need for authentication and routes the request to the CAS server’s login endpoint. Very importantly, it indicates in that request that the calling service is the SAML2 module and the endpoint expected to do follow-up processing. Just like before, CAS Server routes the request to an external identity provider (Facebook in our case), whether manually or automatically, and processes the (OAuth2) response. When successful, CAS Server establishes an SSO session, creates a service ticket and redirects back to the SAML2 module (a complicated yet humble corner of itself effectively) that now is tasked to produce a SAML2 response. The SAML2 module receives the service ticket, validates it and understands the user profile via the provided assertion. It then produces the SAML2 response for the original client application. Possible GotchaThe above flow may prove to be somewhat dysfunctional, if the delegated/proxied identity provider happens to be ADFS. If your deployment today requires the above flow with ADFS acting as the identity provider, please suspect and verify. So… The trick, if I could re-emphasize, is noting that all protocols are clients of the CAS server that interact with it using the CAS protocol. This is done at the request/browser level, as opposed to doing things internally via heavily customized webflows and such that would be entangled with one another. The protocol modules that exist in CAS make zero assumptions about the internal inner workings of the CAS authentication flow/engine. They treat it just like they would an external CAS server; the only difference is, they sit and live inside the CAS server directly and yet they remain completely agnostic of that fact. Simply put in our example, the SAML2 module basically says: “this incoming request needs to be authenticated. So I’ll route it to a CAS server for authentication and when it comes back, I’ll do my bit”. This surely continues to maintain SSO sessions as well for all follow-up requests, because the CAS server does not care about the calling party; whether external or internal, the SSO session will be established and available for everything else. References More notes on the design are available here. Summary Remember; the client originating the authentication request can use ANY protocol supported by CAS, so long as CAS is configured to accept and recognize that protocol and regardless of whether CAS is acting as a proxy or directly authenticating the user via its own internal data stores. I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/02/26/cas-delegation-protocols/"
  },

  
  
  
  {
    "title": "Why does uPortal use Apache 2 license?",
    "text": "I’d be interested to hear what licenses other projects were using, and why? What license does uPortal use? The easy part of the question: uPortal is using Apache License 2.0. Why did uPortal license away from New BSD, its original license? The hard part of the question: why? In the beginning (in the JA-SIG, or JASIG, or Jasig days), uPortal used the BSD 3-Clause aka New BSD license. In the run up to merging with the Sakai Foundation to become the Apereo Foundation, Jasig adopted the position that New BSD is not good enough, which is now Apereo’s documented position. This license simply does not provide enough protection for either contributors or adopters to really understand the terms under which the software is being shared. (I don’t agree with this statement. New BSD meets the Open Source Definition, and it thoroughly disclaims warranties and liabilities. Good enough is good enough. I’d have no qualms about contributing to or adopting a New BSD licensed software product.) GNU says this about 3-clause BSD: The modified BSD license is not bad, as lax permissive licenses go, though the Apache 2.0 license is preferable. … the Apache 2.0 license is better for substantial programs, since it prevents patent treachery. Maybe how badly you want to re-license away from New BSD hinges on how worried you are about patent treachery. Some people worried. So Jasig required uPortal to re-license. So that’s why not New BSD. Why did uPortal re-license to Apache2, its current license? I don’t recall just how Apache2 was selected, who did the selecting, what alternatives were considered. I don’t even recall if this is something I once knew and have forgotten. A 2008 document in the Jasig wiki, Open Source Licensing, (by Unicon / John Lewis) recommends Apache2 for the non-copyleft case and might have been influential. Guessing at what might have happened: Do what the Apache Software Foundation does. Apache2 is widely adopted, widely understood, well documented, the practices around it are well documented and honed by the Apache Software Foundation. It’s not just a viable license, it’s a viable license ecosystem. Nobody has to apologize for adopting Apache2, it’s one of those default, acceptable, generally recognized as safe licenses? ECLv2 would also be fine, it’s just less mainstream. uPortal’s adopters and communities weren’t already worked up about Apache2’s patent language so there wasn’t enough reason to start getting worked up about that. - Andrew Petro wearing individual contributor hat. The views expressed herein are not necessarily those of Apereo, nor of uPortal, nor of my employer, nor of…",
    "tags": "uPortal Licensing",
    "url": "/2018/02/20/apache2-chose-uportal/"
  },

  
  
  
  {
    "title": "Apereo CAS - Attribute-based Application Authorization",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. A fairly common CAS deployment use case is to enforce access to a particular set of applications via user attributes and roles. Once the authentication/authorization server passed on the required attributes and entitlements to the application, each service might individually be tasked with controlling entry access, and once authorized, enforcement of a set of specific functions inside the application which the user may be allowed to carry out. The purpose of this tutorial is to present an alternative to the first scenario, by providing options to centrally control and manage that ruleset that allows the user to enter an application that is integrated with Apereo CAS. Our task list is rather short: Configure CAS to fetch attributes from LDAP, JDBC and other potential sources. Register an application with CAS and define authorization rules for access based on retrieved attributes. To keep this tutorial simple, we are going to stick with the default CAS method of authentication with the obvious assumption that our authentication sources shall be different from sources that may produce user attributes. Environment CAS 5.2.x CAS Maven WAR Overlay Follow the instructions provided by the README file to produce a functional build. Attribute Retrieval Attribute resolution strategies in CAS are controlled by the Person Directory project. The Person Directory dependency is automatically bundled with the CAS server and provides a number of options to fetch attributes and user data from sources such as LDAP, JDBC, etc. Since we do have multiple sources of attributes, the Person Directory component is also able to aggregate and merge the results and has options to decide how to deal with disagreements in case two sources produce conflicting data. There is very little left for us to do other than to teach CAS about our specific data sources. LDAP Attribute Retrieval In the given cas.properties file, the following settings allow us to fetch attributes from LDAP: cas.authn.attributeRepository.ldap[0].baseDn=ou=people,dc=example,dc=org cas.authn.attributeRepository.ldap[0].ldapUrl=ldap://localhost:1385 cas.authn.attributeRepository.ldap[0].userFilter=uid={0} cas.authn.attributeRepository.ldap[0].useSsl=false cas.authn.attributeRepository.ldap[0].bindDn=... cas.authn.attributeRepository.ldap[0].bindCredential=... cas.authn.attributeRepository.ldap[0].attributes.displayName=displayName cas.authn.attributeRepository.ldap[0].attributes.givenName=givenName cas.authn.attributeRepository.ldap[0].attributes.mail=email The above configuration defined the very basic essentials as far as LDAP connection information while also teaching CAS the set of attributes that should be first retrieved and optionally remapped. In practice, CAS would begin to fetch displayName, givenName and mail from the directory server and then process the final collection to include displayName, givenName and email. From this point on, CAS only knows of the user’s email address under the email attribute and needless to say, this is the attribute name that should be used everywhere else in the CAS configuration. Multiple SourcesCAS settings able to accept multiple values are typically documented with an index, such as cas.some.setting[0]=value. The index [0] is meant to be incremented by the adopter to allow for distinct multiple configuration blocks JDBC Attribute Retrieval The table table_users in our HyperSQL database contains the user attributes we need: uid attribute value casuser role Manager casuser role Supervisor user2 role Engineer The above schema is what’s referred to as a Multi-Row setup in the Person Directory configuration. In other words, this is the sort of setup that has more than one row dedicated to a user entry and quite possibly similar to above, multiple rows carry out multiple values for a single attribute definition (i.e. role). In order to teach CAS about this setup, we could start with the following settings: cas.authn.attributeRepository.jdbc[0].attributes.role=personRole cas.authn.attributeRepository.jdbc[0].singleRow=false cas.authn.attributeRepository.jdbc[0].columnMappings.attribute=value cas.authn.attributeRepository.jdbc[0].sql=SELECT * FROM table_users WHERE {0} cas.authn.attributeRepository.jdbc[0].username=uid cas.authn.attributeRepository.jdbc[0].driverClass=... cas.authn.attributeRepository.jdbc[0].user=... cas.authn.attributeRepository.jdbc[0].password=... cas.authn.attributeRepository.jdbc[0].url=... Pay attention to how the columnMappings setting defines a set of 1-1 mappings between columns that contain the attribute name vs the attribute value. Furthermore and similar to the LDAP setup, we are teaching CAS to fetch the attribute role (again, determined based on the mappings defined) and virtually rename the attribute to personRole. Just like the LDAP setup and from this point on, CAS only knows of the user’s role under the personRole attribute and needles to say, this is the attribute name that should be used everywhere else in the CAS configuration. Smoke Test At this point, you should be able to authenticate into CAS and observe in the logs that the constructed authenticated principal contains the following attributes: ... &lt;Authenticated principal [casuser] with attributes [{personRole=[Manager, Supervisor], displayName=Test User, givenName=CAS, email=casuser@example.org}] ...&gt; If you need to troubleshoot, the best course of action would be to adjust logs to produce DEBUG information. Application Registration The CAS service management facility allows CAS server administrators to declare and configure which services/applications may make use of CAS in different ways. The core component of the service management facility is the service registry that stores one or more registered services containing metadata that drives a number of CAS behaviors including authorization rules. To keep this tutorial simple, we are going to use the JSON Service Registry. This registry reads services definitions from JSON configuration files on startup. JSON files are expected to be found inside a configured directory location and this registry will recursively look through the directory structure to find relevant JSON files. For this tutorial, we expect CAS to find our JSON registration record files using the following setting: cas.serviceRegistry.initFromJson=false cas.serviceRegistry.json.location=file:/etc/cas/config/services …and inside the above directory, we are going to create an ExampleApplication-100.json file that contains the following: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://example\\\\.application\\\\.edu.*\", \"name\" : \"ExampleApplication\", \"id\" : 100, \"evaluationOrder\" : 1 } All that remains for us is to decorate the registration record with the authorization rules. Application Authorization Rules The access strategy of a registered service provides fine-grained control over the application authorization rules. It describes whether the service is allowed to use the CAS server, allowed to participate in single sign-on authentication, and (as it’s relevant for our use case here) it may also be configured to require a certain set of attributes that must exist before access can be granted to the service. RememberCAS is only gatekeeping here, deciding whether entrance is allowed to the given application. Once the user is allowed to enter, the extent of capabilities and functions available to the user are and must be decided by the application itself where CAS at that point would completely step aside. Our JSON registration record could be modified as such: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://example\\\\.application\\\\.edu.*\", \"name\" : \"ExampleApplication\", \"id\" : 100, \"evaluationOrder\" : 1, \"accessStrategy\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceAccessStrategy\", \"requiredAttributes\" : { \"@class\" : \"java.util.HashMap\", \"personRole\" : [ \"java.util.HashSet\", [ \"Manager\" ] ] } } } In simpler terms, the above configuration is saying: Access to applications that interact with CAS whose URL matches the pattern defined by the serviceId is only granted if the authenticating user has an attribute personRole that contains the value Manager. Summary I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/02/20/cas-service-rbac-attributeresolution/"
  },

  
  
  
  {
    "title": "CAS 5.3.0 RC2 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.2.0 GA was released on November 27th, 2017. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.3.0. This post intends to highlight some of the improvements and enhancements packed into the second release candidate in the 5.3.0 series. The in-development documentation of CAS 5.3.0 is available here. The release schedule is also available here. The release policy is available here. You can read about the previous release candidate here. Shake Well Before Use Apache Maven Gradle Minors Hazelcast Discovery Apache Syncope Authentication Operation Lombok HTTP Security Headers per Service Registered Services REST API Configuration Discovery SAML2 Service Providers JSON Whitelist Authentication REST Protocol Credential Extraction AWS Credential Fetching Mapped Attribute Value Filters Authenticate Credentials via REST Protocol REST Protocol Enhancements REST-based Audits SAML2 Attribute Friendly Names Configuration Binding Behavior New Command-line Shell Commands SAML2 Audits OAuth2 Audits REST API Audits Audit Trail Management Authentication Throttling MongoDb Authentication Throttling Library Upgrades Get Involved Das Ende Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. In order to start experimenting with release candidates, use the following strategies. At any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Apache Maven In the pom.xml of the overlay, adjust the following tag to match below: &lt;cas.version&gt;5.3.0-RC2&lt;/cas.version&gt; Gradle In the gradle.properties of the overlay, adjust the following setting to match below: cas.version=5.3.0-RC2 Minors The embedded Apache Tomcat container is now given the ability to support basic authentication. Caching attributes fetched from external attribute repositories is now corrected to handle caching more efficiently. Thanks to @leleuj, MFA bypass via REST is corrected to format parameters properly for the REST request. Thanks to @alexdp, the Apache Ignite cache is corrected to include the right cache names for proxy tickets. Thanks to @rrenomeron, better error handling is put into place while parsing YAML property files. Thanks to @leleuj, better error handling is put in place for email notifications specially when no principal attribute is found to indicate the target email address. The DynamoDb table name used to hold CAS’ registered service definitions can now be customized via CAS settings. The logout webflow/view is now able to correctly recognize and activate the required code snippet for Google Analytics. Thanks to @marqc,the condition that controls the issuing of ticket-granting tickets is improved to take into account identical usernames found in multiple account sources. Thanks to @johnlister, better error handling is put in place during the password management reset flows when an invalid username is provided. Thanks to @plajko, ordering of the authentication handlers selected for the current transaction is correctly enforced. Thanks to @deel77, the Slovak language bundles are updated. Thanks to @3cdota,delegated authentication using Pac4j will attempt to preserve the requested URL upon CAS logout. Thanks to @dima767, the ranking logic that affected variegated multifactor providers such as Duo Security is now corrected. Thanks to @tienthanh2509, a new language pack for Vietnamese is now included in CAS. The LDAP service registry is able to correctly import JSON definition files where specified. Thanks to @dacurry-tns, handling of MongoDb connection strings specified by client URIs is now improved. Thanks to @arbner, consent view pages now have access to the authenticated principal. Thanks to @alexdp, Google Apps integration in CAS is improved to properly load the given certificates. Thanks to @hdeadman, the SSL valve for the embedded Apache Tomcat is now correctly registered with the servlet container. Thanks to @dima767, the log viewer available as part of the CAS dashboard gets a number of performance improvements internally. Thanks to @fjollberg, authenticating to Couchbase buckets receives a number of bug fixes. Thanks to @plajko, a number of MongoDb performance and configuration improvements are included in this release candidate. Additionally, the default size of the embedded Apache Tomcat’s thread pool is now increased. Thanks to @plajko, JWT ids generated with CAS as OpenId Connect OP are set to the service ticket identifier to account for proper session mapping when dealing with SLO. Minor bug fix in the way attributes are resolved and fetched from REST endpoints. Hazelcast Discovery CAS is now able to leverage Apache jclouds and Microsoft Azure, when it comes to Hazelcast and auto-discovery. Apache Syncope Authentication As yet another method of authentication, CAS is now able to leverage Apache Syncope to locate user accounts. Operation Lombok CAS begins to adopt Project Lombok in order to reduce noise and boilerplate code used to obtain logger objects, generate getter/setter methods, etc. This is part of a bigger gradual step at possibly converting the codebase relevant modules over to Kotlin to further improve readability and reduce LOC. Before the migration, total number of lines for Java classes stood at 207,002. Today, after the migration the number of lines is reduced down to 190,398. HTTP Security Headers per Service Injection of HTTP security headers into the response can now be controlled on a per-service basis. See this guide for more info. Registered Services REST API For some time, CAS has had support for a REST-like API allowing one to add service definitions into the registry. This API was quite limited in accepting different properties of a given service definition or different types of services for various protocols. In this release candidate, this API is improved slightly to accept all types of service definitions in the API request body and making it slightly easier to execute such requests with proper authentication and authorization enforcements. BewareThis is a breaking change. Please revisit the API requests and reformulate them accordingly. Configuration Discovery The Configuration Discovery endpoint in CAS is now able to report back configured and supported clients used in the context of delegated authentication. SAML2 Service Providers The following new SAML2 service providers are now supported by CAS out of the box: Amazon JSON Whitelist Authentication A JSON-based authentication strategy is now included that allows one to mimic user account details, mostly useful for development and testing. REST Protocol Credential Extraction The CAS REST protocol in this release candidate is given the ability to extract multiple sets of credentials from the request body and prep them for authentication. In practice this means that various modules, such as YubiKey and Google Authenticator, may be allowed to insert a special credential extractor into the REST engine automatically when detected in order to let the REST request achieve MFA. AWS Credential Fetching For components that tightly integrate with AWS such as Cloud Directory Authentication or CloudWatch, etc CAS is now given the ability to fetch credentials from a variety of sources as part of an ordered chain. Sources include system properties, environment variables, EC2 instance metadata, etc. BewareThis is a breaking change. As part of this change, a number of module names for CloudWatch logging, etc have changed their names to belong to the support category of CAS modules rather than core. Review the documentation and adjust accordingly. Mapped Attribute Value Filters A new attribute value filter is added whose main ability is to filter attribute values by a collection of patterns and then supplant the value dynamically based on the results of the regex match. Authenticate Credentials via REST Protocol A new REST endpoint is now exposed that is tasked to only verify the validity of the provided credentials without dealing with the ticket API. REST Protocol Enhancements The CAS REST protocol is now enhanced internally to be able to accept other types of protocols and parameters in order to issue a response (i.e. service ticket). As a first candidate, the REST protocol is now able to issue SAML1 tickets just as well as the normal web-based SSO flows. REST-based Audits CAS audit data and logs may now be POSTed to a REST endpoint of your choosing. SAML2 Attribute Friendly Names CAS acting as a SAML2 identity provider is given the ability to individually configure friendly names for attributes released to service providers. Configuration Binding Behavior Starting with this release candidate, the configuration binding operations start to be a bit less forgiving when it comes to detecting unknown CAS settings found in property sources such as the cas.properties file. If you have existing settings that are no longer accepted or recognized, CAS will present you with an error at runtime and on startup forcing you clean up the configuration and find the correct replacements where relevant. As part of this change, please note that the following settings that deal with CAS standalone configuration resolution have been renamed: cas.standalone.config to cas.standalone.configurationDirectory cas.standalone.config.file to cas.standalone.configurationFile cas.standalone.security to cas.standalone.configurationSecurity BewareThis is done to ensure configuration settings recognized by CAS are kept up-to-date, accurate and relevant throughout upgrades. As yet another reminder, it is unnecessary to copy an entire collection of CAS settings and values into property sources without fully knowing their application and impact. Per the usual recommendation, you are to keep the entire overlay construct clean, precise and laser-focused on behavior you do in fact need. New Command-line Shell Commands The CAS command-line shell is now given the following capabilities: Export database schemas and DDLs Generate SAML IdP metadata and related keystores and certificates Jasypt-related commands to test available cipher algorithms and providers used to secure CAS properties, thanks to @hdeadman. SAML2 Audits SAML2 requests and responses accepted and produced by CAS while running as a SAML2 identity provider are now routed to the audit log. As part of this change, the auditing functionality in CAS is slightly improved to allow for dynamic registration of audit action and resource resolution events that may be carried out by any CAS module at runtime and typically on startup. OAuth2 Audits OAuth2 user profiles produced by CAS while running as an OAuth2 identity provider are now routed to the audit log. REST API Audits Interactions with the CAS REST API that would allow one to obtain ticket-granting tickets and/or service tickets are now also sent to the audit log. Audit Trail Management Audit record management in CAS is given the abllity to work with multiple managers, storing audit data in many destinations at the same time. The auditing library is also given the ablity to fetch audit data based on a starting date whose value may be controlled in CAS settings. BewareAs part of this change, a number of settings that specifically controlled the behavior of audit functionality based on log files and Slf4j have changed location, moving over to a slf4j category. Review the documentation for all settings and adjust accordingly if you have included any of those settings in your property sources. Authentication Throttling Authentication throttling configuration is slightly simplified to skip creating NoOp throttlers when throttling is disabled. As part of this change, other components that take advantage of throttling such as REST and OAuth protocols are affected to use the same throttler and configuration that would is used for other areas of the system namely the usual login endpoints. BewareAs part of this change, the throttler setting that REST and OAuth module settings carried is now removed in favor of the default throttler functionality. MongoDb Authentication Throttling In addition to recording audit records in MongoDb databases, CAS also offers the authentication throttling functionality based on MongoDb that is tightly integrated with the same auditing facility. Library Upgrades Kotlin Checkstyle Spring Webflow Commons Pool Spring Boot Apache Tomcat Pac4j Gradle Person Directory Apache HttpClient HikariCP Inspektr Spring Java CAS Client (version 3.5.0 is now available) Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Das Ende Big thanks to all who participate in the development of this release to submit patches and contribute improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2018/02/09/530rc2-release/"
  },

  
  
  
  {
    "title": "CAS 5.2.x Deployment - WAR Overlays",
    "text": "This is a short and sweet tutorial on how to deploy CAS via the WAR Overlay method. This tutorial specifically requires and focuses on: CAS 5.2.x Java 8 Need Help?If you ever get stuck and are in need of additional assistance, start by reviewing the suggestions provided here. You may also look at available support options provided here. Overlay…What? Overlays are a strategy to combat repetitive code and/or resources. Rather than downloading the CAS codebase and building it from source, overlays allow you to download a pre-built vanilla CAS web application server provided by the project itself, override/insert specific behavior into it and then merge it all back together to produce the final (web application) artifact. You can find a lot more about how overlays work here. The concept of the WAR Overlay is NOT a CAS invention. It’s specifically an Apache Maven feature and of course, there are techniques and plugins available to apply the same concept to Gradle-based builds as well.You are free to choose between Maven or Gradle. For this tutorial, I opted into the Maven WAR overlay. Once you have forked and cloned the repository locally, you’re ready to begin. NoteRemember to switch to the appropriate branch. Today, the master branch of the repository applies to CAS 5.2.x deployments. That may not necessarily remain true when you start your own deployment. So examine the branches and make sure you checkout the one matching your intended CAS version. Overlay’s Anatomy Similar to Grey’s, a Maven WAR overlay is composed of several facets the most important of which is the pom.xml file. This is a build descriptor file whose job is to teach Apache Maven how to obtain, build, configure (and in certain cases deploy) artifacts. KISSYou do not need to download Apache Maven separately. The project provides one for you automatically with the embedded Maven Wrapper. The pom.xml is composed of several sections. The ones you need to worry about are the following. Properties &lt;properties&gt; &lt;cas.version&gt;5.2.2&lt;/cas.version&gt; &lt;springboot.version&gt;1.5.8.RELEASE&lt;/springboot.version&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;app.server&gt;-tomcat&lt;/app.server&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; This is the bit that describes build settings, and specifically, here, what versions of CAS, Spring Boot, and Java are required for the deployment. You are in practice mostly concerned with the &lt;cas.version&gt; setting and as new (maintenance) releases come out, it would be sufficient to simply update that version and re-run the build. This might be a good time to review the CAS project’s Release Policy as well as Maintenance Policy. Dependencies The next piece describes the dependencies of the overlay build. These are the set of components almost always provided by the CAS project that will be packaged up and put into the final web application artifact. At a minimum, you need to have the cas-server-webapp-${app.server} module available because that is the web application into which you intend to inject your settings and customizations if any. Also, note that the module declarations are typically configured to download the CAS version instructed by the property ${cas.version}. Here is an example: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp${app.server}&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Including a CAS module/dependency in the pom.xml simply advertises to CAS your intention of turning on a new feature or a variation of a current behavior. Do NOT include something in your build just because it looks and sounds cool. Remember that the point of an overlay is to only keep track of things you actually need and care about, and no more. RememberKeep your build clean and tidy. A messy build often leads to a messy deployment, complicates your upgrade path and is a documented cause of early hair loss. Keep changes down to the absolute essentials and document their need for your deployment. If you review the configuration a year from now, you should have an idea of why things are the way they are. And What About…? There are many other pieces in the pom.xml, such as repositories, profiles, plugins, etc that I skipped. For everything else, there is MasterCard…and of course the official Apache Maven guides. Enjoy! The Build Now that you have a basic understanding of the build descriptor, it’s time to actually run the build. An Apache Maven build is often executed by passing specific goals/commands to Apache Maven itself, aka mvn. So for instance in the terminal and once inside the project directory you could execute things like: cd cas-overlay-template mvn clean …which may be a problem if you don’t have already have Apache Maven downloaded and installed. While you can do that separate install, the WAR Overlay project provides you with an embedded Apache Maven instance whose job is to first determine whether you have Maven installed and if not, download and configure one for you based on the project’s needs. So you can replace that command above with: cd cas-overlay-template mvnw clean …which may be a problem because, how are you supposed to know what commands/goals can be passed to the build? You can study them for sure, but the project provides you with a shell script that wraps itself around the Maven wrapper and provides an easy facade for you to remember commands and their use. This is the build.sh file, which you can run as such: cd cas-overlay-template ./build.sh help Usage: build.sh [copy|clean|package|run|debug|bootrun] What do these commands do? Type Description copy Copies the configuration from the local etc/cas/config directory to /etc/cas/config. See this guide to learn more. clean Deletes any previously-built and leftover artifacts from the target directory. package Runs clean and copy. Then packages the CAS web application artifact and run through the overlay to inject local customizations. The outcome is a target/cas.war file which is ready to be deployed. run Involves package and then deploys and runs the CAS web application via its own embedded server container. debug Same thing as run, except that you can remote-debug the CAS web application over port 5000. bootrun Same thing as run, except the deployment is managed by the Spring Boot Maven plugin. This command has very specialized and limited use cases. Please review this issue to learn more. RememberDocs grow old. Always consult the overlay project's README file to keep to date. As an example, here’s what I see if I were to run the package command: ./build.sh copy package Creating configuration directory under /etc/cas Copying configuration files from etc/cas to /etc/cas/config etc/cas/config/application.yml -&gt; /etc/cas/config/application.yml etc/cas/config/cas.properties -&gt; /etc/cas/config/cas.properties etc/cas/config/log4j2.xml -&gt; /etc/cas/config/log4j2.xml [INFO] Scanning for projects... [INFO] [INFO] Using the MultiThreadedBuilder implementation with a thread count of 5 [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building cas-overlay 1.0 [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ cas-overlay --- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ cas-overlay --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /cas-overlay-template/src/main/resources [INFO] [INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ cas-overlay --- [INFO] No sources to compile [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ cas-overlay --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /cas-overlay-template/src/test/resources [INFO] [INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ cas-overlay --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ cas-overlay --- [INFO] No tests to run. [INFO] [INFO] --- maven-war-plugin:2.6:war (default-war) @ cas-overlay --- [INFO] Packaging webapp [INFO] Assembling webapp [cas-overlay] in [/cas-overlay-template/target/cas] [info] Copying manifest... [INFO] Processing war project [INFO] Processing overlay [ id org.apereo.cas:cas-server-webapp-tomcat] [INFO] Webapp assembled in [786 msecs] [INFO] Building war: /cas-overlay-template/target/cas.war [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ ... You can see that the build attempts to download, clean, compile and package all artifacts, and finally, it produces a /cas-overlay-template/target/cas.war which you can then use for actual deployments. RememberYou are allowed to pass any of Maven's native command-line arguments to the build.sh file. Things like -U or -X might be useful to have handy. Configuration I am going to skip over the configuration of /etc/cas/config and all that it deals with. If you need the reference, you may always use this guide to study various aspects of CAS configuration. Suffice it to say that, quite simply, CAS deployment expects the main configuration file to be found under /etc/cas/config/cas.properties. This is a key-value store that is able to dictate and alter the behavior of the running CAS software. As an example, you might encouter something like: cas.server.name=https://cas.example.org:8443 cas.server.prefix=https://cas.example.org:8443/cas logging.config=file:/etc/cas/config/log4j2.xml …which at a minimum, identifies the CAS server’s URL and prefix and instructs the running server to locate the logging configuration at file:/etc/cas/config/log4j2.xml. The overlay by default ships with a log4j2.xml that you can use to customize logging locations, levels, etc. Note that the presence of all that is contained inside /etc/cas/config/ is optional. CAS will continue to fall back onto defaults if the directory and the files within are not found. Keep Track It is VERY IMPORTANT that you contain and commit the entire overlay directory (save the obvious exclusions such as the target directory) into some sort of source control system, such as git. Treat your deployment just like any other project with tags, releases, and functional baselines. Registering Applications Client applications that wish to use the CAS server for authentication must be registered with the server apriori. CAS provides a number of facilities to keep track of the registration records and you may choose any that fits your needs best. In more technical terms, CAS deals with service management using two specific components: Individual implementations that support a form of a database are referred to as Service Registry components and they are many. There is also a parent component that sits on top of the configured service registry as more of an orchestrator that provides a generic facade and entry point for the rest of CAS without entangling all other operations and subsystems with the specifics and particulars of a storage technology. In this tutorial, we are going to try to configure CAS with the LDAP service regitry. Configuration First, ensure you have declared the appropriate module/intention in the build: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-ldap-service-registry&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; Next, you must teach CAS how to contact the LDAP server to read and write registration records. This is done in the cas.properties file: cas.serviceRegistry.initFromJson=false cas.serviceRegistry.ldap.ldapUrl=ldaps://ldap1.example.edu ldaps://ldap2.example.edu cas.serviceRegistry.ldap.baseDn=dc=example,dc=org cas.serviceRegistry.ldap.bindDn=cn=Directory Manager,dc=example,dc=org cas.serviceRegistry.ldap.bindCredential=Password LDAP SchemaService definitions are by default stored inside the description attribute as JSON objects with the objectClass casRegisteredService. The numeric identifier for each service definition that is used for lookups and search operations is also kept under attribute uid all of which you can of course customize. The format and syntax of the JSON is identical to that of JSON Service Registry. That’s all, as far as the schema goes. That’s all. Next, you will need to pre-populate the LDAP server with registration records manually, or better yet, use the CAS Management web application’s user interface to do so in more interactive terms. To populate the LDAP server manually, remember that there is no pre-defined fancy schema where a registration record in CAS would be broken apart and mapped to individual attributes one by one. The body of the registration record, sampled below, is stored in LDAP under the designated attribute: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://app.example.org\", \"name\" : \"ApplicationName\", \"id\" : 1001, \"evaluationOrder\" : 10 } Ticketing A robust CAS deployment requires the presence and configuration of an internal database that is responsible for keeping track of tickets issued by CAS. CAS itself comes by default with a memory-based node-specific cache that is often more than sufficient for smaller deployments or certain variations of a clustered deployment. Just like the service management facility, large variety of databases and storage options are supposed by CAS under the facade of a Ticket Registry. In this tutorial, we are going to configure CAS to use a Hazelcast Ticket Registry with the assumption that our deployment is going to be deployed in an AWS-sponsored environment. Hazelcast Ticket Registry is often a decent choice when deploying CAS in a cluster and can take advantage of AWS’s native support for Hazelcast in order to read node metadata properly and locate other CAS nodes in the same cluster in order to present a common, global and shared ticket registry. This is an ideal choice that requires very little manual work and/or troubleshoot, comparing to using options such as Multicast or manually noting down the address and location of each CAS server in the cluster. Configuration First, ensure you have declared the appropriate module/intention in the build: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-hazelcast-ticket-registry&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; Next, the AWS-specific configuration of Hazelcast would go into our cas.properties: cas.ticket.registry.hazelcast.cluster.discovery.enabled=true cas.ticket.registry.hazelcast.cluster.discovery.aws.accessKey=... cas.ticket.registry.hazelcast.cluster.discovery.aws.secretKey=... cas.ticket.registry.hazelcast.cluster.discovery.aws.region=us-east-1 cas.ticket.registry.hazelcast.cluster.discovery.aws.securityGroupName=... # cas.ticket.registry.hazelcast.cluster.discovery.aws.tagKey= # cas.ticket.registry.hazelcast.cluster.discovery.aws.tagValue= That should do it. Of course, if you are working on a more modest CAS deployment in an environment that is more or less owned by you and you prefer more explicit control over CAS node registrations in your cluster, the following settings would be more ideal: # cas.ticket.registry.hazelcast.cluster.instanceName=localhost # cas.ticket.registry.hazelcast.cluster.port=5701 # cas.ticket.registry.hazelcast.cluster.portAutoIncrement=true cas.ticket.registry.hazelcast.cluster.members=123.321.123.321,223.621.123.521,... Overlay Customization If I cd into the target/cas directory, I can see an exploded version of the cas.war file. This is the directory that contains the results of the overlay process. Since I have not actually customized and overlaid anything yet, all configuration files simply match their default and are packaged as such. So as an example, let’s change something. Digging further down, I notice there exists a /target/cas/WEB-INF/classes/messages.properties file, which is the default message bundle. I decided that I am going to change the text associated with screen.welcome.instructions. RememberDo NOT ever make changes in the target directory. The changesets will be cleaned out and set back to defaults every time you do a build. Follow the overlay process to avoid surprises. First, I will need to move the file to my project directory so that Apache Maven during the overlay process can use that instead of what is provided by default. Here we go: cd cas-overlay-template mkdir -p src/main/resources cp target/cas/WEB-INF/classes/messages.properties src/main/resources/ Then I’ll leave everything in that file alone, except the line I want to change. ... screen.welcome.instructions=Speak Friend and you shall enter. ... Then I’ll package things up as usual. ./build.sh package ... [INFO] --- maven-war-plugin:2.6:war (default-war) @ cas-overlay --- [INFO] Packaging webapp [INFO] Assembling webapp [cas-overlay] in [/cas-overlay-template/target/cas] [info] Copying manifest... [INFO] Processing war project [INFO] Processing overlay [ id org.apereo.cas:cas-server-webapp-tomcat] [INFO] Webapp assembled in [1005 msecs] [INFO] Building war: /cas-overlay-template/target/cas.war [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS ... If I look at target/cas/WEB-INF/classes/messages.properties after the build, I should see that the overlay process has picked and overlaid onto the default my version of the file. RememberOnly overlay and modify files you actually need and try to use externalized resources and configuration as much as possible. Just because you CAN override something in the default package, it doesn't mean that you should. Deploy You have a number of options when it comes to deploying the final cas.war file. This post should help. What About…? CAS Multifactor Authentication with Duo Security CAS 5 LDAP AuthN and Jasypt Configuration CAS 5 SAML2 Delegated AuthN Tutorial For more content, please see this link. So… It’s important that you start off simple and make changes one step at a time. Once you have a functional environment, you can gradually and slowly add customizations to move files around. I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/02/06/cas52-gettingstarted-overlay/"
  },

  
  
  
  {
    "title": "Link CAS OIDC user to existing Database user",
    "text": "Contributed ContentFrancis Le Coq was kind enough to share this guide. CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. This example is here to show an example of our try to use CAS in order to authenticate users via France Connect, by registering them to our own database linked with an user that is already registered. What we want The first thing is that the user register only internally via our own services, not via a public page but via our private system. That means that the user on first usage already has an account and can log into CAS via the Login Form. The second thing is that we want to give the possibility for the user to connect an OIDC, in our example it would be France Connect, but only if the user has already access to our website via Login Form. In conclusion, on first connect via France Connect, the user will have to log onto France Connect and log onto Login Form in second in order to be recognized as the owner of the France Connect account used. On next France Connect login, the user will directly have access. Form Login is the basic, login and password form from CAS. Our environment CAS 5.2.2 CAS Maven WAR Overlay What is our configuration We use an LDAP server and an OIDC CAS configuration. Not more than that. The user has two choices when on the CAS interface, the Login Form and the France Connect button. We will use “cas.authn.pac4j.oidc” for configuring our OIDC to authenticate our user using France Connect. We will use “cas.authn.ldap” to authenticate our user using LDAP database. We will use “cas.authn.attributeRepository.ldap” to retrieve some attributes after user authentication. What do we need We need to : Connect to France Connect on the behalf of the user (when the user click on the button) and get the OIDC ID Take this ID and store it Ask the user to identify via Login Form Link the UserId and OIDC ID and store into our LDAP database Send back the user to its final destination which is the asked service Simple ! How to do it Define our first service We will use CAS services, by asking a “requiredAttributes” Create a file into your service folder or equivalent, https-01.json : //On any service, it will ask for UID, if not redirect { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"^(https|imaps)://.*\", \"name\" : \"default\", \"id\" : 9997, \"description\" : \"Welcome in here\", \"evaluationOrder\" : 9998, // The usernameAttribute is always uid attribute for this service \"usernameAttributeProvider\" : { \"@class\" : \"org.apereo.cas.services.PrincipalAttributeRegisteredServiceUsernameProvider\", \"usernameAttribute\" : \"uid\" }, \"accessStrategy\": { // We created and changed the AccessStrategy, see below why \"@class\" : \"org.esupportail.cas.services.ClaExternalIDRegisteredServiceAccessStrategy\", // If doesn't find 'uid' it will redirect to URL that will link and store IDs \"unauthorizedRedirectUrl\" : \"https://my-jetty-server/claExternalID/\", \"requiredAttributes\" : { \"@class\" : \"java.util.HashMap\", \"uid\" : [ \"java.util.HashSet\", [ \".*\" ] ] } } } On first OIDC authentication, France Connect transmit some attributes, but none of them are named ‘uid’, so at this moment CAS redirect the user to \"unauthorizedRedirectUrl\": \"https://my-jetty-server/claExternalID/\". In this simple URL we are missing some information that we need in our use case, the OIDC Id and the service target. It is not implemented into CAS to add those parameters automatically to the URL. The second service configuration is { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"^https?://.*/claExternalID/associate/.*\", \"name\" : \"Votre identité FranceConnect n'est pas connu dans l'établissement\", \"id\" : 55, \"theme\": \"cla\", \"description\" : \"Veuillez vous authentifier auprès de l'université pour confirmer votre identité\", \"evaluationOrder\" : 55, \"usernameAttributeProvider\" : { \"@class\" : \"org.apereo.cas.services.PrincipalAttributeRegisteredServiceUsernameProvider\", \"usernameAttribute\" : \"uid\" }, \"attributeReleasePolicy\" : { \"@class\" : \"org.apereo.cas.services.ReturnAllAttributeReleasePolicy\", \"principalAttributesRepository\" : { \"@class\" : \"org.apereo.cas.authentication.principal.cache.CachingPrincipalAttributesRepository\", \"mergingStrategy\" : \"ADD\" } } } This is when your standalone server send back to the second login Form, you need to give the theme. Force CAS to give OIDC ID When CAS check “requiredAttributes”, if an attribute is missing it will throw an Exception and a handler will catch this exception in order to redirect to the URL we added inside our service configuration. So we will add a new Exception inside the StrategyAccess and the ExceptionHandler will customize the Url. For that part we need to add our new ClaExternalIDPrincipalException that will store the attributes coming from our ClaExternalIDRegisteredServiceAccessStrategy. Second part, we need to override the handler AuthenticationExceptionHandlerAction and replace it by our own ClaExternalIDAuthenticationExceptionHandlerAction. First our ClaExternalIDRegisteredServiceAccessStrategy, this class is used into service configuration. It allows us to throw the exception, it needs as well to store the attributes needed later on. public class ClaExternalIDRegisteredServiceAccessStrategy extends DefaultClaExternalIDRegisteredServiceAccessStrategy { private static final Logger LOGGER = LoggerFactory.getLogger(ClaExternalIDRegisteredServiceAccessStrategy.class); //this function is used to check \"requiredAttributes\" public boolean doPrincipalAttributesAllowServiceAccess(final String principal, final Map&lt;String, Object&gt; principalAttributes) { if (!enoughAttributesAvailableToProcess(principal, principalAttributes)) { LOGGER.debug(\"Access is denied. enoughAttributesAvailableToProcess\"); return false; } if (doRejectedAttributesRefusePrincipalAccess(principalAttributes)) { LOGGER.debug(\"Access is denied. doRejectedAttributesRefusePrincipalAccess\"); return false; } if (!doRequiredAttributesAllowPrincipalAccess(principalAttributes, this.requiredAttributes)) { LOGGER.debug(\"Access is denied. doRequiredAttributesAllowPrincipalAccess\"); principalAttributes.put(\"principal\", principal); //We throw our exception, it will be intercepted by the Handler inside the Webflow throw new ClaExternalIDPrincipalException(\"ClaExternalIDPrincipalException\", new HashMap&lt;&gt;(), new HashMap&lt;&gt;(), principalAttributes); } LOGGER.debug(\"Access is authorized\"); return true; } } As you saw above, a new class appear ClaExternalIDPrincipalException, the handler will need it to recognize the situation. public class ClaExternalIDPrincipalException extends PrincipalException { public ClaExternalIDPrincipalException( final String message, final Map&lt;String, Class&lt;? extends Throwable&gt;&gt; handlerErrors, final Map&lt;String, HandlerResult&gt; handlerSuccesses, final Map&lt;String, Object&gt; principalAttributes) { super(message, handlerErrors, handlerSuccesses); setPrincipalAttributes(principalAttributes); } public void setPrincipalAttributes(Map&lt;String, Object&gt; principalAttributes){ this.principalAttributes = principalAttributes; } public Map&lt;String, Object&gt; getPrincipalAttributes(){ return this.principalAttributes; } } To finish this part, the handler that will modify the Url public class ClaExternalIDAuthenticationExceptionHandlerAction extends AuthenticationExceptionHandlerAction { protected String handleAuthenticationException(final AuthenticationException e, final RequestContext requestContext) { final URI url = WebUtils.getUnauthorizedRedirectUrlIntoFlowScope(requestContext); if (e.getHandlerErrors().containsKey(UnauthorizedServiceForPrincipalException.class.getSimpleName())) { if (url != null) { LOGGER.warn(\"Unauthorized service access for principal; CAS will be redirecting to [{}]\", url); return CasWebflowConstants.STATE_ID_SERVICE_UNAUTHZ_CHECK; } } //We add this part to catch the exception thrown and we customize the url, // adding the attributes from OIDC and the url service asked if (e instanceof ClaExternalIDPrincipalException) { if (url != null) { final ClaExternalIDPrincipalException eClaExternalID = (ClaExternalIDPrincipalException) e; final URI url2 = getUrl(url, eClaExternalID.getPrincipalAttributes(), WebUtils.getService(requestContext).getOriginalUrl()); WebUtils.putUnauthorizedRedirectUrlIntoFlowScope(requestContext, url2); LOGGER.warn(\"Unauthorized service access for principal; CAS will be redirecting to [{}]\", url2); return CasWebflowConstants.STATE_ID_SERVICE_UNAUTHZ_CHECK; } } final String handlerErrorName = getErrors() .stream() .filter(e.getHandlerErrors().values()::contains) .map(Class::getSimpleName) .findFirst() .orElseGet(() -&gt; { LOGGER.debug(\"Unable to translate handler errors of the authentication exception [{}]. Returning [{}]\", e, UNKNOWN); return UNKNOWN; }); final MessageContext messageContext = requestContext.getMessageContext(); final String messageCode = DEFAULT_MESSAGE_BUNDLE_PREFIX + handlerErrorName; messageContext.addMessage(new MessageBuilder().error().code(messageCode).build()); return handlerErrorName; } /** * Create an URI object with attributes as paramaters in it */ protected URI getUrl(final URI uri, final Map&lt;String, Object&gt; principalAttributes, final String target){ MultiValueMap&lt;String, String&gt; queryParams = new LinkedMultiValueMap&lt;String, String&gt;(); principalAttributes.forEach((key, i) -&gt; { if(i instanceof Iterable){ for (Object y : (Iterable) i) { queryParams.add(key, (String) y); } } else { queryParams.add(key, (String) i); } }); queryParams.add(\"target\", target); UriComponents uriComponents = UriComponentsBuilder.newInstance() .fromUri(uri).queryParams(queryParams).build(); try { return uriComponents.toUri(); } catch(Exception e) { LOGGER.debug(e.toString()); } throw new RuntimeException(\"Failed to create the URL\"); } } At this moment, everything is good but our handler is not registered to be used by Spring. Register the newly created handler It is pretty simple, we will override the Bean authenticationExceptionHandler by creating our own customized configuration class. @Configuration(\"ClaExternalIDConfiguration\") @EnableConfigurationProperties(CasConfigurationProperties.class) public class ClaExternalIDConfiguration { @Autowired private CasConfigurationProperties casProperties; @RefreshScope @Bean /** * This bean has the same name that the CAS \"CasCoreWebflowConfiguration\", so it will * overwrite that class, it will work only because it is implemeted inside * the gradle overlay in our example */ public Action authenticationExceptionHandler() { return new ClaExternalIDAuthenticationExceptionHandlerAction(handledAuthenticationExceptions()); } public Set&lt;Class&lt;? extends Exception&gt;&gt; handledAuthenticationExceptions() { /* * Order is important here; We want the account policy exceptions to be handled * first before moving onto more generic errors. In the event that multiple handlers * are defined, where one failed due to account policy restriction and one fails * due to a bad password, we want the error associated with the account policy * to be processed first, rather than presenting a more generic error associated */ final Set&lt;Class&lt;? extends Exception&gt;&gt; errors = new LinkedHashSet&lt;&gt;(); errors.add(javax.security.auth.login.AccountLockedException.class); errors.add(javax.security.auth.login.CredentialExpiredException.class); errors.add(javax.security.auth.login.AccountExpiredException.class); errors.add(AccountDisabledException.class); errors.add(InvalidLoginLocationException.class); errors.add(AccountPasswordMustChangeException.class); errors.add(InvalidLoginTimeException.class); errors.add(javax.security.auth.login.AccountNotFoundException.class); errors.add(javax.security.auth.login.FailedLoginException.class); errors.add(UnauthorizedServiceForPrincipalException.class); errors.add(PrincipalException.class); errors.add(UnsatisfiedAuthenticationPolicyException.class); errors.add(UnauthorizedAuthenticationException.class); errors.addAll(casProperties.getAuthn().getExceptions().getExceptions()); return errors; } } A last file for the configuration is needed in order to declare the configuration file into Spring. org.springframework.boot.autoconfigure.EnableAutoConfiguration=org.esupportail.cas.config.ClaExternalIDConfiguration Linking the OIDC Id and UID This part can be manage by a simple jetty server. Or with some work a spring Webflow implemented yourself. In our side we choose the first case. As explained above, the server will need to receive the first call with the url we constructed and store the OIDC id into the session for example. Next it will send back to a new page implementing a CAS client, that will ask for a new login form authentication. When that authentication is done and granted, it will send back to this page and receive the UID. At this moment, the server link both OIDC id and UID together into the database. And on next login, CAS will get automatically the UID based on the OIDC id received by the OIDC supplier and grant the access. Make disappear the button on second login For that, a theme has to be used via the service configuration, in our code we just replaced the casLoginView.html by one that &lt;div th:replace=\"fragments/loginProviders\" /&gt; has been removed. Conclusion This solution is not perfect and could be maybe improved by using the webflow in order to make the linking possible. As well it has been only tested via an java overlay and will need some improvements if that is transformed into a module. I hope it was instructive and it helped you to do what you wanted to do :) The source are available on Github of course ! Find here our Example source code Plus our simple Standalone LDAP linking server Francis Le Coq",
    "tags": "CAS",
    "url": "/2018/02/02/OIDC-link-account/"
  },

  
  
  
  {
    "title": "CAS Multifactor Authentication with Duo Security",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. As a rather common use case, the majority of CAS deployments that intend to turn on multifactor authentication support tend to do so via Duo Security. This is a quick and simplified guide to demonstrate an approach to that use case along with some additional explanations regarding specific multifactor triggers supported in CAS today. Our task list is rather short: Configure LDAP authentication with CAS Trigger Duo Security for users who belong to the mfa-eligible group, indicated by the memberOf attribute on the LDAP user account. Environment CAS 5.2.x CAS Maven WAR Overlay Configuring Authentication Prior to configuring multiple factors of authentication, we need to first establish a primary mode of validating credentials. To kill two birds with one stone [1], we are going to o address yet another common use case and keep things simple by sticking with LDAP authentication. The strategy here, as indicated by the CAS documentation, is to declare the intention/module in the build script and then configure the relevant cas.authn.ldap[x] settings for the directory server in use. Most commonly, that would translate into the following settings: cas.authn.ldap[0].type=AUTHENTICATED cas.authn.ldap[0].ldapUrl=ldaps://ldap1.example.org cas.authn.ldap[0].baseDn=dc=example,dc=org cas.authn.ldap[0].userFilter=cn={user} cas.authn.ldap[0].bindDn=cn=Directory Manager,dc=example,dc=org cas.authn.ldap[0].bindCredential=... Note that the method of authentication, whether on its own or using separate attribute repositories and queries must have the ability to resolve the needed attribute which will be used later by CAS to trigger multifactor authentication. For this context, the simplest way would be to let LDAP authentication retrieve the attribute directly from the directory server. The following setting allows us to do just that: cas.authn.ldap[0].principalAttributeList=memberOf At this point in the authentication flow, we have established an authenticated subject that would be populated with fetched attribute memberOf. Configuring Duo Security Here, our task is to enable Duo Security in CAS. Practically, similar to the LDAP authentication configuration, this involves declaring the right module in the build and then providing specific Duo Security settings to CAS properties. Things such as the secret key, integration key, etc which should be provided by your Duo Security subscription. Most commonly, that would translate into the following settings: cas.authn.mfa.duo[0].duoSecretKey= cas.authn.mfa.duo[0].duoApplicationKey= cas.authn.mfa.duo[0].duoIntegrationKey= cas.authn.mfa.duo[0].duoApiHost= At this point, we have enabled Duo Security and we just need to find a way to instruct CAS to route the authentication flow over to Duo Security in the appropriate condition. This is where triggers come into place. Configuring Multifactor Authentication Triggers The entire purpose of a trigger here is to detect a condition by which the authentication flow should be rerouted. There are a large number of triggers supported by CAS, all of which kick into action and behave all the same regardless of the multifactor authentication provider. Our task here is to build a special condition that activates multifactor authentication if any of the values assigned to the attribute memberOf contain the value mfa-eligible: cas.authn.mfa.globalPrincipalAttributeNameTriggers=memberOf cas.authn.mfa.globalPrincipalAttributeValueRegex=mfa-eligible Notice that the conditions above do not indicate anything about Duo Security. If the above condition holds true, how does CAS know that the authentication flow should be routed to Duo Security? Per the CAS documentation: Trigger MFA based on a principal attribute(s) whose value(s) matches a regex pattern. Note that this behavior is only applicable if there is only a single MFA provider configured since that would allow CAS to know what provider to next activate. In other words, if the above condition holds true and CAS is to route to a multifactor authentication flow, that would obviously be one supported and provided by Duo Security since that’s the only provider that is currently configured to CAS. Of course, if there are multiple providers available at runtime (i.e. Duo Security, YubiKey, etc) then we would need massage the condition since the automatic detection of the multifactor provider would not be immediately obvious…and that sort of thing would be outside the scope of this tutorial. Summary I hope this review was of some help to you and I am sure that both this post as well as the functionality it attempts to explain can be improved in any number of ways. Please feel free to engage and contribute as best as you can. Misagh Moayyed [1] No birds were harmed during the production of this blog post.",
    "tags": "CAS MFA",
    "url": "/2018/01/08/cas-mfa-duosecurity/"
  },

  
  
  
  {
    "title": "Deploying Apereo CAS Behind a Proxy",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. I suppose the majority of CAS deployments today sit behind some sort of proxy or load balancer, especially with high-availability requirements in mind. F5, HAProxy, etc. In most setups, the proxy upfront terminates SSL and then hands off the request over to CAS on a secured connection typically on port 8080. While doing this sort of thing with an external servlet container such as Apache Tomcat is perfectly doable and folks have been doing that for ages, this guide aims to demonstrate how one might go about achieving the same result using the embedded Apache Tomcat container that ships with CAS. Environment CAS 5.2.1 CAS Maven WAR Overlay Configuration We are using the embedded Apache Tomcat container provided by CAS automatically. This is the recommended approach in almost all cases (The embedded bit; not the Apache Tomcat bit) as the container configuration is entirely automated by CAS and its version is guaranteed to be compatible with the running CAS deployment. Furthermore, updates and maintenance of the servlet container are handled at the CAS project level where you as the adopter are only tasked with making sure your deployment is running the latest available release to take advantage of such updates. RememberNote that CAS does also provide embedded servlet container options based on Jetty and Undertow. Depending on the functionality at hand, certain features may require additional support and development for automation. YMMV. So, in order to open up a communication channel between the proxy and the CAS embedded Apache Tomcat server, we want to do the following: Ensure Apache Tomcat runs on port 8080, assuming that’s what the proxy uses to talk to CAS. Ensure Apache Tomcat has SSL turned off. Ensure the Apache Tomcat connector listening on the above port is marked as secure. The above tasklist translates to the following properties expected to be found in your cas.properties: server.port=8080 server.ssl.enabled=false cas.server.http.enabled=false cas.server.httpProxy.enabled=true cas.server.httpProxy.secure=true cas.server.httpProxy.scheme=https cas.server.httpProxy.protocol=HTTP/1.1 That’s all. Summary I hope this review was of some help to you. As you have been reading, I can guess that you have come up with a number of missing bits and pieces that would satisfy your use cases more comprehensively with CAS. In a way, that is exactly what this tutorial intends to inspire. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2018/01/05/cas-deployment-with-proxy/"
  },

  
  
  
  {
    "title": "CAS 5.3.0 RC1 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.2.0 GA was released on November 27th, 2017. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.3.0. This post intends to highlight some of the improvements and enhancements packed into the first release candidate in the 5.3.0 series. The in-development documentation of CAS 5.3.0 is available here. The release schedule is also available here. The release policy is available here. Shake Well Before Use Apache Maven Gradle Minors CosmosDb Service Registry SAML2 Service Providers Delegated AuthN SAML2 Metadata Endpoints Groovy Access Strategy Service Replication via Hazelcast Global Attribute Caching Policies Documentation CleanUp Dynamic Metadata Management Externalized Views Health Indicators &amp; Monitors HashiCorp Consul Hazelcast AWS EC2 Discovery Multifactor Authentication Trigger Per Service Via Groovy Microsoft Azure’s KeyVault Secrets Response Type Per Service Delegated Authentication Access Policy Shibboleth Attribute Resolver Splunk Logging U2f Authentication Registration Record Encryption Library Upgrades Get Involved Das Ende Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. In order to start experimenting with release candidates, use the following strategies. At any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Apache Maven In the pom.xml of the overlay, adjust the following tag to match below: &lt;cas.version&gt;5.3.0-RC1&lt;/cas.version&gt; Gradle In the gradle.properties of the overlay, adjust the following setting to match below: cas.version=5.3.0-RC1 Minors A boolean flag is now exposed in CAS settings to toggle Google reCAPTCHA behavior. Scratch codes for Google Authenticator multifactor authentication are now properly recognized as valid tokens. A series of small bug fixes to ensure claims and scopes are properly recognized and released via the OpenID Connect protocol. Thanks to @Thaslin,delegating authentication to ADFS gains support for WCTX while handling concurrent requests. This problem manifests itself when multiple iframes redirect to CAS at nearly the same time. Since only one static session key was used for the CAS service, all requests were redirected to the same service URL after authentication success. Using the WCTX parameter as part of the session key solves this problem. Thanks to @pdrados, risk-based authentication gains a few new fixes when CAS begins to calculate the authentication risk factor based on date/time. Thanks to @robertoschwald, the CAS protocol specification is slightly revved to provide a few fixes to the XSD schema and to remove the memberOf attribute. A number of improvements to URL validators by @swoeste to support unknown yet valid TLDs. Regex support is now added to CAS HTTP configuration to ensure URL authorities can be correctly verified based on that pattern. Thanks to @hdeadman, the command-line shell is slightly improved when it’s asked to add properties for a configuration group that is not strictly controlled by CAS itself. (i.e. add-property -group tomcat). LDAP support is slightly enhanced with a new setting to enable dereferencing aliases. The CAS internal Gradle build is integrated with Google’s error-prone plugin to detect anomalies and prevent bugs. References to Spring’s VelocityEngineFactory are removed and CAS attempts to create its own VelocityEngine instance required and used to support SAML and friends. This is also a prepping move before CAS switches over to Spring 5 where Velocity functionality is now absent. CAS startup banner details, such as CAS version or commit id, etc are now also included in the info endpoint. The HTTP security filter is made more flexible by accepting values for X-FRAME-OPTIONS and X-XSS-PROTECTION. The embedded Apache Tomcat container now supports a few additional filters such as CSRF and Remote-Address. CAS audit logs see a few small improvements when data is formatted as JSON. Ticket validation events in the audit log are also able to show the authenticated principal and the collection of attributes released to the application as part of the assertion. CAS is now able to inject arbitrary headers into the response where needed to account for custom workflows and security settings. The configuration metadata is slightly improved to ensure metadata for inherited fields is properly generated. When securing admin pages and dashboard in CAS via IP address, there is now the ability to determine the IP via alternative headers such as X-Forwarded-For. A number of documentation improvements by @dstepe, @mac-reid. Thanks to @dacurry-tns, connections to MongoDb are now improved to better handle clientUri settings. Thanks to @mbenson, the CAS BOM is now improved to include all CAS modules. Thanks to @gledsonrabelo, the prefix for proxy tickets is now fixed to be PT. CosmosDb Service Registry CAS service definitions can now be managed and controlled via Microsoft Azure’s CosmosDb. SAML2 Service Providers The following new SAML2 service providers are now supported by CAS out of the box: GitLab Hipchat AppDynamics Delegated AuthN SAML2 Metadata Endpoints When delegating authentication to external SAML2 identity providers, CAS is able to present both the SP (CAS) and the IdP metadata via dedicated endpoints. Groovy Access Strategy Service access strategy policies can now take advantage of a Groovy script for more dynamic rules. Service Replication via Hazelcast In the event that CAS service definitions are not managed globally via a centralized store, service definition files managed as JSON or YAML files can be replicated across the CAS cluster via Hazelcast in addition to the native tooling options of the CAS platform. Global Attribute Caching Policies Attribute release caching in CAS may certainly be done on a per-service basis. In this release, CAS provides a strategy for caching attributes at a more global level specifically at release time. Documentation CleanUp A large number of CAS settings that are shared and common across modules are cleaned up to only be referenced once in a common area, pointing to a specific configuration key. This is a gradual effort and will take some time to complete. For instance, when it comes to MongoDB support there are a large number of CAS modules and components that support and integrate with it whose settings, structurally, are very much shared. Consider the duplicated settings below for features feature1 and feature2: cas.feature1.mongo.host=localhost1 cas.feature1.mongo.timeout=2000 cas.feature2.mongo.host=localhost2 cas.feature2.mongo.timeout=4000 Instead, the common settings such as host, timeout, etc are moved to a common block and take the form of: ${configurationKey}.mongo.host=localhost1 ${configurationKey}.mongo.timeout=2000 …where the configurationKey can either be cas.feature1 or cas.feature2, etc. &times; BewareAs part of the cleanup, the property userFilter that dealt with LDAP authentication filters and queries is now deprecated and replaced with searchFilter to be consistent with all other LDAP integration modules and features. Dynamic Metadata Management Managing service provider metadata documents, especially for bilateral integrations can now be done with the likes of MongoDB, SQL databases or Groovy, etc. See this guide for more info. Externalized Views CAS UI pages and that of Thymeleaf can now be loaded from external locations outside the web application context. While this was always a possible, this release candidate provides the ability to conditionally load views from an external path when found, and otherwise fall back to the default location inside the web application. Health Indicators &amp; Monitors CAS for some time has had the ability to monitor external systems and data sources such as LDAP, Memcached, etc. In this release candidate, the legacy CAS Monitor API is removed in favor of Spring Boot’s native HealthIndicator components. CAS monitors are removed from the /status page and moved to the Spring Boot’s /health endpoint. Note that the new endpoint by default does not show details of the monitors configured unless the request is an authenticated one with Spring Security. This behavior of course can be controlled via CAS settings. Note that as a result of this change, status codes that are returned by CAS have changed to include: UNKNOWN, UP, DOWN, WARN and OUT_OF_SERVICE many of which are by default provided by Spring Boot. HashiCorp Consul Thanks to Spring Cloud, CAS can now be tightly integrated with HashiCorp’s Consul for service discovery, health checks as well as configuration management via Consul’s key-value store. See this guide for more info. Hazelcast AWS EC2 Discovery Hazelcast support in CAS is now equipped to handle AWS EC2 auto-discovery. It is useful when you do not want to provide or you cannot provide the list of possible IP addresses for the cluster members. Furthermore, you may now specify a partitioning group configuration that may be zone-aware. See this guide for more info. Multifactor Authentication Trigger Per Service Via Groovy Multifactor authentication triggers per applications can now be more dynamically decided via a Groovy script. See this guide for more info. Microsoft Azure’s KeyVault Secrets Azure Key Vault Secrets can now act as a storage mechanism for CAS properties and settings in conjunction with Spring Cloud. See this guide for more info. Response Type Per Service The CAS protocol likely since its inception has provided support for a method parameter whose value would allow CAS to respond back to the service/application with a ticket via a redirect, a POST, etc. This behavior can now be applied to a registered service definition, controlling application behavior and expectations centrally. If you have a group of individual applications who all expected CAS to contact them back with a POST, you may group them together in a definition and set the responseType accordingly rather than having each individual application specify a method=POST in the authentication request. Delegated Authentication Access Policy In the event that CAS is allowed and configured to delegate the authentication request to an external provider such as a SAML2 IdP, you may now assign policies to registered service definitions in the CAS service registry to let each service control the set of authorized external identity providers. This behavior is enforced in the UI and while tickets are generated or validated. See this guide for more info. Shibboleth Attribute Resolver Support for resolving attributes using a Shibboleth IdP’s attribute-resolver.xml is now removed. Splunk Logging Support for publishing logs to Splunk is now included in this release. CAS is not quite taking advantage of native Splunk logging capabilities to format messages and that bit surely might receive more attention in future releases. U2f Authentication Registration Record Encryption Support for encryption/decryption of U2F authentication registration records stored in RDBMS as well as MongoDB repositories has been added via new properties Library Upgrades Gradle Hibernate AspectJ Spring Spring Boot Spring Cloud AWS Java SDK Hazelcast HikariCP Authy Azure CosmosDb Cassandra Apache Commons Apache CXF Apache Tomcat Eureka Apache Fediz Geo2IP Maxmind Google Maps Apache HttpClient Apache Ignite Couchbase Jose4J Apache Log4j MariaDB Driver Mockito Apache Velocity OpenSAML Pac4j SemVer Zipkin Sleuth Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Das Ende Big thanks to all who participate in the development of this release to submit patches and contribute improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2017/12/29/530rc1-release/"
  },

  
  
  
  {
    "title": "Apereo CAS SAML Integration With ADFS",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. This is a short and sweet tutorial on how to integrate Apereo CAS, acting as a SAML identity provider, with ADFS. Environment CAS 5.2.0-SNAPSHOT CAS Maven WAR Overlay CAS Configuration In order to allow CAS to become a SAML2 identity provider, the overlay needs to be prepped based on the instructions provided here. Remember to add the relevant module to the overlay along with the list of required build repositories. The SAML IdP configuration will need to minimally match the following settings: cas.authn.samlIdp.entityId=https://cas.example.edu/idp cas.authn.samlIdp.scope=example.edu cas.authn.samlIdp.metadata.location=file:/etc/cas/saml You will, of course, need to adjust your entityId and scope as needed. Upon startup, CAS will attempt to generate the appropriate metadata based on provided settings and produced artifacts will be placed at /etc/cas/saml. Of course, the running CAS process will need to have the right permissions in order to create this directory and the contents within it. To keep things simple, we will also configure CAS to use LDAP authentication such that the established single sign-on session is based on the authenticated principal whose is based on the sAMAccountName attribute. The ADFS instance needs to be registered with CAS as a service provider. You can choose a variety of service management options. For this tutorial, I will be using the JSON Service Registry with the following snippet as the ADFS registration record: { \"@class\": \"org.apereo.cas.support.saml.services.SamlRegisteredService\", \"serviceId\": \"http://adfs.example.edu/adfs/services/trust\", \"name\": \"adfs\", \"id\": 10000007, \"description\": \"adfs service\", \"logoutType\": \"NONE\", \"attributeReleasePolicy\": { \"@class\": \"org.apereo.cas.services.ReturnMappedAttributeReleasePolicy\", \"allowedAttributes\": { \"@class\": \"java.util.TreeMap\", \"upn\": \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/upn\", \"http://schemas.microsoft.com/ws/2008/06/identity/claims/windowsaccountname\": \"groovy { return 'DOMAIN\\\\\\\\' + attributes['username'][0] }\" } }, \"requiredNameIdFormat\": \"urn:oasis:names:tc:SAML:1.1:nameid-format:unspecified\", \"metadataLocation\": \"/path/to/adfs-metadata.xml\", \"signAssertions\": true, \"signResponses\": false } You certainly need to modify the serviceId and metadataLocation for your configuration but the most important bit in the above snippet is the blob that controls the allowedAttributes. The attribute release policy is essentially doing the following: upn is released and mapped to the ADFS-required SAML name http://schemas.xmlsoap.org/ws/2005/05/identity/claims/upn. http://schemas.microsoft.com/ws/2008/06/identity/claims/windowsaccountnwin is required by ADFS and is released here as a custom attribute. Since it requires a value in the format of DOMAIN\\\\username, this value is constructed via an inline groovy script, with each \\ escaped with another \\. Remember that username here is the name mapped to the attribute sAMAccountName that is retrieved from LDAP and is the CAS principal id. Also note that because all attributes in CAS are sort of treated and assumed to be multi-valued, we need to ensure that we grab the attribute value for username by indexing it with [0]. ADFS Configuration Start with adding a Claims Provider Trust. In the screenshot below, ours is called CAS Login –TEST. On the “Monitoring” tab, enter the URL of your CAS IdP metadata into the “Claims provider’s federation metadata URL:” field (i.e https://cas.example.edu/cas/idp/metadata). On the “Identifiers” tab, enter a “Display name:” and enter the entity ID that you specified in your CAS IdP configuration into the ”Claims provider identifier” field (i.e. https://cas.example.edu/idp). On the “Endpoints” tab, enter the endpoints for “SAML Single Sign-On Endpoints” and “SAML Logout Endpoints”. These can be found from your CAS IdP metadata. The first two values entered here are based on the “SingleSignOnService” bindings at the following endpoints: https://cas.example.edu/cas/idp/profile/SAML2/POST/SSO https://cas.example.edu/cas/idp/profile/SAML2/Redirect/SSO The logout endpoint is based on the “SingleLogoutService” binding located at the following endpoint: https://cas.example.edu/cas/idp/profile/SAML2/POST/SLO To enable CAS only (ADFS will auto-redirect to CAS), run the following PowerShell command on the ADFS server: Set-AdfsRelyingPartyTrust -TargetName \"Microsoft Office 365 Identity Platform\" -ClaimsProviderName \"CAS Login - TEST\" To revert back to Active Directory, run the following PowerShell command on the ADFS server: Set-AdfsRelyingPartyTrust -TargetName \"Microsoft Office 365 Identity Platform\" -ClaimsProviderName \"Active Directory\" Summary I hope this review was of some help to you. As you have been reading, I can guess that you have come up with a number of missing bits and pieces that would satisfy your use cases more comprehensively with CAS. In a way, that is exactly what this tutorial intends to inspire. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2017/11/22/cas-saml-integration-adfs/"
  },

  
  
  
  {
    "title": "Introduction to CAS Commandline Shell",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Amongst the new features of CAS 5.2.x is a command-line tool whose objective is to automate some of the more mundane deployment tasks by tapping into the CAS APIs to provide help on available settings/modules and various other utility functions. This shell engine that is based on Spring Shell is presented as both a CLI utility and an interactive shell. In this post, I am going to provide an overview of the CAS Shell and enumerate a few utility functions that might prove useful during a CAS deployment. Environment CAS 5.2.0-SNAPSHOT CAS Maven WAR Overlay Spawn The Shell While I am using the Maven WAR overlay, note that each CAS WAR Overlay deployment project should already be equipped with this functionality. You should not have to do anything special and extra to interact with the shell. See the relevant overlay documentation and README file for more info on how to invoke and work with the shell. Specifically applicable to the Maven WAR Overlay, one may launch the CLI by simply executing the following command: ./build.sh cli This should present you with the general welcome message as well as a list of command-line options accepted for various functions. Command-line Options One of the more useful utilities baked into CAS CLI tool is the ability to search for CAS settings and get better documentation and help on each. All individual CAS properties in most cases carry relevant Javadocs, examples, and links embedded right alongside the field in the housing component. The CAS build process upon every release attempts to collect all settings and their documentation into a JSON metadata file that can be queried by the CLI tool for more info. This of course not only includes CAS specific settings (i.e. cas.authn.xyz=something) but also all other Spring Boot settings and just about any other component that exposes its settings via a @ConfigurationProperties. If you want to learn more about how this is done, please see this article. Examples NoteFor the majority of the listed commands, I am going to skip the output. Feel free to try these yourself and observe the outcome. Configuration Metadata Let’s say we are looking for additional documentation on duoApplicationKey. To run the search, use: # Skipping the CAS Banner via `-skb` ./build.sh cli -skb -p duoApplicationKey Cool, but maybe that’s too limiting. How about notes on every setting in CAS that deals with duo? ./build.sh cli -skb -p duo.+ The output seems too verbose. How about we compact it a little bit? ./build.sh cli -skb -p duo.+ --summary Nice. What about some other non-CAS setting like, I don’t know, maxHttpPostSize? ./build.sh cli -p maxHttpPostSize -skb You see the above setting applies to Tomcat, Jetty and a few more. Here is a slightly fancier and more direct version: ./build.sh cli -p server.tomcat.max-http-post-size -skb Others Other CLI options include the following: Generating JWTs: ./build.sh cli -gw -sub Misagh -skb Generating keys for a CAS setting group that requires signing/encryption keys: ./build.sh cli -gk -p cas.tgc -skb … As more options and commands are added to the CLI, you should always confirm new additions by simply running ./build.sh cli -h -skb to get a listing of all options. Interactive Shell There is also an interactive shell which essentially provides identical functionality to the CLI yet it is more flexible and powerful in many ways. Some of the key highlights include: A simple, annotation-driven, programming model to contribute custom commands Tab completion, colorization, and script execution Already built-in commands, such as clear screen, gorgeous help, exit You can simply launch into the shell via ./build.sh cli -sh. While in the shell, simply type quit to exit the shell. Shell Commands In addition to a number built-in commands such as help, version and the most useful cls or clear, the following CAS-provided commands are available. Remember: Use double-tab to take advantage of auto-completion and history. Use help to see a listing of all commands. Use help &lt;command-name&gt; to learn more about the command itself. Find Identical to its CLI equivalent, allows one to look up a CAS setting: cas&gt;find --name duo Undocumented Settings Acts as a sanity check and lists undocumented properties for which allowing contributors to step up and contribute to the documentation: cas&gt;list-undocumented Generate JWTs Identical to its CLI equivalent: cas&gt;generate-jwt --subject Misagh Generate Crypto Keys Identical to its CLI equivalent: cas&gt;generate-key --group cas.tgc JSON To YAML Convert a CAS service definition file in JSON to YAML and optionally save the file at path: cas&gt;generate-yaml /etc/cas/config/services/WSFED-400.json --destination /etc/cas/config/services/WSFED-400.yml Validate Service Validate a service definition file in JSON or YAML to ensure correctness of syntax. Note that this command should and does support all service types (SAML2, OAuth, etc) provided by CAS: cas&gt;validate-service --file /etc/cas/config/services/WSFED-400.json Add Properties All associated settings with a given property group are added to the properties file defined. Existing values should be preserved. cas&gt;add-properties --group cas.tgc --file /etc/cas/config/my.properties Extending Commands When the shell is launched with the -sh option, all components under the org.apereo.cas.shell that are annotated with org.springframework.stereotype.Service are picked up as command implementations. The outline of a given command is as such: package org.apereo.cas.shell.commands; @Service public class DoesStuffCommand implements CommandMarker { @CliCommand(value = \"do-stuff\", help = \"This does stuff\") public void doStuff() { ... } } If you are interested in adding new and fancier commands, by all means create your own based on the above outline and contribute back. Summary I hope this review was of some help to you. As you have been reading, I can guess that you have come up with a number of missing bits and pieces that would satisfy your use cases more comprehensively with CAS. In a way, that is exactly what this tutorial intends to inspire. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/10/30/intro-cas-cli-shell/"
  },

  
  
  
  {
    "title": "Multitenancy With CAS",
    "text": "CollaborateThis blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. According to Wikipedia, the term “software multitenancy” is defined as: …a software architecture in which a single instance of software runs on a server and serves multiple tenants. A tenant is a group of users who share a common access with specific privileges to the software instance. I have been asked on and off about multitenancy capabilities of CAS and whether it is possible to have one CAS deployment serve many tenants. To be clear, multitenancy in a CAS context would cover the following areas for each tenant: Brand and theme the user interface. Define and limit authentication sources including attribute retrieval and release. Control logging strategies and audits in different granular details. Define and limit enabled/supported authentication protocols both as an IdP and IdP Proxy (delegated authentication). Feature management, such as tickets, security, access strategy, flow customizations, etc. … In addition to the problem of isolating configuration per tenant, there also needs to be a mechanism by which CAS may shake hands with each tenant to recognize and activate their connected configuration. Furthermore, any design needs to also carefully weigh and evaluate possibilities of feature imbalance which is the problem of introducing capabilities requested by a tenant without impact and side-effects to others and doing so in such a way to ensure all tenants can get their fair share of system capabilities if and when asked. If all of this sounds complex and seems like a lot of work, it is simply because it is. If this is something you desire to see in your deployment, please reach out. While support for multi-tenancy in the above terms and conditions is absent in CAS today, in this tutorial I wish to uncover a few aspects of the CAS software that may prove as viable alternatives or shortcuts for the time being to handle multitenancy-like features. Scenario Let’s suppose we are in charge of a CAS deployment that is tasked to serve two distinct tenants A and B each of which wish to register a few different applications registered with CAS with a variety of other rules that affect attribute release, themes, etc. Constraints It is important to treat these tenants as generic as possible and not make any assumptions about their underlying deployment or architecture. Equally significant, note that our tenants are simply unable to make changes whatsoever on their end to make our lives easier on this end. We might be able to relax this clause and make amends later in the future, (assuming fairly tight control over the environment) but until then, tenants’ expectation is to integrate with a given CAS deployment as if it was only their own completely ignorant of its multitenancy capabilities. Everything that can be done should be done with CAS to see that expectation to reality. Poor Man’s Multitenancy One possible solution is to turn the problem from one of software into one of deployment topology. Rather than having a single CAS deployment serving many tenants, you would simply have many smaller deployments serving each tenant and you would assign each tenant a specific endpoint that handles their needs exclusively. For our tenants, we could have https://sso.example.org/tenantA/cas/ and https://sso.example.org/tenantB/cas endpoint and so on. (If you care, rewrite the URLs prettier at some level to hide details) All CAS functionality is scoped to the specific endpoints that are shared with each tenant and the software itself cares not how it is contacted and by whom so long as requests are well-formed. While arguably this is the simplest of all options and grants the most flexibility, it goes without saying that managing many small deployments, upgrades and maintenance efforts across the platform does incur cost and risk and requires quite a bit of automation, technique and infrastructure support to let all play nice. Authentication To further complicate the scenario, let’s suppose that tenant A uses a MySQL database for its account source and authentication while tenant B uses Active Directory. Our goal is to let tenant A users only use MySQL while tenant B users are limited to Active Directory and we want to do so based on the semantics of the credential passed. Simply put, if the credential id matches the syntax of xyz@tenantA.org, we would want CAS to use MySQL and if the credential matches xyz@tenantB.org, CAS would use Active Directory instead. I am of course assuming, rather obviously, that tenants support username/password authentication modes. Fancier forms of authentication are left out for brevity. Let’s also assume that we know how to configure CAS to use MySQL and Active Directory as authentication sources. With that, the first question we might ask is: Can CAS be configured to use a specific authentication strategy based on the properties of the credential? The answer is, yes. Most authentication strategies in CAS are given a predicate to examine the requested credential for eligibility. This predicate is simply a fancy a condition whose outcome determines whether the authentication strategy/handler should proceed to operate on the credential. So, we can design the following conditions for our MySQL and Active Directory authentication modes: ... cas.authn.jdbc.search[0].credentialCriteria=.+@tenantA\\.org ... cas.authn.ldap[0].credentialCriteria=.+@tenantB\\.org ... In the above settings, the credentialCriteria is a regular expression pattern that is tested against the credential identifier. A successful match indicates credential eligibility. Attribute Retrieval Having configured authentication sources for each tenant, how could we retrieve attributes in much the same way? A number of authentication strategies in CAS have the ability to fetch attributes from the same source in which the account was found. In our case above, we want firstName and lastName to be retrieved from MySQL and cn and givenName from Active Directory once the authentication attempt is successful. The requirements are translated as below: ... cas.authn.jdbc.search[0].principalAttributeList=firstName,lastName ... cas.authn.ldap[0].principalAttributeList=cn,givenName ... Simple, eh? Attribute Release In our quest to multi-tenancy, we need to design a strategy to release bundles of attributes to each tenant. One option is to simply register all applications with CAS and design attribute release policies for each. While reasonable, this approach might lead to some maintenance overhead, especially as you begin to design attribute release rules from a tenant perspective and as that number grows over time. To elaborate, let’s say all applications managed by tenant A should receive the firstName attribute but only a few privileged applications in the same group need access to lastName. Are we to duplicate the same attribute release policy rules for each service definition with firstName as the allowed attribute and only in special cases then make room for lastName? Not quite. What might be more desirable is if we had a way to share policy rules across tenants and definitions to centralize configuration and policy. One option is to use a Groovy script shared across members of a given tenant. For instance, our release policy includes something like this: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"some-application-part-of-tenant-A\", \"name\" : \"Example Tenant A application\", \"id\" : 10, \"attributeReleasePolicy\" : { \"@class\" : \"org.apereo.cas.services.GroovyScriptAttributeReleasePolicy\", \"groovyScript\" : \"classpath:/tenantA-attr-release-policy.groovy\" } } …and the shared script would have the following outline: import java.util.* def Map&lt;String, List&lt;Object&gt;&gt; run(final Object... args) { def currentAttributes = args[0] def logger = args[1] def principal = args[2] def service = args[3] ... } You may also want to get even fancier by assigning arbitrary tags to each service definition to further control different sorts of centralized policies in the script. Themes Based on the CAS documentation for dynamic themes, CAS can also utilize a service’s associated theme to selectively choose which set of UI views will be used to generate the standard views. This is especially useful in cases where the set of pages for a theme that is targeted for a different type of audience are entirely different structurally that simply using a simple theme is not practical to augment the default views. Sounds exactly like what we might want to use for our tenants. In my example, I am simply going to customize the CAS login view fragment for each tenant and then assign the special theme identifier to all tenant A members. Let’s say I am going to call the theme identifier tenantATheme: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"some-application-part-of-tenant-A\", \"name\" : \"Example Tenant A application\", \"id\" : 10, \"theme\": \"tenantATheme\", \"attributeReleasePolicy\" : { \"@class\" : \"org.apereo.cas.services.GroovyScriptAttributeReleasePolicy\", \"groovyScript\" : \"tenantATheme\" } } Then, I would create the theme directory which would contain the customized login view for tenant A members: mkdir -p src/main/resources/templates/tenantATheme cd src/main/resources/templates/tenantATheme touch casLoginView.html My theme may also contain its own CSS and Javascript variants under a src/main/resources/tenantATheme.properties: standard.custom.css.file=/themes/[theme_name]/css/cas.css cas.javascript.file=/themes/[theme_name]/js/cas.js admin.custom.css.file=/themes/[theme-name]/css/admin.css The casLoginView.html found at src/main/resources/templates/tenantATheme will now always be used for applications that are members of tenant A and carry the assigned theme in their definition. Summary I hope this review was of some help to you. As you have been reading, I can guess that you have come up with a number of missing bits and pieces that would satisfy your use cases more comprehensively with CAS. In a way, that is exactly what this tutorial intends to inspire. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/10/23/cas-multitenancy/"
  },

  
  
  
  {
    "title": "JWT Of All Things With CAS",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Apereo CAS has had built-in support for JWTs for some time now in a variety of different ways. Notions of JWT support really date back to CAS 3.5.x with the work @epierce did as a CAS extension to enable token authentication support. Since then, support for JWTs has significantly improved and grown over the years and continues to get better with an emerging number of use cases whose chief concern is improving performance and removing round-trip calls, among other things. In this tutorial, I am going to briefly review various forms of JWT functionality in CAS. Specifically, the following topics will be reviewed: JWT Authentication: Allowing CAS to accept JWTs as credentials in non-interactive authentication modes mostly. JWTs with Duo Security Multifactor Authentication: Exploring an approach where a non-interactive authentication request may be routed to a multifactor authentication flow and back. JWTs as Service Tickets: Allowing CAS to transform service tickets issued for applications into JWTs. Environment Apereo CAS 5.2.0-SNAPSHOT curl 7.54.0 …and last but not least, a functional vanilla CAS overlay. For this tutorial, I am using the CAS Maven WAR Overlay project. JWT Authentication CAS provides support for token-based authentication on top of JWTs, where an authentication request can be granted an SSO session based on a form of credentials that are JWTs. CAS expects a token parameter (or request header) to be passed along to the /login endpoint as the credential. The parameter value must of course be a JWT. Let There Be JWT To generate a JWT, I ended up using the CAS Command-line Shell: cd cas-overlay-template ./build.sh cli -sh This will allow you to enter the interactive shell, where you have documentation, tab-completion and history for all commands. Welcome to CAS Command-line Shell. For assistance press or type \"help\" then hit ENTER. cas&gt; cas&gt;generate-jwt --subject Misagh ==== Signing Secret ==== MY4Jpxr5VeZsJ... ==== Encryption Secret ==== MZCjxBbDFq9cHPdy... Generating JWT for subject [Misagh] with signing key size [256], signing algorithm [HS256], encryption key size [48], encryption method [A192CBC-HS384] and encryption algorithm [dir] ==== JWT ==== eyJjdHkiOiJKV1QiLCJ... Hooray! We have a JWT. There are a variety of other parameters such as encryption methods and signing algorithms you can choose from to generate the JWT. For the purposes of this tutorial, let’s keep things simple. Of course, you don’t have to use the CAS command-line shell. Any valid compliant JWT generator would do fine. Don't Take Things LiterallyI am abbreviating the secrets and the generated JWT above. Do NOT copy paste these into your environment and configuration, thinking they might do the trick. Configure Application CAS needs to be taught the security properties of the JWT to unpack and validate it and produce the relevant authenticated session. For a given authentication request, CAS will try to find the matching record for the application in its registry that is capable of validating JWTs. If such a record is found and the request is in fact accompanied by JWT credentials, the credential is validated and the service ticket issued. My CAS overlay is already equipped with the relevant configuration module and my application record using the JSON service registry looks something like this: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://www.example.org\", \"name\" : \"Example\", \"id\" : 1000, \"properties\" : { \"@class\" : \"java.util.HashMap\", \"jwtSigningSecret\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceProperty\", \"values\" : [ \"java.util.HashSet\", [ \"MY4Jpxr5VeZsJ...\" ] ] }, \"jwtEncryptionSecret\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceProperty\", \"values\" : [ \"java.util.HashSet\", [ \"MZCjxBbDFq9cHPdy...\" ] ] } } } Now, we are ready to start sending requests. Authenticate Using curl from a terminal, here is the authentication sequence: $ curl -i \"https://mmoayyed.example.net/cas/login?service=https://www.example.org&amp;token=eyJjdHkiOiJKV1QiLCJ...\" HTTP/1.1 302 ... Location: https://www.example.org?ticket=ST-1-zmEt1zfAuHv9vG6DogfBeH5ylmc-mmoayyed-4 ... A few things to note: The -i option allows curl to output the response headers where Location in the above case contains the redirect URL with the issued service ticket. The entire url in the curl command in encased in double-quotes. This is necessary for curl to ensure the query string is entirely passed along to CAS. Of course, I can pass the JWT as a request header too: $ curl -i \"https://mmoayyed.example.net/cas/login?service=https://www.example.org\" --header \"token:eyJjdHkiOiJKV1QiLCJ...\" HTTP/1.1 302 ... Location: https://www.example.org?ticket=ST-1-qamgyzfAuHv9vG6DogfBeH5ylmc-mmoayyed-4 ... Grab the ticket from the Location header and proceed to validate it, as you would any regular service ticket. Duo Security MFA With JWTs I want to be able to use my JWT to authenticate with CAS and get a service ticket issued to my application at https://www.example.org, but I also want the request to be verified via second-factor credentials and an MFA flow provided by Duo Security. How do I do that? Duo Security integration support of CAS is able to also support non-browser based multifactor authentication requests. In order to trigger this behavior, applications (i.e. curl, REST APIs, etc.) need to specify a special Content-Type to signal to CAS that the request is submitted from a non-web based environment. The multifactor authentication request is submitted to Duo Security in auto mode which effectively may translate into an out-of-band factor (push or phone) recommended by Duo as the best for the user’s devices. YMMVIf you are using a different kind of multifactor authentication provider, you will need to verify whether it's able to support such behaviors. Configure Duo Security My overlay is prepped with the relevant configuration module of course and settings that include integration keys, secret keys, etc. Application MFA Trigger I am also going to configure an application-based trigger for https://www.example.org so that authentication requests are routed to the relevant multifactor authentication provider. So my application record will take on the following form: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://www.example.org\", \"name\" : \"Example\", \"id\" : 1000, \"multifactorPolicy\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceMultifactorPolicy\", \"multifactorAuthenticationProviders\" : [ \"java.util.LinkedHashSet\", [ \"mfa-duo\" ] ] } \"properties\" : { \"@class\" : \"java.util.HashMap\", \"jwtSigningSecret\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceProperty\", \"values\" : [ \"java.util.HashSet\", [ \"MY4Jpxr5VeZsJ...\" ] ] }, \"jwtEncryptionSecret\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceProperty\", \"values\" : [ \"java.util.HashSet\", [ \"MZCjxBbDFq9cHPdy...\" ] ] } } } Authenticate Using curl again from a terminal, here is the authentication sequence: $ curl -i \"https://mmoayyed.example.net/cas/login?service=https://www.example.org\" --header \"token:eyJjdHkiOiJKV1QiLCJ...\" --header \"Content-Type: application/cas\" HTTP/1.1 302 ... Location: https://www.example.org?ticket=ST-1-gdfe1zfAuHv9vG6DogfBeH5ylmc-mmoayyed-4 ... Things work exactly the same as before, except that this time your device registered with Duo Security will receive a notification where your approval will authorize CAS to establish a session and generate a ticket. JWT Service Tickets All operations so far have issued a regular service ticket back to the application that must be validated in a subsequent trip so the application can retrieve the authenticated user profile. In a different variation, it’s possible for the service ticket itself to take on the form of a JWT. JWT-based service tickets are issued to applications based on the same semantics defined by the CAS Protocol. CAS having received an authentication request via its /login endpoint will conditionally issue back JWT service tickets to the application in form of a ticket parameter via the requested http method. Let's RESTIn case you are using the CAS REST APIs, you should know that service tickets issued as part of REST API operations may also be JWTs. Configure JWTs In order for CAS to transform service tickets into JWTs, essentially we need to execute the reverse of the above configuration steps. We will need to ensure CAS is provided with relevant keys to generate JWTs and these keys are in turn used by the application to unpack the JWTness of generated service ticket. The overlay also needs to be equipped with the relevant extension module of course to allow for this functionality. You may generate the required secrets manually per the above link. In this example, I left them undefined in my properties which forces CAS to generate a few on its own and warn me about them when it starts up: ... - &lt;Secret key for encryption is not defined for [Token/JWT Tickets]; CAS will attempt to auto-generate the encryption key&gt; ... - &lt;Generated encryption key [...] of size [256] for [Token/JWT Tickets]. The generated key MUST be added to CAS settings under setting [cas.authn.token.crypto.encryption.key].&gt; ... - &lt;Secret key for signing is not defined for [Token/JWT Tickets]. CAS will attempt to auto-generate the signing key&gt; ... - &lt;Generated signing key [...] of size [512] for [Token/JWT Tickets]. The generated key MUST be added to CAS settings under setting [cas.authn.token.crypto.signing.key].&gt; Fine! Let’s proceed. Configure Application JWTs as service tickets are issued on a per-application basis. This means that once CAS finds a matching record for the application in its registry, it will try to determine if the application requires JWTs as service tickets. So my application record will take on the following form: { \"@class\" : \"org.apereo.cas.services.RegexRegisteredService\", \"serviceId\" : \"https://www.example.org\", \"name\" : \"Example\", \"id\" : 1000, \"multifactorPolicy\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceMultifactorPolicy\", \"multifactorAuthenticationProviders\" : [ \"java.util.LinkedHashSet\", [ \"mfa-duo\" ] ] } \"properties\" : { \"@class\" : \"java.util.HashMap\", \"jwtSigningSecret\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceProperty\", \"values\" : [ \"java.util.HashSet\", [ \"MY4Jpxr5VeZsJ...\" ] ] }, \"jwtEncryptionSecret\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceProperty\", \"values\" : [ \"java.util.HashSet\", [ \"MZCjxBbDFq9cHPdy...\" ] ] }, \"jwtAsResponse\" : { \"@class\" : \"org.apereo.cas.services.DefaultRegisteredServiceProperty\", \"values\" : [ \"java.util.HashSet\", [ \"true\" ] ] } } } Now, we are ready to start sending requests. Authenticate Using curl again from a terminal, here is the authentication sequence: $ curl -i \"https://mmoayyed.example.net/cas/login?service=https://www.example.org\" --header \"token:eyJjdHkiOiJKV1QiLCJ...\" --header \"Content-Type: application/cas\" HTTP/1.1 302 ... Location: https://www.example.org?ticket=eyJhbGciOiJIUzUxMiJ9.WlhsS05tRllRV2xQYVVwRlVsV... ... This works exactly the same as before, except that now the ticket parameter contains a JWT as a service ticket. Summary I hope this tutorial was of some help to you. As you have been reading, I can guess that you have come up with a number of missing bits and pieces that would satisfy your JWT needs more comprehensively with CAS. In a way, that is exactly what this tutorial intends to inspire. Please feel free to engage and contribute as best as you can. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/10/17/cas-jwt-authn-with-duo/"
  },

  
  
  
  {
    "title": "CAS 5.2.0 RC4 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on Github. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.1.0 GA was released on May 27th 2017. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.2.0. This post intends to highlight some of the improvements and enhancements packed into the fourth release candidate in the 5.2.0 series. The in-development documentation of CAS 5.2.0 is available here. The release schedule is also available here. The release policy is available here. You can read more about the previous release candidate here. Shake Well Before Use Apache Maven Gradle Minors Test Coverage Attribute Resolution Dashboard Management Web Application Authentication Contacts Attribute Value Filters User Interface Redis Sentinel Support JMS Ticket Registry OAuth User Profile Rendering Attribute Consent Attribute Hashing Groovy Support Service Expiration Policies Acceptable Usage Policy MongoDb Storage Groovy Password Encoders Configuration Metadata UI Metrics Storage REST Service Registry Library Upgrades Get Involved Das Ende Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. In order to start experimenting with release candidates, use the following strategies. At any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Apache Maven In the pom.xml of the overlay, adjust the following tag to match below: &lt;cas.version&gt;5.2.0-RC4&lt;/cas.version&gt; Gradle In the gradle.properties of the overlay, adjust the following setting to match below: cas.version=5.2.0-RC4 Minors Thanks to @CobraFlow, delegated authentication using CAS is now able to correctly parse the CAS protocol setting. Cassandra authentication support is now able to correctly pick up the connection factory from the application context, and uses the correct setting for usernames when constructing authentication queries. Thanks to @marwatk, the password management webflow is now correctly registering an event to respond to Password Must Change scenarios. Documentation guidelines to explain how to deploy CAS as an OS service. Thanks to @acvcu, multifactor authentication bypass options now correctly take into account the principal attribute name. Small improvements in the way access strategy policies are enforced, specially when dealing attribute release policies that have semi complex mapping rules. Mapping attributes to be considered as CAS usernames now correctly takes into account multi-valued attributes. Thanks to @marwatk, validating security question answers are now made extensible to account for custom validation rules. Anchor fragments are now automatically preserved while redirecting back to the application with a ticket. MDUI elements for services found in the registry now correctly honor information and privacy URLs. Thanks to @bhohler, verification of credential’s password against Cloud Directory is now done properly. Signing certificates configured for WSFED delegated authentication are now made watchable. Thanks to @bsandiford, memcached serialization via Kryo now takes into account a few more ticket expiration policies and other components. It is also set to issue a warning if and when unregistered classes in the kryo registry are found. CAS as a Spring Boot Application can now be deployed as a fully-executable file. Thanks to @marwatk, extensible error handling logic is now built into the password management to ensure password update operations can correctly report back failure events. Slight cleanup to ensure MongoDb and Redis ticket registries are able to take advantage of crypto operations. Thanks to @sbearcsiro, servide registry auto-initialization from JSON services now is prevented from adding duplicate records. Minor improvements to the audit log message where super long messages are now abbreviated down to 125 characters. Thanks to @marwatk, ordering of security questions for password management is now preserved. Plenty of minor documentation improvements, such a few notes on how the service registry initialization works and what one might be able to do in order to disable CAS’ embedded logging configuration when using an external servlet container. Thanks to @NgSekLong, the signature block type produced in a SAML2 response is now controllable via settings to encode signatures in PEM or DER mode. Thanks to @frett, the payload produced by proxy validation event is now able to remain CAS Protocol v3 compatibble by releasing attributes. X509 principal resolution is now able to support EDIPI defined as part of the certificate’s CN. Remote Trusted authentication is now able to use a custom request header to extract the authenticated username. Delegated authentication is now able to support Keycloak. Test Coverage CAS is now integrated with coveralls.io to report back test coverage statistics. The propduced report will help to identify areas that need more attention in terms of QA and verification. As of this writing, CAS stands at 43% test coverage and that number will continue to grow in the coming months with the addition of test cases and fine-tuning of the reporting tool to skip and ignore relevant areas. Attribute Resolution Dashboard The attribute resolution interface presented as part of CAS dashboard now allows for one to test authentication and observe the CAS payload that might be released to a registered application in the CAS service registry, indicating various protocols. Management Web Application Authentication Authentication strategies for the CAS management web application have been improved to support a few more options. Similarly, authorization rules are now allowed to support JSON/YAML backends. Contacts Thanks to @tsschmidt, the registered service definition model is now able to support contacts. Support for contacts is also made available in the management web application. Attribute Value Filters Thanks to @tsschmidt, attribute value filters are now also supported in the CAS management web application: User Interface Thanks to @tsschmidt, UX continues to see improvements and minor bug fixes. Time and availability permitting, we are working to include workflow and wizard functionality into the interface. Redis Sentinel Support Redis Sentinel provides high availability for Redis. In practical terms this means that using Sentinel you can create a Redis deployment that resists without human intervention to certain kind of failures. Redis Sentinel also provides other collateral tasks such as monitoring, notifications and acts as a configuration provider for clients. Thanks to @ozayduman, components in CAS that integrate with Redis such the Redis Ticket Registry or the Redis Service Registry are now extended to support Sentinel for better HA configuration. JMS Ticket Registry A new ticket registry implementation is now available which based on JMS with support for a variety of messaging systems such as ActiveMQ, Artemis, etc. OAuth User Profile Rendering Additional options are now exposed that control the rendering of the OAuth user profile. Attribute Consent Attribute Hashing BewareThis may be a breaking change. Consult the docs to learn more. Attribute consent functionality no longer applies a SHA-512 hashing function to attribute names and values. The consent decisions are now limited to signing and encryption only. With the one-way hash removed, CAS now presents the functionality underneath to decrypt records and present them back to the user in form of administrative dashboards and user interfaces, allowing users to revoke or modify a decision. Groovy Support Attribute consent can now be managed via an externally-defined Groovy script for easier extensibility and customizations. Service Expiration Policies Service definitions are now given the ability to expire on a designated date. Thanks to @tsschmidt, the management web application also supports this capability too: Acceptable Usage Policy MongoDb Storage Acceptable Usage Policy is now slightly improved to support MongoDb for a storage option. Groovy Password Encoders CAS password encoders are now allowed to be defined as a Groovy script to assist with designing custom encoding schemes. Configuration Metadata UI Accessing CAS configuration metadata is now possible via the CAS dashboards: Most if not all CAS properties are annotated with @RequiredProperty and @RequiredModule which are then picked up by the metadata generation process and translated for REST APIs, etc. Metrics Storage CAS metrics may be routed to varying types of databases for storage and analytics. REST Service Registry Managing service definitions may also be carried out via a REST implementation of your choice. Library Upgrades Spring Boot Spring Webflow Spring jQuery jQuery UI Gradle Hibernate Apache Tomcat Apache Http Client Spring Data Log4j Spring MongoDb Dropwizard Metrics Swagger Bootstrap Datepicker AspectJ MariaDb Driver Google Maps AWS Java SDK Additionally, Javascript linting process is internally updated to support ECMAScript 6. Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Das Ende Big thanks to all who participate in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2017/10/16/520rc4-release/"
  },

  
  
  
  {
    "title": "Extending CAS 5 Webflows",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Unlike previous versions, CAS 5 attempts to automate all required Spring Webflow changes on a per-module basis. This aligns well with the new IDD (Intention-Driven Development) model where all one should have to do is, declare the appropriate module in the build script…and viola. CAS will take care of the rest. You may ask: Wait! What’s really happening? How can it accomplish everything that we had to apply manually before? Why am I being asked to do less work? What exactly do the CAS internals look like? Did machines finally take over? Most importantly, Turkey’s tombili died?! Some answers follow. Hakuna Matata Stop worrying. Stop coding. You are no longer required to become a Spring Webflow ninja or Java champion overnight to apply a myriad of XML configuration snippets here and there to get something to work. That’s all taken care of for you. Sit back and relax. More importantly, avoid making ad-hoc changes to the Webflow as much as possible. Consider how the change you have in mind might be more suitable as a direct contribution to CAS itself so you can just take advantage of its configuration; NOT its maintenance. If you find something that is broken where the auto-configuration strategy fails to deliver as advertised, discuss that with the project community. Submit an issue and/or file a patch. Avoid one-off changes. The “Flexibility” Argument You may have been illusioned to think that the auto-configuration strategy is less powerful because much of the configuration is hidden away and you no longer have the flexibility to change anything and everything. Consider: Just because you had access to 20 configuration files, that did not mean that you could go about changing anything and everything. This claim is not a question of capability. It’s a question of sanity and rationale. Is there a reason the project should expose you to 20 files where in reality, you mostly should, nay, MUST care about just a few? Similarly, just because you now have access to only a few configuration files that does not mean your capabilities of modifying the software internals are now diminished and your freedom lost. The mechanics may have changed but not the underlying principals. In fact, you can do A LOT MORE. What Did You Do? So in the olden days, the following recipe was more or less what was done: Write a Spring Webflow Action in Java that does X. Declare a Spring bean definition in XML that configures that action class. Modify the Spring Webflow configuration to point to that action at the right injection point. Wait. I may have missed a few steps. The recipe did also include: A degree in software engineering and/or computer science may be needed. Learn Java Learn Spring; Convince yourself that this is really expected of you. Learn Spring Webflow; Convince yourself that this is really expected of you. Learn CAS APIs Learn CAS Spring Webflow What is also inconsistent with this strategy is that a perhaps-simple change spanned across multiple unfamiliar barriers. Even if you learned and mastered all the underlying technologies, you still needed to touch Java, Spring XML and Spring Webflow XML configuration to get something to work. Is that verbosity the same thing as flexibility? So, Now What? Every CAS module that needs to dynamically augment the Spring Webflow routes simply takes on the following form: public class SomethingWebflowConfigurer extends AbstractCasWebflowConfigurer { @Override protected void doInitialize() throws Exception { final Flow flow = super.getLoginFlow(); // Magic happens; Call 'super' to see what you have access to... } } CAS modules register their WebflowConfigurer instances in @Configuration classes: @Configuration(\"SomethingConfiguration\") public class SomethingConfiguration { @Autowired @Qualifier(\"loginFlowRegistry\") private FlowDefinitionRegistry loginFlowDefinitionRegistry; @Autowired private FlowBuilderServices flowBuilderServices; @ConditionalOnMissingBean(name = \"somethingWebflowConfigurer\") @Bean public CasWebflowConfigurer somethingWebflowConfigurer() { final SomethingWebflowConfigurer w = new SomethingWebflowConfigurer(); w.setLoginFlowDefinitionRegistry(this.loginFlowDefinitionRegistry); w.setFlowBuilderServices(this.flowBuilderServices); ... return w; } } When CAS comes up, it scans the context to find @Configuration classes and then will invoke each and every WebflowConfigurer to execute changes. What About You? CAS itself handles Spring Webflow changes related to its first-class features by default automatically. That strategy equally applies, should you need to write your own configurers if you absolutely need to. Accidents Happen What if you have two WebflowConfigurers who all decide to inject actions and state into the same Spring Webflow areas? What if multiple WebflowConfigurers are competing to set themselves up as starting points of the CAS webflow? Who wins, who mourns? Indeed, these are questions you ought to be thinking about as a developer. With power comes responsibility. Summary Today: Changes are all scoped to one technology, that is Java. You have the full power of Java to dynamically augment the Spring Webflow as you see fit. Your changes are all self-contained. Unlike XML, your changes are now part of the CAS APIs. If you upgrade and something breaks, you will be notified immediately at build time. That’s all. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/10/07/webflow-extcfg/"
  },

  
  
  
  {
    "title": "August 2017 uPortal Slack summary",
    "text": "In August 2017, 2 people participated substantially in conversation in the slack.apereo.org #uportal channel. (This is around one fifth as many participants as in June.) Andrew Petro Christian Murphy Conversation highlights include: Raising awareness of an initial pass at implementing GitLocalize for internationalizing uPortal documentation c.f. uportal-dev@ thread. Raising awareness of a branch freeze for the uPortal 4.3.2 release c.f. uportal-dev@ thread. Raising awareness of a new GitHub feature for embedding code snippets. Raising awareness of a one liner for re-building and re-deploying skins in uPortal 5 ( ./gradlew tomcatStop overlays:uPortal:clean overlays:uPortal:tomcatDeploy tomcatStart ) Raising awareness of a tool for trying whether WIP code will pass Travis CI without needing to push. On Slack I have concerns about the openness properties of Slack as implemented by Apereo. You can’t access it anonymously. It’s not Google search indexed. Older messages aren’t available even if you log in. Summarizing the conversations here on apereo.github.io in this anonymously, publicly accessible, and Google-indexable context somewhat mitigates these problems. But not necessarily other problems that make email list communications preferable in open source projects. Arguably, all of the conversations held in the #uportal Slack channel could have been held via email on uportal-dev@ or uportal-user@ email lists additionally or instead. Some relevant email list threads are linked above. For myself, I’m convinced that we just shouldn’t use Slack in the Apereo uPortal project. Use the email lists. Possibly look to implementing Discourse for better discussion forums / “email lists”. See also June 2017 uPortal Slack summary (~11 participants) July 2017 uPortal Slack summary (~5 participants) -Andrew",
    "tags": "uPortal",
    "url": "/2017/09/26/August-2017-uportal-slack-summary/"
  },

  
  
  
  {
    "title": "CAS 5.1.x Load Tests by Lafayette College",
    "text": "Contributed ContentCarl Waldbieser, an active member of the CAS community, was kind enough to share this analysis. Lafayette College has an active user base of XXX and regularly records 78 CAS authentication events/minute on average with peaks of 220 events/minute. In preparation of deploying CAS 5.1.x, locust.io was used to put CAS under load and soak and stress tests. Results indicate that CAS 5.1.x deployed with reasonable hardware in a multi-node deployment architecture using nginx+ and hazelcast. Deployment architecture, testing scenarios and results are detailed in the rest of this blogs post. In preparation for a service upgrade from CAS server version 5.0.x to version 5.1.x, load testing trials were conducted on the CAS stage environment. All trials were carried out against the same deployment architecture, with all nodes configured identically. The deployment architecture and nodes have not changed since the last load test was conducted around April 25, 2017. Overview The deployment architecture itself consists of 3 virtual machine nodes: cas3.stage.lafayette.edu cas4.stage.lafayette.edu cas5.stage.lafayette.edu Each node has 3.7 GiB real memory available to it and 2 CPUs. The characteristics of the CPUs are as follows: Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 2 On-line CPU(s) list: 0,1 Thread(s) per core: 1 Core(s) per socket: 2 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 42 Model name: Intel Xeon E312xx (Sandy Bridge) Stepping: 1 CPU MHz: 1899.999 BogoMIPS: 3799.99 Hypervisor vendor: KVM Virtualization type: full L1d cache: 32K L1i cache: 32K L2 cache: 4096K NUMA node0 CPU(s): 0,1 The nodes are deployed behind an Nginx+ proxy in an active-active-active configuration. The nodes share ticket information using encrypted hazelcast messages, so any application state is shared. The Test Swarm The testing framework used was locust.io, a Python based load testing framework. The test suite deploys a fixed number of “locusts” against a web site. The initial population ramps up with a configurable “hatch rate”. In the tests, locusts were conceptually divided into 3 “lifetime” categories: Short-lived locusts live approximately 60 seconds. Medium-lived locusts last for approximately 5 minutes. Long-lived locusts exist for approximately 2 hours. The category to which a given locust is assigned is randomly determined with a ratio of short : medium : long being 7:2:1. Ideally, 70% of the population is short-lived, 20% is medium lived, and 10% is long-lived. The lifetime of a locust determines how long it will retain and make use of a single web SSO session. Short-lived locusts discard their sessions quickly. Long-lived locusts hold on to them for considerable time. All locusts continually request and validate service tickets throughout their lives every 5-15 seconds. All locusts are only 25% likely to log out upon their deaths. The CAS service must continue to track TGTs of locusts that have not logged out until the ticket expires, so this behavior can put pressure on the memory storage resources of the nodes. Each locust uses credentials taken randomly from one of 9 test accounts. Each locust has a 1% chance of entering an erroneous password for an account. Locusts that fail to authenticate will die immediately. When a locust dies, it is reborn immediately. Its lifetime category remains the same, but its SSO session and all other random parameters are reset. SSO Session Tracking SSO sessions are tracked by the TGTs they produce. Any event that creates or destroys a TGT is logged, and these observations are plotted after the fact. Because only 25% of locusts will explicitly end a session, many sessions will accumulate and consume storage in the CAS ticket registry until the session times out. Using the probability of long, medium, and short lived locusts in the population, the actual number of active sessions at any time is estimated. The charts produced should provide a reasonable estimate of how many simultaneous sessions are being managed by the CAS service at any given time. Trial 01 Date / duration 2017-09-05 from 09:30:00-04:00 until 16:44:00-04:00 (7h 14m) Number of locusts 150 Hatch rate 10/s The first trial produced authentication events at a rate of 1,800.11 events/minute. The majority of these were service ticket creation and validation events. The trial was concluded with no noticeable degradation in performance. Net SSO sessions increased at a rate of 73.5 sessions per minute until the idle session timeout duration was reached. Trial 02 Date / duration 2017-09-20, 09:00:00-04:00 - 17:00:00-04:00 (8 hours) Number of locusts 50 Hatch rate 10/s An average of 600.46 events per second were handled by the CAS service under load during this trial. There were no noticeable service disruptions. Net SSO sessions increased at a rate of 27.4 sessions per minute, until the session idle timeout duration was reached. Trial 03 Date / duration 2017-09-22, 09:05:00-04:00 - 09:33:00-04:00 (28 minutes) Number of locusts 175 Hatch rate 10/s Net SSO sessions increased at a rate of 82.9 sessions per minute. Trial 04 Date / duration 2017-09-22, 11:49:00-04:00 - 12:30:00-04:00 (41 minutes) Number of locusts 200 Hatch rate 10/s Net SSO sessions increased at a rate of 93.0 sessions per minute. Trial 05 Date / duration 2017-09-22, 15:10:00-04:00 - 15:47:00-04:00 (37 minutes) Number of locusts 125 Hatch rate 10/s Net SSO sessions increased at a rate of 64.0 sessions per minute. Trial 06 Date / duration 2017-09-22, 16:35:00-04:00 - 16:50:00-04:00 (20 minutes) Number of locusts 250 Hatch rate 10/s Net SSO sessions increased at a rate of 124.6 sessions per minute. Effect of Number of Locusts on Mean Rate of Events Observations from the previous trial and the current trial were plotted in order to give some sense of the influence the number of locusts in the test swarm would have on the mean rate of events processed by the service each minute. The data suggest that for each additional locust added, there are approximately 12 more events generated per minute. Observed and Predicted Mean Rates mean_rate mean_rate_observed locusts 0 1.09 N/A 25 300.51 N/A 50 599.93 600.46 75 899.35 N/A 100 1,198.76 N/A 125 1,498.18 1,496.84 150 1,797.60 1,800.11 175 2,097.02 2,095.36 200 2,396.43 2,395.12 225 2,695.85 N/A 250 2,995.27 2,996.53 275 3,294.69 N/A 300 3,594.10 N/A 325 3,893.52 N/A 350 4,192.94 N/A Effect of Number of Locusts on Increase in SSO Sessions The rate at which net new SSO sessions are created during the period from the beginning of a trial until the discarded TGTs begin to timeout is also useful. Since it seems to be a linear function of the number of locusts, this figure can be used to predict the number of SSO sessions that will be present were a trial to reach the session timeout mark. Conclusions Measurements 1 taken from the production CAS service from September 1-22, 2017 during normal business hours (9am to 5pm) have the following characteristics: mean 78 events / minute median 75 events / minute mode 59 events / minute max 220 events / minute min 8 events / minute standard deviation 28 The data suggests that the production CAS service is operating well under the maximum sustainable load, and should have plenty of capacity to spare for temporary spikes in utilization. Carl Waldbieser 1 Splunk query for Sep 1-21, 2017: index=auth_cas (sourcetype=cas OR sourcetype=cas5) action=* date_hour &gt;= 9 date_hour &lt;= 16 date_wday!=\"saturday\" date_wday!=\"sunday\" | bin _time span=1m | stats count by _time | stats min(count) max(count) mean(count) mode(count) median(count) stdev(count)",
    "tags": "CAS",
    "url": "/2017/09/25/cas51-perfresults-LafayetteCollege/"
  },

  
  
  
  {
    "title": "CAS 5.2.0 RC3 Feature Release",
    "text": "CollaborateThe contents of this blog are managed and hosted on Github. If you wish to update the contents of this post, please submit a pull request to this repository. The official CAS 5.1.0 GA was released on May 27th 2017. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.2.0. This post intends to highlight some of the improvements and enhancements packed into the third release candidate in the 5.2.0 series. The in-development documentation of CAS 5.2.0 is available here. The release schedule is also available here. The release policy is available here. You can read more about the previous release candidate here. Shake Well Before Use Apache Maven Gradle Minors Management Web Application Redesign Authentication Events InfluxDb Storage Caffein for Guava Caching SAML2 Service Provider Integrations Monitoring MongoDb Ehcache Memcached Authentication Interrupt JMeter Performance Testing Attribute Consent LDAP Storage Policy Per Service MongoDb Storage Schema Change Time-based Multifactor Authentication Trigger Protocol Attributes Release per Service OAuth &amp; OpenID Connect Authorized Grant/Response Types Token Revocation Pairwise Subject Identifiers Unique Principal Authentication Policy MongoDb Configuration Surrogate Authentication FIDO U2F MFA MongoDb Storage Audit Storage Acceptable Usage Policy Memcached Ticket Registry Performance Connection Pooling Redis Service Registry SAML2 Improvements SAML2 Artifact Resolution SAML2 Attribute Queries SAML2 POST SimpleSign Library Upgrades Get Involved Das Ende Shake Well Before Use We strongly recommend that you take advantage of the release candidates as they come out. Waiting for a GA release is only going to set you up for unpleasant surprises. A GA is simply a tag and nothing more. In order to start experimenting with release candidates, use the following strategies. At any given time, you should be able to append -SNAPSHOT to the CAS version specified in order to take advantage of snapshot builds as changes are made and published. Apache Maven In the pom.xml of the overlay, adjust the following tag to match below: &lt;cas.version&gt;5.2.0-RC3&lt;/cas.version&gt; Gradle In the gradle.properties of the overlay, adjust the following tag to match below: cas.version=5.2.0-RC3 Minors MongoDb authentication is improved to honor the MongoDb connection pool and threads which monitor that pool. The default port for the management web application when run in embedded mode is now switched to 8444 to avoid conflicts with the main CAS web application server when both are run in the same environment. Thanks to @karlbanke, MongoDb functionality gains a few new additional settings that control ssl, replicas, etc. The default ability of defining Spring beans in XML inside the management web application has been removed. Thanks to @tsschmidt, the /status endpoint is now changed to run synchronous blocking mode to avoid side effects. The default ability of defining Spring beans in XML/Groovy inside the CAS web application has been removed. The management web application is now able to advertise readiness in logs via ascii art. Thanks to @scalding, generating persistent ids in a Shibboleth-friendly way now correctly takes into account the salt and more. Thanks to @robertoschwald, generating primary keys for hibernate schemas is improved to take on a more native approach with some caveats documented that affect MySQL while running in a Galera cluster. Thanks to @tduehr, generating random secure strings falls back to a more performant though ever-so-slightly less secure strategy and algorithm until Java 9 is released. The multifactor trusted device functionality for Google Authenticator and Swivel now correctly registers the relevant MFA flow into the CAS webflow engine at runtime. Thanks to @arbner, SAML MDUI functionality is now able to parse fields based on localized values correctly. Thanks to @arbner, consent functionality is now able to recognize the relevant service when used in SAML IdP mode. Thanks to @pdrados, the attribute name carrying the principal DN as part of LDAP authentication is now set to a static fixed name to avoid attribute encoding issues and easier release policies. A number of small readjustments to schemas that deal with storing trusted device records in databases, in cases where a number of field names clashes with reserved database keywords. Thanks to @SRieckhoff, a possible NPE with SPNEGO authentication is now prevented. SAML1 validation response is now updated in the documentation to ensure it matches the structure produced by CAS. Thanks to @tduehr, Apache Ignite support is given the ability to run in client mode. Thanks to @kingjared, generating SAML1 assertions gains an issueLength property to set the interval between the NotBefore and NotOnOrAfter timestamps. The JSON rendering performance of the CAS validation payload is significantly improved. Management Web Application Redesign Huge thanks to @tsschmidt, the CAS management web application is given an entirely new facelift and redesign using Material UI and Angular 4 based on Typescript. Aside from the fantastic new looks, the application is now able to support and handle most if not all of the configuration knobs and tweaks one can apply to a given service definition. This is a huge milestone allowing for a more solid foundation to start building much fancier integrations and features, such as auto-expiring services, approval workflows and more. Here are a few sample screenshots: Authentication Events InfluxDb Storage CAS authentication events now gain the ability to use InfluxDb for storage. Caffein for Guava Caching Most if not all internal caching strategies and policies have switched from using the Guava library to Caffein. This is for the most part an invisible change, yet the swich allows CAS to dictate more granular expiration policies for caches that apply to each individual entry in the cache, rather than the cache itself as a whole. SAML2 Service Provider Integrations A number of new SAML2 service provider integrations are added to settings that include New Relic, Egnyte and more. Monitoring MongoDb A new monitor is now included that is able to report back status and statistics on a MongoDb instance. Ehcache The Ehcache monitor is now improved to ensure it can work correctly with its ticket registry, taking into account caches created dynamically by the ticket catalog. Memcached The configuration of the memcached monitor is now moved into a separate block in order to leverage and provide support for connection pooling. Authentication Interrupt CAS has the ability to pause and interrupt the authentication flow to reach out to external services and resources, querying for status and setings that would then dictate how CAS should manage and control the SSO session. Interrupt services are able to present notification messages to the user, provide options for redirects to external services, etc. A common use case of this functionality deals with presenting a bulletin board during the authentication flow to present messages and announcements to select users and then optionally require that audience to complete a certain task before CAS is able to honor the authentication request and establish a session. See this guide for more info. JMeter Performance Testing Thanks to @astohn, JMeter scripts for performance and stress testing CAS are now available. Attribute Consent LDAP Storage Thanks to @arbner, attribute consent gains a new storage option to save decisions in LDAP. See this guide for more info. Policy Per Service Handling attribute consent now takes on a more wholesome API approach where there exists a consentPolicy that can dictate how attribute are selected and qualified for consent. See this guide for more info. MongoDb Storage A new storage option is now added to include support for MongoDb. See this guide for more info. Schema Change &times; BewareThis may be a breaking change. Consult the docs to learn more. The structure of a consent decision is changed to rename the field date to createdDate, in to avoid collisions when the storage option is one of JDBC where date is considered a reserved keyword. You may need to readjust the schema manually in order to have CAS recognize existing records. Time-based Multifactor Authentication Trigger Adaptive authentication can also be configured to trigger multifactor authentication based on specific days and times. See this guide for more info. Protocol Attributes Release per Service Attribute release policies gain a small setting to control whether the application is authorized and allowed to receive authentication/protocol attributes. See this guide for more info. OAuth &amp; OpenID Connect Authorized Grant/Response Types OAuth and OpenID Connect service definitions now get to specify the list of supported and authorized response and grant types. Note that for the time being, the absence of authorized response and grant types in the configration simply means the service is allowed to accept everything though this may change in the future. Additionally, some foundational work is done to allow for parsing of requested scopes so they can later be mapped to attribute and claim release policies. Token Revocation Support for revoking OpenID Connect access/refresh tokens is now included in this release. Pairwise Subject Identifiers OpenID Connect support in CAS now presents the ability to support different subject types. This specifically includes support for pairwise subject id generation. See this guide for more info. Unique Principal Authentication Policy An additional authentication policy is now provided that can prevent an authentication event, if the user has already logged on and has a session with CAS. MongoDb Configuration &times; BewareThis may be a breaking change. Consult the docs to learn more. In refactoring a number of configuration classes that deal with MongoDb settings, the MongoDb service registry is changed slightly to use a collection property rather than collectionName in order to keep things consistent across all settings. Similarly, a number of property placeholders have changed from mongodb to simply just mongo in order to again ensure a consistent naming strategy is used everywhere. Surrogate Authentication &times; BewareThis may be a breaking change. Consult the docs to learn more. Surrogate authentication (Impersonation) gains the ability to dictate an expiration policy assigned to a surrogate session. Additionally, surrogate account storage and querying can now be done via a REST resource as well. Access strategies for impersonation are also improved to allow per-service authorization rules. Note that the baseline module to include in the overlay has changed in this release candidate to clearly separate core and webflow functionality. Consult this guide for more info. FIDO U2F MFA MongoDb Storage Device registration records for FIDO U2F may now be saved inside a MongoDb instance. Audit Storage Audit logs are now given the ability to store audit records inside a MongoDb database. Acceptable Usage Policy &times; BewareThis may be a breaking change. Consult the docs to learn more. AUP support gains the ability store decisions via JDBC and REST. Note that the baseline module to include in the overlay has changed in this release candidate to clearly separate core and webflow functionality. Memcached Ticket Registry Performance The registry has long carried the behavior to execute blocking ticket operations. In this release candidate, the registry switches to a more asynchronous model to gain maximum performance. Connection Pooling Memcached client instances are now pooled and during ticket registry operations are borrowed from and then returned to the pool in order to ensure maximum performance. Redis Service Registry A new service registry implementation based on Redis is now available. SAML2 Improvements Federation Interoperability Profile The CAS project strives to conform to the SAML V2.0 Implementation Profile for Federation Interoperability. An evaluation of the requirements against the current CAS release is available here. It is RECOMMENDED that you view, evaluate and comment on functionality that is currently either absent or marked questionable where verification is needed. SAML2 capabilities of CAS in this release provide support for the following: Metadata caching can be controlled via the validUntil element in the entity metadata. A new attribute release filter is now available based on metadata entity attributes. A new attribute release filter is now available to release attributes based on requested attributes specified in the SP metadata. All signing operations are now able to consult metadata in order to resolve signing keys and iterate through all to find a successful matching candidate. SAML2 Artifact Resolution SAML2 capabilities of CAS in this release add support for the Artifact Resolution profile. See this guide for more info. SAML2 Attribute Queries SAML2 capabilities of CAS in this release add support for the Attribute Query profile. See this guide for more info. SAML2 POST SimpleSign SAML2 capabilities of CAS in this release add support for the POST SimpleSign profile. See this guide for more info. Library Upgrades Spring Shell Spring Cloud Sleuth Apache Fediz Apache Fortress Spring Boot Admin Hibernate Validator MongoDb Driver Guava Caffein Amazon SDK Apache Tomcat Google Maps Twillio Kryo PostgreSQL MariaDb Driver Jose4J Apache Ignite Couchbase Driver Thymeleaf Infinispan Dropwizard Metrics Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Das Ende A big hearty thanks to all who participate in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2017/09/15/520rc3-release/"
  },

  
  
  
  {
    "title": "Do State The Obvious",
    "text": "If you are into open source and a bit of a neophiliac when it comes to discovering new software, chances are you have read something akin to the following statements etched proudly at the top of some project’s README on GitHub: Yo! X helps you write applications that behave consistently, run in different environments, and are easy to test. It is fast, simple, reliable with zero-overhead production readiness and nada ceremony. You know why? Because sometimes people wake up in the morning and ask themselves: “What shall I do today? Oh, I know! I shall design a framework that forces applications to behave terribly inconsistent and of course, they must all run in the same exact environment down to the kilobyte level. Not only the application must be crap to test but it must be slow, Lost-The-TV-Show-level convoluted with so much overhead that once you’re done with production, you will yourself wholeheartedly finance a “Thank the Gods for we are forever done with this junk” ceremony. Yes. Yes. That happens, which is why projects need to explicitly state the obvious opposite. Seriously[?], Misagh Moayyed",
    "tags": "Blog",
    "url": "/2017/09/13/efficient-marketing-intech/"
  },

  
  
  
  {
    "title": "Stop Writing Code",
    "text": "As a fellow somewhat active in the technology space and that of open-source identity and access management, a reasonable portion of my time throughout the week is loaned to conference calls reviewing and discussing the viability of software upgrades and feature deployments. Much of this is spent on reviewing what already exists, analyzing any and all available documentation at luck’s behest and finally enumerating approaches to the ultimate upgrade goal. Take note that in the majority of these conversations, the underlying motivation first and foremost is to fall back to stock functionality and try-remove most if not all of the existing local customizations for which at one point significant time and investment was made. “Why?” That is an excellent question. This post intends to provide a local and customized answer. The Trap Amongst many other factors, a significant and common motivation for one to adopt and deploy open-source software is to avoid vendor lock-in and feel empowered by a permitting license to tailor the packaging to one’s needs. Indeed, the source is open and you are for the most part allowed and encouraged to ride the freedom train and turn the package inside out where needed. As time marches on with more applications on-boarded and newer systems integrated, your deployment would be bombarded with all sorts of new and unfamiliar requirements whose successful delivery at times would undoubtedly require writing code. Take a deep breath and pause when you get to this stage, for there be dragons here. Customizations Let’s get the obvious out of the way; not all customizations are “evil”. In my experience, the opposite is usually far truer. In fact, most open-source projects likely have a documented set of guidelines where a certain batch of changes in particular areas of the system is recommended or even expected. In such scenarios, the internals of the deployment are treated very much like a black-box and the software is considered more like a product rather than a platform. Common examples include providing one’s own strategy for authentication, content, user interface and logging where you are expected to make the system uniquely yours. So long as you stay within these boundaries, you will do perfectly fine. It’s when you have to step out of bounds that things get more interesting. Let There Be Change As much as you would try to avoid this, there will be requirements and integrations whose implementation requires you to step out of bounds and write the code. These are the most common rationales I have learned: Integration with home-grown legacy system/behavior. NIH syndrome. “But that’s how we have always done things”. Integration with black box whose design philosophy is immune to reasonable thought and suggestion. Inability or unwillingness to reason with certain stakeholders with sensitive requirements. “Meh…it was faster this way”. Toying around with an exciting new idea with merit for wider adoption. (By far, the most prevalent). So you step into it. Deadlines begin to breath down your neck. Management continues to push for 5am Saturday production deployments to minimize downtime and risk. The inner-child in you continues to have reservations about the nature of the change, the rightness of it all pondering if there is a better path yet you keep reminding yourself to side-step doubt and consider the code and change a temporary solution that would surely be revisited, refactored and hopefully removed some day after production. Of course, that day rarely comes. What’s more alarming is that over time, you continue this exercise again and again…and again such that a year from now, the thing no longer resembles anything of its original nature. Potential Problems Such extensions to software are like bad roommates that rarely move out. They sit on your couch all day, eat your food and insist on watching Grey’s Anatomy all day fascinated by life and love. They require continuous care to ensure the system as a whole would not remain stale and maintenance to warrant unbroken paths to future upgrades. Substantial effort may need to be spent during the design phase as you have to account for best security/coding/deployment practices; Then you would need to document the behavior and share, review and teach it to other coworkers who one day might step into your position. All of this is a very long way of saying: hidden cost. But on the other hand, let’s not forget though that you might have immense satisfaction once you deliver because you very proudly were able to analyze, understand, design, implement and deliver a useful practical needed change. So, good for you. Very well done! It’s quite obvious that none of us can stop change. The legacy systems, the vendors, the integrations, the requirements…they will continue to come and as much as you may disagree with intent or behavior, thou shall deliver. When you start to make changes, the Why and the How are important but those are not this post’s concern. For the purposes of this rant, the Where is where it’s at. Literally. The Where Let me reemphasize that I think the majority of all changes are well intentioned, solve an underlying pain point and on the surface look reasonable and attractive. As a colleague, my personal and professional position is to just evaluate and yet never argue the Why with you, because after all I am just a guest in your house and once I leave, you are responsible for the mortgage. So I might express concerns about the validity and soundness of the use case, but ultimately, it is always and forever will be your decision. Now that we have gotten that out of the way, let’s figure out how we are going to implement the change together. Rather than firing up your workstation immediately to redefine HTTP, exchange passwords in plain-text, design your own message queue or REST-based content protocol and replace XML with JSON because readability or any other creative solutions, I recommend you take the following approach instead. Talk It is likely that someone else in your open-source community has already coded and delivered the very same thing. Nowadays, it’s very difficult to come up with something that hasn’t already been thought of and done by the Simpsons. Ask around. Chances are you will find similarities and opportunities for collaboration. Negotiate So it might turn out that you essentially need to start from scratch. Great. This is your moment in the spotlight to negotiate a contribution agreement with the community. Questions you should be asking might include “Is anyone else interested in this functionality? Is anyone else interested to collaborate on this? Is the community interested in adopting this if and when we deliver?” These are excellent questions. As I have repeatedly outlined, it most often does not matter what this is. Maybe you are working on a brand new capability absent in the current software stack…or maybe you’re adding a new variation to an existing feature, like the ability to use a relational database instead of a NoSQL database…or perhaps you want the system to dance for you based on the native and traditional customs of the end-user’s current region determined by the browser’s locale…who knows. Ordinarily, it’s all good. The worst that could happen is, “No, sorry. Code this for you only”. Execute Assuming positive reception and answers to the above questions, the task would then turn into one of contributing back and figuring out the quirks and the specifics as to make the intended behavior and feature generic and useful enough for the masses. Do not overdo. Do not pre-optimize. Remove institution-specific assumptions, write a bit of documentation and share. Do it all out in the open, from the start without fear. Others will step up to adopt, collaborate and improve the functionality over time, or else it’s perfect just as you intended it to be. With time it will either get better, or the trainman will take it back to the machine world. WIP Read this. So What this post is trying to say, if it’s saying anything, is that your goal in all such endeavors should be to avoid marooning changes on islands whose only citizens are you and your company. At rare times, it might be that the change is so unique enough for others to dissuade them from ever bunking with you on that island and that might be just fine, but most usually the use case is objective, shareable and reasonable. So avoid making custom changes; Being a single parent is tough, so avoid carrying the maintenance burden solely on your own. Avoid treating your deployment unreasoningly unique. You are not that special. Stop writing code. Write it where it belongs. Misagh Moayyed",
    "tags": "Blog",
    "url": "/2017/09/10/stop-writing-code/"
  },

  
  
  
  {
    "title": "CAS 5.1.x User Swap - Cause and Analysis",
    "text": "Contributed ContentTravis Schmidt, an active member of the CAS community, was kind enough to share this analysis. Problem Shortly after deploying CAS 5.1.2 to our production environment, we received incident reports of users signing into various systems as themselves, but were presented with the accounts of other random users. The first applications we received reports on were GMail and Box, which both used Shibboleth and the ShibCAS plugin to authenticate, so that is where we first focused our attention. Later that day after investigating the first incidents, another was reported on a system that only used CAS to authenticate and our attention switched solely to CAS. After the CAS only incident was reported we did an emergency roll back to our previous CAS 4.2.6 version. After the rollback, no new incidents have been reported. Reproducing the Error First Attempt In order to try and identify a cause we looked at the differences between our development environment and our production environment. The most obvious difference is that production is four nodes while development is only three nodes. Since it appeared user info was swapped, the Hazelcast ticket registry was our first suspect and we focused our initial efforts there. We added a fourth node to match production and began load testing again, but were not able to reproduce the error with just this added. Second Attempt We next focused on our JMeter script used to load test the application. We modified it to put random delays between users being presented with the login page and posting the login page, calls to all three service validate protocols, and a delayed logout to about half the user threads. We still did not produce the error with this new script. Third Attempt Lastly we tried a massive amount of load, significant factor higher than what we expect in production. We saw significant amount of timeout errors and where the system could not keep up, but not the user swap error. Finally I realized that a significant difference between this deployment and our previous deployment was the removal of the statistics/ping endpoint. This meant that the F5 load balancer, and the monitoring systems were changed to call the cas/status endpoint. In production this meant that the cas/status endpoint was being called on each node once every 2-3 seconds. For all the load testing we did before deployment and after, the development nodes were removed from the load balancer and a static page was being sent to the F5 from Apache. This extra load was never present when running load test before deployment. After running the load test with this cas/status being called by the F5, we started to see the timeouts happen earlier in the run. For all test runs to this point I was stopping the test at the first error, and then trying to exam the state of the system. No real information was gleamed from looking at logs. After one test had stopped I tried doing a cas/login to the node that produced the error. This is where our breakthrough came. Instead of being presented with the login page, I was looking at the status page. I set the tests to only stop the thread that caused the error and continued running the test. This is when we started to see the responses start to be mixed. It would always start with AJP timeouts, but after a bit we start seeing responses being mixed, and eventually two service validate calls would hit just right and tesuserYYY would be validated as testuserXXX. Now we were able to consistently reproduce the error. Identifying the Cause Deployment Infrastructure CAS is run on Apache Tomcat servers that are fronted on each instance by an Apache httpd web server that uses AJP to proxy request to the application. I think this configuration is quite normal and probably used widely elsewhere. We focused our attention on Apache, firstly because they were upgraded the same time as the deployment, and secondly because restarting the web server on an affected node cleared the swapping issue. We tried downgrading, and applying even newer updates, but the problem still persisted. We then tried to upgrade Tomcat to 8.5.x from our current 8.0.x version that we are using, but the problem still persisted. Analyzing Customizations We have quite a few customizations that we make to the CAS application. In order to rule out that we introduced the issue with our code, we created clean version of the CAS 5.1.x branch with Hazelcast, LDAP and Duo Security modules compiled in. The error still occurred with this version of CAS. Analyzing the Network We next focused on the AJP proxy between Apache and Tomcat. We reconfigured Tomcat to accept connections on 8443 and called it directly bypassing Apache. This somewhat mitigated the issue. After several runs this way we always saw swapping occur, but it always seemed to just swap the status page with a login or service validate call, but never saw the CAS protocol endpoints swap, or a user swap on validate. Viola! Our focus was then on to the component that produces the status page, HealthCheckController. After numbly staring at the code for a while, and trying a few things, we finally noticed that the mapped method for the status page was coded to return a WebAsyncTask. How the callable object was being used would turn out to be the cause of our issue. Fixing the Problem I put together a patch targeted at the next CAS 5.1.x release (5.1.4 at the time of this writing) to address this problem. The patch is of course merged, and it is also brought forward to master. You should be able to mitigate this problem, the very next time you upgrade your CAS 5.1.x instance. To see the CAS release schedule, please click here. Travis Schmidt",
    "tags": "CAS",
    "url": "/2017/08/31/cas5-userswap-buganalysis/"
  },

  
  
  
  {
    "title": "Summer 2017 uPortal Roadmap Update",
    "text": "Summary Almost two dozen conference attendees came to the uPortal Roadmap BOF at the Open Apereo 2017 conference. Prior to the conference, members of the community were invited to submit and comment on roadmap ideas in a shared google doc. 15 items were suggested but during the BOF we focused on which ones we anticipated someone would actually devote time and resources to. In the end, we anticipate making progress over the next year on the 8 items listed below. Release of uPortal 5 This long awaited release includes a refactoring of the build system using a Gradle-based build in the uPortal-start repository. We are currently aiming for a mid-September release candidate and feature freeze followed by a GA release by the end of October. Semantic versioning and releasing often While no specific action items were identified, we renewed our commitment to ship releases more often and use semantic versioning when doing so. We should not be afraid of doing more frequent major releases. Better web service API documentation Most of the existing web service APIs are not well documented. This makes them harder to use or sometimes even be aware of. There was a commitment to documenting new APIs that are developed. UW-Madison committed to documenting APIs it depends on. Easier adoption: Complete and accurate documentation A work in progress, we are looking at shifting uPortal 5 documentation to github.io with an initial focus on installing and configuring core uPortal. This remains in early stages and the details are in flux. Discussion continues on the uportal email lists. Separation of presentation layer This will be a work in progress for some time. While uPortal Home has adopted this modern architecture, uPortal core is being refactored piecemeal. It is anticipated that developers will move towards more modularization as they work with specific parts of the codebase. uPortal install - demo edition (fka QuickStart) This would be a modern version of the quick start we previously published with uPortal releases. Someone interested in seeing uPortal in action would be able to download the demo edition and have it running locally within minutes. uPortal install - front end developer edition While the demo edition is targeted for demonstration purposes only, this version of uPortal is an easy way for front end developers to stand up a uPortal server locally, turn it on, and start developing the front ends of applications. The only additional requirements would be downloading a JDK and git client and cloning the uPortal-start repo. Develop a lightweight uPortal ecosystem incubation process Developers in the uPortal community are doing interesting innovative work for local campuses that others could benefit from yet this work cannot be easily adopted. This roadmap item is an effort to lower the barriers to local work participating more directly in the greater uPortal ecosystem. The uPortal Steering Committee is close to issuing a draft of a process that, given certain assumptions, will make it easier for someone to share code without having to go through the full Apereo project incubation process. Everyone has some code to share. Borrowing from the Sirius Cybernetics Corporation, “Share and enjoy!” Jim Helwig uPortal Steering Committee Chair",
    "tags": "uPortal",
    "url": "/2017/08/30/summer-2017-uportal-roadmap-update/"
  },

  
  
  
  {
    "title": "Interrupt CAS With Class",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The fastest route to a 10X engineer is to give them 0.1X the distractions. - Eric Meyer While that is generally sensible advice, when it comes to CAS there are times where you wish to interrupt the CAS authentication flow and the present the end-user with notifications and annoucements. A common use case deals with presenting a message board during the authentication flow to select users and then optionally require the audience to complete a certain task before CAS is able to honor the authentication request and establish a session. Examples of such messages tasks may include: “The kitchen’s menu today features Khash. Click here to get directions.” or “The office of compliance and regulations has announced a new policy on using forks. Click to accept, or forever be doomed with spoons”. This is a tutorial on how to present such interruptions to your CAS audience, as a fairly recent feature in CAS 5.2.x and beyond. To learn more about this behavior, please see this guide. &times; WATCH OUT!As of this writing, CAS 5.2.x is not officially released. See the release schedule for more info. Interrupt Source First and foremost, there needs to be an engine of some sort that is able to produce notifications and interruptions. CAS supports a range of such engines that are backed by JSON &amp; Groovy resources, REST endpoints or one you decide to create and inject into the runtime. For the purposes of this tutorial, I will be using the static JSON resource which is a perfectly suitable option for super small deployments or relevant during development and testing. The JSON resource path is taught to CAS via the following setting: cas.interrupt.json.location=file:/etc/cas/config/interrupt.json Interrupt Rules Once you have defined the above setting and assuming your overlay is prepped with relevant configuration module, CAS will attempt to understand the interruption rules that are defined in the interrupt.json file. My rules are defined as such: { \"casuser\" : { \"message\" : \"We have interrupted your CAS authentication workflow to bring you the following information. Select one of the links below to go somewhere and do something fun and then come back to continue with &lt;strong&gt;CAS&lt;/strong&gt;.\", \"links\" : { \"Go to Google\" : \"https://www.google.com\", \"Go to Yahoo\" : \"https://www.yahoo.com\" }, \"ssoEnabled\" : false, \"interrupt\" : true, } } The above ruleset simply says: Whenever casuser authenticates, present the message to the user with a number of links. Make sure an SSO session is not established which would have the user present credentials again in subsequent attempts. The Looks Once that is all in place, casuser will see the following screen, after having authenticated successfully: It’s that simple. So… For more advanced and production-quality interruptions you likely need to write a Groovy script or design a REST endpoint that ties CAS with your own institutional messages and you most certainly should want to decorate the user interface much better. Given this is very new today, I am sure you will find plenty of opportunities to improve the functionality with more cowbell. Laundry doesn’t fold itself so please do. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/08/30/cas-loginflow-interrupt/"
  },

  
  
  
  {
    "title": "Let Your Docker Containers Speak",
    "text": "If you are like me, you have probably come to the same conclusion that Docker does wonders with the automation of much of the needed infrastructure while working on a particular development task. For example, I primarily keep myself busy in the realm of Identity and Access Management (IAM) and there does not a day go by where I find myself in need of a running SAML service provider, a CASified PHP application protected by mod_auth_cas running inside Apache, or a full blown Grouper deployment for which I might be trying to add a changelog consumer, etc. Docker can automate and (more importantly) isolate all of that noise, allowing me to focus on the task at hand. Today and while I have opted for both approaches given context and need, my preference is to keep the core platform/application I am working on outside the running Docker ecosystem while leaving all of the stuff-I-need-for-the-integration components inside. I find that this strategy allows for faster builds and more performant/natural debugging and diagnostics. However, one problem I run into often is: how do I connect the two separate environments? Or put another way, how do I let a component running in Docker make a back-channel call to something outside running on the host? Being so far away from home can be challenging. This blog is about that problem. That Problem My docker setup usually is based on this project, which is the wonderful produce of my esteemed colleague, @jtgasper3. As the perfect IAM testbed, it is composed (catch the pun?) of an LDAP server, a Shibboleth SP, Apache httpd, a CASified PHP application, simpleSAMLphp, a Shibboleth IdP and possibly more. I simply enable/disable components I need running in the package and viola! It takes care of the rest. I am not going to bore you with all the intricate details of how this is all organized docker-wise, but one thing that is perhaps relevant is that each running component is tagged with a networks configuration that simply controls the application networking via custom networks where each can be linked to a driver configuration (i.e. bridge, the default for the Docker engine). This might come in handy, should you decide to go fancier and beyond what I explain here for a solution. Long story short, the issue had to do with the dockerized Shibboleth SP unable to make a SOAP query to my IdP running outside. If you think about it, this sort of makes sense. What runs inside does not necessarily know anything about what’s on the outside. It might seem like everything is simply running on the same machine, but localhost for you, an outsider, is a very different unknown to the Shibboleth SP container running in its own network. I needed an inside man. One Solution I am convinced there are better solutions that muck around with native docker networking configuration, bridging host and container. Indeed, one can set up extra hosts, perhaps define a host network mode of some kind, etc. Who knows! That was a rabbit hole I didn’t want to venture into and so I settled for the following simpler albeit temporary solution. export DOCKERHOST=$(ifconfig | grep -E \"([0-9]{1,3}\\.){3}[0-9]{1,3}\" | \\ grep -v 127.0.0.1 | awk '{ print $2 }' | \\ cut -f2 -d: | head -n1) If you open up your terminal and run that command, you might see something like: &gt; echo $DOCKERHOST 192.168.1.170 Sweet! Next, I was able to modify the relevant configuration files and use 192.168.1.170 anywhere the dockerized Shibboleth SP needed to make a call to the outside world. While this works fine, I should note that it is absolutely a temporary solution as hardcoding an IP address that might change later on obviously is a broken path but it did suffice my development needs at the time. Post-credits Scene …and oh, if you need to find a quick way to SSH into a running Docker container, put the following in your profile: function dockerssh() { export CID=$(docker ps -aqf \"name=$1\"); docker exec -it $CID /bin/bash } Then use as follows: dockerssh [container-name] …and you’re in. HTH. Misagh Moayyed",
    "tags": "Blog",
    "url": "/2017/08/24/tip-docker-container-to-host/"
  },

  
  
  
  {
    "title": "Better by design 2017: Integrating accessibility across design and development lifecycle",
    "text": "I recently attended a day-long workshop on Integrating accessibility across the design and development lifecycle by Karl Groves at Better By Design 2017. The most important point I took from the workshop was a reminder to automate functionally testing the front end for those usability characteristics and WCAG targets amenable to automated testing. Mostly the workshop was a call-to-action to care about accessibility, to comply with law and regulation about accessibility, and to avoid expensive legal liability. The workshop motivated thinking about accessibility and usability through the lens of fictional startups wherein, contrary to our typical lived developer experience, accessibility would be prioritized in product vision, design, hiring, corporate priorities, technical support, etc. A healthy thought experiment perhaps too far from my lived reality to be fully relatable. Automate front-end testing. Suggested tech stack: Selenium WebDriver : drive web browsers via automation Mocha: JavaScript test framework Chai: assertion library Should: another assertion library Cucumber : executable specifications The speaker’s product, tenon.io , has something to offer for a11y checking automation. It’s usability Don’t primarily think of it as a11y, as extra stuff to do to accommodate disability. Think of it as making your app usable for everyone. Focusing on a11y and disability is useful for legal compliance and to help broaden thinking of all the users and all their needs. If it takes thinking about blindness specifically to get you to pay attention to screen reader experiences, so be it. But mostly if you build it right, if it’s clear what things are and what they do, if it’s usable and thoughtful and high quality, accessibility takes care of itself. And of course automate testing for any code quality characteristics that can be automatically detected, because that’s what computers are for. Software development has a quality and a culture problem The problem is Software products are of agonizingly poor quality. Software development culture is often broken, with lack of empathy, empowerment, attention to quality and detail, resources. Of course low quality software built in agonizing culture has poor usability and poor accessibility. Do less. Do it with radically higher quality. Win. The different versions and levels of WCAG WCAG 1: three priority levels (1, 2, 3) organized by importance to the usability. WCAG 2: A, AA, and AAA levels organized by expected cost to implement. WCAG A is no-UI-impact stuff that you have no excuse not to do. Very low cost. WCAG AA is modest-impact stuff that you really ought to do but it comes at a cost. This is de-facto where the industry has landed as acceptable. You’re liable to suit if you don’t meet WCAG AA; remediation will likely be to meet WCAG AA. WCAG AAA is potentially tremendously expensive stuff. All of A, AA, and AAA are important to accessibility, usability. It’s not that the AAA stuff isn’t important, it’s that it’s potentially expensive to comply. Good practice: meet all of AA. Meet parts of AAA that you can feasibly achieve. Good practice: don’t volunteer to meet AAA – you’re probably just not going to do it. Recommendation: lurk or participate directly in WCAG 3 standard development. ( community group) Performance budget analogy Concept: performance budget. From the outset, how slow will we allow our site / application / pages to be? By what measures? Then work within that budget. Analogous concept: accessibility budget. How un-usable will we allow our site / application / pages to be? Then work within that budget. Don’t remediate to WCAG AA. Decide WCAG AA is your “accessibility budget” from the outset and anything violating WCAG AA, it’s just not in your project’s budget. Drag-and-drop re-ordering as a11y challenge Almost any UI control can be made usable and accessible for all users. Drag-and-drop re-ordering is a notorious exception to this. Provide an alternative experience so that users who cannot easily use visual drag-and-drop controls can instead re-order or re-arrange objects in another way. Misc Other grab bag of points made, references. Accessibility as differentiator on resume. a11y is important and getting more important; companies are hiring for it. Paciello Group: inclusive design principles. Inclusive Design Patterns book by Heydon Pickering . Seems to be available online as a PDF. Brad Frost atomic design, pattern lab Inclusive Design Principles Josh Blue (comedian) DHS Trusted Tester program Just Ask: Integrated Accessibility throughout Design (book) (contents available online) Lean UX (book) ARIA practices guide , as published Planning to automate MyUW accessibility testing Added to draft Q4 MyUW roadmap an item to automate functionally testing a11y criteria in MyUW as deployed to a test tier. This doesn’t guarantee we’ll actually do this in Q4 – it just places a reminder to consider it when tightening up Q4 planning. -Andrew",
    "tags": "a11y",
    "url": "/2017/08/22/bbd-integrating-a11y-across-lifecycle/"
  },

  
  
  
  {
    "title": "CAS 5.2.0 RC2 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.1.0 GA was released on May 27th 2017. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.2.0. This post intends to highlight some of the improvements and enhancements packed into the second release candidate in the 5.2.0 series. The in-development documentation of CAS 5.2.0 is available here. The release schedule is also available here. The release policy is available here. You can read more about the previous release candidate here. Minors Default Theme For Services Authentication Plan Configurators Authentication Graph Dynamic Authentication Policies Configuration Documentation What does this mean for you? Why not use plain markdown instead? Configuration Metadata Server Apache Fortress Integration SQRL Authentication Support Encryption/Signing Log Messages Clustered Service Replication Gradle Build Performance Service Definition File Checking Scripted Username Providers Attribute Consent SAML2 Metadata Expiration Swagger Documentation CAS Demos Multimapped Attributes Password Management REST Attribute Repository Scripted Attribute Repositories Surrogate Authn via JDBC Library Upgrades What’s Next? Get Involved Das Ende Minors Service access strategies based on principal attributes should now correctly be enforced prior to jumping into subsequent factors of authentication. Thanks to @gbatalski, JWT authentication in CAS is now able to support base64-encoded secrets. Thanks to @benht, expired tickets are now properly removed from CAS when using MongoDb ticket registry. Thanks to @klewczuk, refresh tokens are no longer auto-generated when using grant type refresh_token. Thanks to @WhiteMarlin, a number of reference to Jasig are now removed from CAS language bundles. Database drivers are now defined to be available at runtime via the published POM, so they can be included in the overlay. Groovy/Scripting utilities are cleaned up to use a consistent strategy across the codebase where needed. MongoDb Ticket/Service registry configuration is now able to take advantage of distinct unique group of settings. YAML service registry bean is now properly renamed so it can honor @Conditional annotations. Thanks to @pdrados, throttled authentication attempts are better explained in the UI via a new http status code. Service registry initialization from JSON is now able to honor service definitions found at the path specified via settings, rather than only loading those found on the classpath’s services directory. Thanks to @bbooth, password management flows now correctly register a password update state. Thanks to @swoeste, URL validation is now provided an option to support localhost type urls, when dealing with things such as SLO. Thanks to @tduehr, generating random strings that specially affect ticket ids and such are now improved to use more secure algorithms and strategies. Default Theme For Services Thanks to @swoeste, the CAS default theme is now also consulted by registered services. Services still have the ability to define a specific theme and have it be resolved by the theme resolution machinery, but if no theme is defined, services are now given the ability to fall back onto the default theme specified by cas.theme.defaultThemeName. Authentication Plan Configurators All configuration components in CAS that register authentication handlers into the runtime engine have now become their own @Bean marked as @Conditional for easier overrides. Authentication Graph The CAS statistics page now boasts the ability to present authentication events as a chart. Dynamic Authentication Policies Additional authentication policies are now made available to check account status and state via Groovy and REST endpoints. This is useful in the event that the underlying authentication scheme does not provide a way to check for account status and you wish to resort to more elaborate means of enforcing policies dynamically. See this guide for more info. Configuration Documentation &times; BewareThis may be a breaking change. Consult the docs to learn more. The entire CAS configuration model is now annotated and documented using Javadocs. The build process is also augmented to scan the configuration model and produce a repository of all settings, groups, etc along with their description, values, hints and documentation. This repository is then later used by the CAS configuration metadata server to allow deployers to query settings via REST or CLI tools. In future releases, GUIs will also be able to auto-initialize a module using relevant settings that are sorted and ranked from the same repository instance. What does this mean for you? In cleaning up the configuration model and in order to maximize reuse, a number of duplicate settings were moved around and refactored so as so to allow centralization of documentation items without having to duplicate notes and descriptions. At a high level, the following category of settings are cleaned up and made reusable: Various encryptionKey and signingKey settings were duplicated throughout the codebase. These are now cleaned up so that for instance every component that requires access to crypto-related settings now hosts crypto.encryption and crypto.signing settings that house keys and settings in a reusable way. The same strategy is also applied to scheduler-related tasks that define repeatInterval and startUpDelay where these are moved to a parent reusable component that is usually noted by the schedule key name (i.e. cas.xyz.schedule.repeatInterval rather than cas.xyz.repeatInterval). Properties that referenced a Spring-managed resource prior to this release took the form of cas.setting.config.location. These are now cleaned up to simply define the resource as cas.setting.location. Explicit properties are now made available for both JSON and YAML service registries in form of cas.serviceRegistry.json and cas.serviceRegistry.yaml. In your own local configuration, you will need to adjust key names to match the new locations. Why not use plain markdown instead? This all means that rather than documenting every single setting and key in the project documentation via markdown, the project documentation specially for settings and confguration now sits right beside the setting itself. This not only turns documentation into working code, and it not only provides additional processing power and querying to be done on the setting, it furthermore allows the codebase to automate the requirement of documentation for settings as well and fail the build in case something goes undocumented. Note that this is just a very modest starting point and the field descriptions that now are available for settings will continually need to be improved, revised and expanded. Writing good documentation for adopters who step forward with varying levels of skill is a very difficult and delicate task and good-enough is usually never enough. You’re encouraged to continually improve the docs and explain things to the level you deem appropriate for your own audience. Configuration Metadata Server The metadata server is an interactive CLI tool that allows one to query the CAS configuration metadata and learn more about propeties, groups, etc. The configuration metadata repository is built and generated for every CAS build and release and the metadata server is then simply tasked to query the database and respnd to commands. The server ships with both a CLI as well as interactive shell interface. See this guide for more info. Apache Fortress Integration Thanks to @yudhik, CAS gains integration support with Apache Fortress. Apache Fortress is a standards-based access management system that provides role-based access control, delegated administration and password policy services with LDAP. Read more about the CAS integration here. SQRL Authentication Support Modest amount of work has been done to begin support for the SQRL Protocol. This is very much in an experimental state as both the specification as well as client implementations today are rather incomplete and in flux. This will eventually be ironed out, provied the finalization of the protocol spec itself. Encryption/Signing Log Messages In certain cases where CAS begins to generate keys for signing/encryption tasks, there are now additional log messages that indicate the setting name under which the newly generated key must be placed. 2017-07-24 07:29:26,249 WARN [org.apereo.cas.util.cipher.BaseStringCipherExecutor] - &lt;Secret key for encryption is not defined for [Ticket-granting Cookie]; CAS will attempt to auto-generate the encryption key&gt; 2017-07-24 07:29:26,259 WARN [org.apereo.cas.util.cipher.BaseStringCipherExecutor] - &lt;Generated encryption key [...] of size [256] for [Ticket-granting Cookie]. The generated key MUST be added to CAS settings under setting [cas.tgc.crypto.encryption.key].&gt; Clustered Service Replication CAS gains the ability to replicate and redistribute registered service definition files across the cluster via Hazelcast and more. See this guide to learn more. Gradle Build Performance Internally, the CAS Gradle build is readjusted to ensure required build repositories are only made available to submodules that need them for artifacts, which should allow for much faster load times when the project is loaded into a development environment in a non-offline mode manner. Service Definition File Checking In the event that a resource-based service registry is employed (i.e. JSON, YAML), additional checks are now built in to ensure that the service files are named appropriately. Scripted Username Providers CAS gains the ability to use Java’s native scripting functionality for username attribute providers to support Groovy, Javascript and Python scripts. Attribute Consent At last, CAS provides the ability to enforce user-informed consent upon attribute release. SAML2 Metadata Expiration SAML2 services now gain the ability to define an expiration duration for their metadata. If left undefined, a global default will be used for all resolved metadata in the cache. Swagger Documentation CAS is now able to auto-generate API documentation for all endpoints, controllers and REST services, via Swagger. CAS Demos &times; BewareThis may be a breaking change. Consult the docs to learn more. A number of URLs for CAS demos running on Heroku have changed. Multimapped Attributes CAS gains the ability to map and rename the same attribute definition multiple times to different names. This can be done either as part of attribute retrieval or at release time. Password Management &times; BewareThis may be a breaking change. Consult the docs to learn more. Password management functionality in CAS is now broken up into distinct modules depending on the backened storage service in use. REST Attribute Repository CAS gains the ability to contact REST endpoints to resolve attributes. Scripted Attribute Repositories CAS gains the ability to use Java’s native scripting functionality for attribute repository sources to support Groovy, Javascript and Python scripts to resolve and retrieve attributes. Surrogate Authn via JDBC CAS gains the ability to support surrogate authentication via JDBC resources. Library Upgrades Apache Tomcat Eureka Spring Boot admin Spring Spring Boot Pac4J Amazon SDK Spring Cloud Jose4J Apache CXF Postgresql driver MariaDb driver MySQL driver Couchbase Apache Cassandra Gradle Hazelcast Ldaptive What’s Next? We are all working to make sure the CAS 5.2.0 release is on schedule. Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. Das Ende A big hearty thanks to all who participated in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2017/08/04/520rc2-release/"
  },

  
  
  
  {
    "title": "July 2017 uPortal Slack summary",
    "text": "In July 2017, 5 people participated substantially in conversation in the slack.apereo.org #uportal channel. (This is around half as many participants as in June.) Andrew Petro Benito Gonzalez Christian Murphy Drew Wills KaJuan Johnson Conversation highlights include: Christian expressing interest in the new GitHub feature around CODEOWNERS files automating suggested code reviewers. (uportal-dev thread). Drew expressing excitement about a Pull Pequest removing Ant and Maven from the uPortal-start build. (uportal-dev@ thread) KaJuan asking about filtering and placeholder replacement in Gradle. Christian expressing excitement about a Pull Request cleaning up uPortal’s Gradle build Christian asking that the Coveralls status reports for uPortal PRs be switched back on. Christian asking about uPortal-developer GitHub team access to a couple specific repos. A branch of conversation about Apereo needing something like the Apache Attic A branch of conversation with the insight that if we want to emulate Apache, maybe we should just do more of our work directly in an Apache Software Foundation context. Love for the now active Apereo uPortal Twitter account and exploring updating its avatar image. On Slack I have concerns about the openness properties of Slack as implemented by Apereo. You can’t access it or read its logs anonymously; it’s not Google search indexed. Past ten thousand messages back, messages aren’t available even if you log in. Summarizing the conversations in this anonymously, publicly accessible, and Google indexable context somewhat mitigates these problems. But not necessarily other problems that make email list communications preferable in open source projects. Arguably, all of the conversations held in the #uportal Slack channel this month could have been held via email on uportal-dev@ or uportal-user@ email lists additionally or instead. Some relevant email list threads are linked above. -Andrew",
    "tags": "uPortal",
    "url": "/2017/08/02/july-2017-uportal-slack-summary/"
  },

  
  
  
  {
    "title": "June 2017 uPortal Slack summary",
    "text": "In June 2017, 11 people participated substantially in conversation in the slack.apereo.org #uportal channel. Aaron Grant Andrew Petro Brandon Powell Christian Cousquer Christian Murphy David Sibley Drew Wills Jim Helwig Marissa Warner-Wu Matt Clare Tim Vertein Conversation highlights include: Aaron Grant’s uportal_commit_stats script and findings about uPortal contributions. gitinspector might also be useful for uPortal-related Git history analysis. Internationalization of documentation stored in Git. What Symfony does in its primary and French-translation documentation. (Separate repos.). Alternatively, the jekyll-multiple-languages-plugin . Example ReactJS portlet with i18n support based in i18next. Sharing resources from the Open Apereo 2017 conference, including Portal?! uPortal! What is this Béchamel, Speeding up uPortal with ReactJS, two-hard-problems. (Cf. uportal-dev@ thread re conference artifacts.) Encouraging interest in the new Accessibility group. (Cf. Accessibility Across Apereo thread on uportal-user@) styled-components for styling React.js apps, browser support for Polymer. conversational UI example Weather API options, including World Weather Online, Weather Underground, weather.gov, DarkSky API. The @uPortal Twitter account. The role of some CSS classes ` up-portlet-control focus externalLink` (turns out to be used in some JavaScript associated with the maximize menu option). uPortal 5 fanciness for setting up Tomcat and deployment via Gradle. Renaming the overlays directory (cf. uportal-dev@ thread on overlays directory renaming or another). myday cloud-based portal sonar, a linting tool for the web On Slack I have concerns about the openness properties of Slack as implemented by Apereo. You can’t access it or read its logs anonymously; it’s not Google search indexed. Only the most recent ten thousand messages are available, so in practice this means logs are unavailable older than about a month back. Summarizing the conversations in this anonymously, publicly accessible and Google indexable context somewhat mitigates these problems. But not necessarily other problems that make email list communications preferable in open source projects. Arguably, all of the conversations held in the #uportal Slack channel this month could have been held via email on uportal-dev@ or uportal-user@ email lists additionally or instead. Some relevant email list threads are linked above. -Andrew",
    "tags": "uPortal",
    "url": "/2017/07/05/uportal-slack-summary/"
  },

  
  
  
  {
    "title": "Apereo CAS - Contribution Guidelines",
    "text": "Most if not all open source projects [should] have a contributor guide, whose job is to explain the project policy and pace when it comes to accepting changes from the community. Indeed and among many other things, providing guidelines and documentation that teach one how to build, test and contribute patches of all sorts and colors is a pretty good sign of a healthy project and a vibrant community. The overarching theme of this guide starts with the following questions: What is the Apereo CAS project policy on accepting contributions? How may one, seriously and in a step-wise fashion, get started with contributions? What do I work on? Certain number of projects in open source try to advertise work items and tasks which they think might be good candidates for contributions. This is generally and often not the Apereo CAS project policy. The policy is much simpler than that. It goes something like this: Everything is ideal for contributions. In other words, There is no “We vs. You”. There is no “Some folks can only fix certain issues and some can’t”. There is no “Person X made the change; so X must fix it too” (aka code ownership) There is no “I am just a user; you are the developers”. Of course, if you are a newcomer to the project and have just begun to understand the ins and outs of the CAS project codebase, there may certainly be areas in which you might find more comfort to slowly get your feet wet. You’re welcome to ask for suggestions. For the most part, the work item you wish to work on should be something you find interesting and enjoyable with some degree of practicality. Remember that you are deploying open source software, which means you have automatically become a project/community member and a potential maintainer, whether you realize it or not. Staying in consume-only mode generally leads to poor results. What can I work on? All contributions are extremely welcomed with open arms regardless of shape, size and color. You may be interested in helping with fixing typos, writing documentation, authoring test cases, developing code, squashing bugs, etc. All is welcome. More contributions simply equal more confidence. In other words, if you happen to come across a bothersome use case and/or something you consider a perfect candidate for improvement and attention, you are most definitely, aggressively and wholeheartedly encouraged to spend time and DNA to improve the quality of your Apereo CAS life. There is no point in silent suffering. If you find that contributing to the project is at the moment out of your reach, don’t worry. There are resources, here and here that can provide training and support to get you started for the win. Do I need an issue first? No. If you have already identified an enhancement or a bug, it is STRONGLY recommended that you simply submit a pull request to address the case. There is no need for special ceremony to create separate issues. The pull request IS the issue and it will be tracked and tagged as such. Remember that this is open source software in an open and collaborative community. It’s not “Some folks report issues and some folks fix problems” software. How do I report issues then? You are welcome to submit issues via the project’s issue tracker. Someone will review the report and will try to evaluate whether this is a genuine RFE or defect in which case the issue will be closed with a follow-up request for contributions and patches. The issue tracker is only a simple communication tool to assess a given problematic case or enhancement request. It’s not tracking anything, really. You are for the most part and at all costs encouraged to submit patches that fix the reported issue and remove pain, rather than waiting for someone to come along and fix it. As prescribed, there is no “we vs. you”. Very simply put: You are the one you have been waiting for. &times; Notepad WorksTry not to use the issue tracker as a backlog for items that need fixes from others. Any good task management software on your laptop will do instead. But, can’t I just use the software? The distinction between user and developer is, for the most part, an imaginary one in open source. You are not a user. You are not a developer. We all are contributors. If you have already diagnosed a problem or have found a use case for an attractive improvement and feature, we strongly recommend you simply walk down the path of making that all a reality and contribute back. If you find yourself unable to do so, you will need to find and procure resources that can teach you the how-to or do it for you. Reporting an issue and hoping/waiting for someone else to come along and provide a fix for you is never an acceptable strategy. I am only one; but still I am one. I cannot do everything; but still I can do something; and because I cannot do everything, I will not refuse to do the something that I can do. - Edward Everett Hale If you insist on being treated like a user, you then need to revisit and realign expectations with folks and resources that can provide you with the treatment you need. All of the work that goes into the development of a rich comprehensive software platform is almost exclusively done on a voluntary basis. Therefor, if you have expectations that resemble something of a commercial support agreement with clauses that include promises, guarantee, SLAs and follow-ups, you simply need to level up with an entity that actually provides that sort of functionality. How do I know who’s working on what? Follow the WIP Pattern and submit early pull requests. This is in fact the recommended strategy from Github: Pull Requests are a great way to start a conversation of a feature, so start one as soon as possible- even before you are finished with the code. Your team can comment on the feature as it evolves, instead of providing all their feedback at the very end. Or put another way: You’re opening pull requests when you start work, not when you’re finished. There is of course the alternative: ask. Can I backport a change to a maintenance branch? Yes, absolutely. Provided the change fits the scope of the maintenance branch and its tracking release and assuming the branch is still under care, you are more than welcome to move changes across the codebase various branches as much as needed to remove pain and improve. What if the change is too big? Start by reviewing the release policy. The change you have in mind should fit the scope of the release that is planned. If needed, please discuss the release schedule and policy with other community members to find alternative solutions and strategies for delivery. Is it worth it? The CAS project generally operates based on its own maintenance policy. Before making changes, you want to cross check the CAS deployment you have today and ensure it is still and to what extent considered viable and maintained by the project. How do I get on the roadmap? By simply delivering the change and having it get merged into the codebase relevant branches. There is no predefined roadmap for the project. The roadmap is what you intend to work on. Work items get completed based on community’s availability, interest, time and money. Practically, how soon is that exactly? You can review the release schedule from here. Note that the dates specified for each are somewhat tentative, and may be pushed around depending on need and severity. As for general contributions, patches in form of pull requests are generally merged as fast as possible provided they are in good health. This means a given pull request must pass a series of automated checks that examine style, tests and such before it becomes eligible for a merge. If your proposed pull request does not yet have the green marking, worry not. Keep pushing to the branch that contains your change to auto-update the pull request and make life green again. If you find that the project is not moving forward at a pace you find reasonable, simply ping the pull request and gently remind someone to step forward and review the issue with you. How do I do this? There is the contributor guide, for sure. However, in this section we are going to practically take a look at the entire process from start to finish and see the patch all the way through. In order to successfully finish this exercise you need: Git IntelliJ IDEA, eclipse or NetBeans (Depending on the change, vim may be perfectly fine too) Java (JDK) Fork the repository First thing you need to do is to fork the CAS repository under your own account. The CAS repository is hosted on Github and is available here. Clone repositories There are much faster ways of cloning the codebase, but let’s keep it simple for now: git clone git@github.com:apereo/cas.git cd cas git remote add mmoayyed git@github.com:mmoayyed/cas.git git checkout master Next, if you simply list the remotes you should see: origin git@github.com:apereo/cas.git (fetch) origin git@github.com:apereo/cas.git (push) mmoayyed git@github.com:mmoayyed/cas.git (fetch) mmoayyed git@github.com:mmoayyed/cas.git (push) You want to isolate your changes inside individual topics branches and never commit anything to the master branch. The workflow more or less is the following: Create topic branch. Make changes and test. Commit changes to branch. Go back to #2 until you are satisfied. &times; Functional BuildYou may want to ensure the codebase can be built locally from source. Follow this guide to learn more. Create branch To create a topic branch for the change, execute: git status git checkout -b my-topic-branch-which-fixes-something Commit changes When you’re ready to commit changes after having made changes, execute: git add --all &amp;&amp; git commit -am \"This change fixes a problem\" Note that the --all flag adds all modified files in the project directory. If you wish to pick and choose, you can either individually add files via a git add fileName command one at a time or perhaps, it might be best to simply opt for a GUI client such as SourceTree or Git Extensions. Push changes Push your changes from the local branch to a remote branch of your own fork: git push mmoayyed my-topic-branch-which-fixes-something Submit pull request Follow the guide here to create a pull request based on your branch to the CAS project. In this particular case, the target branch is the master branch because your own branch was created off of the master branch. How fast can I consume the change? SNAPSHOT releases are published by the automatic Travis CI process. As soon as a patch is merged, you want to track its build status and once it turns green, you should be good to update snapshots in your build script. Practically, this process can take up to 50 minutes or less. Refer to the README file of the build script and the project documentation to learn how you may update the overlay to take advantage of the change. This practically usually involves running the build with a -U or --refresh-dependencies command for Apache Maven and Gradle respectively. So… I hope this brief overview was of some assistance to you. If you happen to come across other ideas that would make all our CAS lives easier, by all means and without hesitation, please get involved. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/07/05/cas-contribution-guide/"
  },

  
  
  
  {
    "title": "CAS 5.2.0 RC1 Feature Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The official CAS 5.1.0 GA was released on May 27th 2017. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.2.0. This post intends to highlight some of the improvements and enhancements packed into the first release candidate in the 5.2.0 series. The in-development documentation of CAS 5.2.0 is available here. The release schedule is also available here. The release policy is available here. 0.1. Minors 0.2. Documentation 0.3. WebJARs for Static Resources 0.4. Trusted Authentication Attributes 0.5. Amazon Cloud Directory Authentication 0.6. CAS Protocol v2 Forward Compatibility 0.7. JWTs for REST API 0.8. Dynamic Caches for Ticket Registries 0.9. Update Checking 0.10. HEADER Response Method 0.11. ADFS Delegated Authentication 0.12. ADFS SAML Integration 0.13. Ticket Registry Encryption 0.14. Stormpath Support Removed 0.15. Ticket Validator SSL Configuration 0.16. Registered Services Endpoint 0.17. YubiKey MongoDb/JPA Storage 0.18. Couchbase Authentication 0.19. Apache Cassandra Authentication 0.20. Custom LDAP Password Policy 0.21. FIDO U2F Device Registration 0.22. JWTs As Service Tickets 0.23. Swivel Secure Authentication 0.24. OpenID Connect Introspection 0.25. OAuth Client Credentials Grant 0.26. Attribute Repository Merging 0.27. Library Upgrades 0.28. What’s Next? 0.29. Get Involved 0.30. Das Ende 0.1. Minors Performance improvements to ensure service selection strategies are properly sorted at runtime. A few bug fixes that affect the password management functionality and webflow handling of authentication failure events, thanks to @pdrados. Small regression in how URL-based SAML2 metadata resources are retrieved from http vs https resources. Thanks to @pavelhoral, ticket registries properly take into account the task of encoding tickets, if needed, before deleting them. Thanks to @jkacer, failed authentication attempts are improved to no longer be reported as throttled authentication attempts. Changes are backported as far as back as 5.0.x. Plenty of minor performance improvements to the CAS service registry as well as the overall ticket registry components and that of Hazelcast in particular, thanks to @DavidRG13 and @tsschmidt. Delegated authentication flows now gain support for naming the client, thanks to @rrenomeron. The Duo WebSDK has been upgraded to its most recent version. 0.2. Documentation Thanks to @mindblender, the documentation site for the CAS project is now equipped with a much better search user interface. 0.3. WebJARs for Static Resources Targeting CAS deployments in environments that have no network access can be tricky. In this release candidate, CAS begins to beautifully bundle static UI resources (css, javascript, etc) into the build for offline access. These resources are turned into dependencies that the project stuffs into the build by default using WebJARs. The org.webjars project seems to package up most things that CAS needs in jars that are available in maven central and the servlet 3.0 specification makes the resources available to be served up by CAS. Huge thanks to @hdeadman for executing on this. 0.4. Trusted Authentication Attributes The Trusted Authentication features of CAS are now able to extract attributes from the remote request object, in cases where CAS is sitting behind a Shibboleth Service Provider, etc. Thanks to @scalding for the find and suggestions on how to improve this best. 0.5. Amazon Cloud Directory Authentication Thanks to @vulpayga, CAS gains the ability to use Amazon Cloud Directory for authentication. 0.6. CAS Protocol v2 Forward Compatibility It is now possible to ensure CAS protocol v2 views are forward compatible with CAS v3. The most significant change here is the ability to release attributes via v2. The behavior is controlled via a setting that can be turned on/off globally for the CAS deployment. You can read more about this behavior here. 0.7. JWTs for REST API The CAS REST API/Protocol is now equipped with the capability to issue JWTs for service tickets. 0.8. Dynamic Caches for Ticket Registries The Ehcache Ticket Registry now gains the option to split caches dynamically based on ticket types, rather than keeping every ticket inside a single statically created cache. The same changeset is also applied to the ticket registry based on MongoDb as well as that of Apache Ignite. 0.9. Update Checking CAS has been given the ability to check for newer released versions and report back as part of its banner. This behavior is off by default, and may be conditionally enabled via the following guide. 0.10. HEADER Response Method CAS has for some time had the ability to redirect back to a requesting application providing the generated service ticket in form of a GET or POST via the method parameter. In this release, CAS adds an extra HEADER option, stuffing the ticket into a response header. This might be useful if you intend to execute non-interactive modes of authentication such as Basic Authentication. 0.11. ADFS Delegated Authentication Delagating authentication to ADFS is now enhanced to support more than once ADFS instance. 0.12. ADFS SAML Integration A number of minor bugs have been fixed in this release to ensure ADFS acting as a SAML2 SP can be integrated with CAS acting as a SAML2 identity provider. 0.13. Ticket Registry Encryption The ticket registry implementations based on Apache Ignite and MongoDb are now enhanced to support ticket registry encryption. 0.14. Stormpath Support Removed Stormpath support has been removed from the codebase. This feature will no longer be available, as Stormpath APIs are soon to be retired in mid August after the Okta acquisition. 0.15. Ticket Validator SSL Configuration There are areas in CAS where a ticket is issued and validated internally to allow access to other downstream components. The configuration of ticket validation component is now exposed to the entire runtime and takes advantage of familiar CAS settings when it comes to SSL factories and hostname verifications. 0.16. Registered Services Endpoint A new endpoint is now exposed in CAS that can report back the collection of registered services with CAS. 0.17. YubiKey MongoDb/JPA Storage YubiKey multifactor authentication is now able to use MongoDb or a relational database for persisting device registration records. Improvements are in to also support new device registration workflows. 0.18. Couchbase Authentication CAS gains the ability to use Couchbase as an authentication store. Remember that Couchbase can also be used to manage CAS services and act as a ticket store for HA deployments. 0.19. Apache Cassandra Authentication Thanks to @vulpayga, CAS gains the ability to use Apache Cassandra as an authentication store. 0.20. Custom LDAP Password Policy There is now support for implementing your own custom LDAP password policy handler based on Ldaptive. Your implementation needs to be taught to CAS and should take on the following form: import org.ldaptive.auth.AuthenticationResponseHandler; public class MyPasswordPolicyAuthenticationResponseHandler implements AuthenticationResponseHandler { } 0.21. FIDO U2F Device Registration FIDO U2F support for multifactor authentication is now equipped with the ability to store device registration records inside a relational database and more. See this for more info. 0.22. JWTs As Service Tickets &times; BewareThis may be a breaking configuration change. Consult the docs to learn more. The ability to issue JWTs as service tickets is now refactored and moved into its own dedicated module such that it can then become reusable as a pluggable extension point in other parts of the codebase. If you had this feature turned on, you may need to adjust the module definition in your build slightly to stay on course with the coolness. 0.23. Swivel Secure Authentication CAS can now take advantage of Swivel Secure’s image-based multifactor authentication. See this guide to learn more. Special thanks to @dacurry-tns for contributing the baseline integration. 0.24. OpenID Connect Introspection Modest support is now added for OpenID Connect to allow for introspection of access tokens. 0.25. OAuth Client Credentials Grant Support for OAuth2’s client_credentials grant is now included in this release. 0.26. Attribute Repository Merging Attributes retrieved during the authentication phase are now given the ability to merge with attributes retrieved from separate attribute repository sources. This behavior previously was only available to select authentication strategies and is now globally applied to all. 0.27. Library Upgrades Spring Data Spring MongoDb Spring Cloud Spring Security EhCache Apache CXF Thymeleaf Sentry Memcached Apache Ignite Gradle Spring Boot Couchbase Infinispan UnboundID SCIM 0.28. What’s Next? We are all working to make sure the CAS 5.2.0 release is on schedule. 0.29. Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Suggest and apply documentation improvements. 0.30. Das Ende A big hearty thanks to all who participated in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2017/06/30/520rc1-release/"
  },

  
  
  
  {
    "title": "CAS 5 - Maintaining Protocol Compatibility",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. The third specification of the CAS protocol was released around the time CAS v4.0.0 came into existence. The primary objective of the revision was to bring the spec up to speed with common community practices and extensions, one of which most significantly was the ability to let CAS release attributes to authorized relying parties and applications. In order to preserve protocol backward-compatibility, a new /p3/serviceVaildate endpoint was added whose only job was to release attributes to be consumed by clients. This way, existing CAS clients unable to parse the new &lt;cas:attributes&gt; block in the validation response could continue to function as they did. Newer clients could simply hit the new endpoint to receive attributes. Problem Statement There are cases where a certain number of today’s CAS clients are perfectly able to consume attributes from CAS protocol v2. How? Because support for attributes was an accepted mod made by most deployers and client developers. A deployer running some version of CAS 3.x for instance had already applied the change to CAS for attribute release and had built clients or instructed vendors to build clients such that they all could consume attributes and enjoy coolness. How’s that situation convered in the most recent CAS 5 release line? Solution The trick is to ensure that the component responsible for validating tickets and producing the final payload is using the correct versions of the view/response which match that of CAS protocol v3. The most bullet-proof way of applying this change is with CAS 5’s auto-configuration strategy described below. CAS 5.0.x Design your own @Configuration class and have it simply match the following body. This component will be placed inside the CAS overlay under /src/main/java/org/apereo/cas/config and it must be housed inside the Java package org.apereo.cas. You may need to create the directory structure and you may also need to ensure relevant dependencies are under the compile scope so the configuration below can properly compile. As you can see below, all we are doing is swapping out one set of views with another. package org.apereo.cas.config; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.View; import org.apereo.cas.web.ServiceValidateController; import javax.annotation.PostConstruct; /** * This is {@link CustomConfiguration} that replaces the CAS Protocol 2 validation endpoint (/serviceValidate) * with the CAS Protocol 3 (essentially applying the attribute modification to CAS protocol 2.. * * @author John Gasper * @since 5.0.x */ @Configuration(\"CustomConfiguration\") public class CustomConfiguration { private static final Logger LOGGER = LoggerFactory.getLogger(CustomConfiguration.class); @Autowired @Qualifier(\"serviceValidateController\") ServiceValidateController serviceValidateController; @Autowired @Qualifier(\"cas3ServiceSuccessView\") View cas3ServiceSuccessView; @Autowired @Qualifier(\"cas3ServiceFailureView\") View cas3ServiceFailureView; @PostConstruct protected void initializeRootApplicationContext() { serviceValidateController.setSuccessView(cas3ServiceSuccessView); serviceValidateController.setFailureView(cas3ServiceFailureView); } } CAS 5.1.x Same exact strategy as 5.0.x, except that now you’re given the freedom to put the Java component anywhere inside any package in the overlay project, provided it’s correctly registered with the CAS auto configuration engine. CAS 5.2.x, 5.3.x All that is still way too much work, right? So starting with CAS 5.2.x all one should have to do is to introduce the following setting in the cas.properties: cas.view.cas2.v3ForwardCompatible=true That’s it. So… Special thanks to @jtgasper3 for sharing this neat trick and letting me brag about it. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/06/23/cas-protocol-compatibility/"
  },

  
  
  
  {
    "title": "MyUW in 2016 - by the numbers",
    "text": "This post considers MyUW in 2016 as framed by metrics. Unless otherwise stated, all numbers are about calendar 2016. Point in time numbers are about December 31, 2016. (See also minimalist slide deck. One use for this post is as notes to support presenting or consuming that deck.) MyUW as production service 10 million sessions Per Google Analytics, MyUW served around ten million user sessions. MyUW serves a lot of traffic. 8 million outbound links Users followed a link in MyUW out to something outside MyUW more than 8,000,000 times, including four million launches of Office365 and two million launches of the course dashboard. MyUW eases navigation to other systems. 100,000 notifications displays Users viewed their full notification page around 100,000 times. Besides helping users navigate to other applications, MyUW helps users understand what they need to do and where they might need to navigate. 100,000 searches and app directory browses MyUW presented the directory of applications around 100,000 times and provided search results in around 100,000 user sessions. Not all MyUW content relevant to all users can fit on default home pages, so MyUW supports users searching and browsing the available content. 100,000 home page modifications Once you’ve searched or browsed to something interesting, you can add it to your home page. Users modified their home pages almost 100,000 times, including adding the new Wiscard Balance widget almost 6,000 times. Releases every 7 days MyUW releases to production every 7 days, in our 5am to 7am Tuesday morning release window. We rarely incur downtime even during this service window. We aspire to release more often, with better automation and evolving local culture to support and sustain this. Still, we’re already releasing relatively frequently. Releasing frequently allows us to ship less change more often to get feedback sooner and to incur less release risk. We occasionally add additional release windows to ship urgent change. Our blue-green deployment practices allow us to do so without incurring service downtime – mostly no one notices. 5 tiers We have 5 tiers: predev: Infrastructure and framework development. Content is relatively stable. test: Content development. Infrastructure is relatively stable. qa: Stable, tagged, versioned releases of all components. The purpose of this tier is to demonstrate specific, promotable versions working correctly together. stage : Production in all ways except it runs the latest production build (the build “staged” for release) and no my.wisc.edu traffic is routed to it. Exactly the Docker image that’s running in stage is promoted to prod in the release process. prod : Production. Runs a specific, deliberately-released version of the whole bundle. Typically a bundle precisely as it was validated in stage. Five tiers mean more opportunity for various development efforts to not step on one another’s toes, more opportunity for quality assurance and testing, and more opportunity to co-opt an environment to test e.g. a major upgrade of an external dependency. Five tiers also helps make breaking changes and complicated upgrade paths painful enough that we look for ways to avoid breaking change, to simplify upgrade paths, and to change gracefully. Components coping better with more versions of dependencies yields a more stable solution, gives us better options in the rare case where we do need to drop back to an older version of a module, and yields more adoptable and supportable software products. 4 production VMs We have 4 production VMs running 8 virtual MyUW nodes of which 4 are typically in service at any time. This provides sufficient capacity to handle peak load, allows one or typically even two nodes to fail without significant adverse effect to service experience, and allows blue-green deployments with zero service downtime. 160 apps We had ~160 “real” items in the app directory, including ~50 apps for Madison students or applicants ~25 administrative tools (both portal administration and some business function administration) ~20 apps for Madison staff ~20 apps for Madison constituents in general ~5 apps supporting advising ~5 apps supporting research We update this content frequently, with 261 changes to app directory content in 2016. ( git log --since=2016-01-01 --before=2017-01-01 --oneline | wc -l ). MyUW as complex system MyuW has ~50 items eligible to appear by default on the user’s home screen. (No real user sees 50 items by default. Group matching pares this down to items that may be relevant.) There are ~90 groups available for targeting in MyUW, including 13 managed in Manifest, UW-Madison’s Grouper instance. MyUW as growing and evolving 5 new notifications in 2016. Lots of potential in this feature, as yet un-realized. MyUW as designed MyUW implements responsive design, flexing across browser window sizes. This improves the experience across the breadth of devices using MyUW, including the 20% tablet or mobile phone form-factor traffic. MyUW budgets for 0.75 FTE UX design from DoIT Communications. ~40 apps had interesting widgets, namely Badger Headlines and NCAA D1 News Benefit Information x2 Campus News Course Guide and its help Course Services DoIT planned and unplanned outages Email Google Apps Help desk notices HR, Payroll, and Benefit News x2 Learning and Talent Development Local Contact Info Manager Time Approval My Courses Payroll Information x2 Research Project Resource Guide Scholarships@UW-Madison UW-Extension CEOEL x11 UWP news, UWRF news UWRF resources Weather x2 Wiscard Balance Working at UW MyUW as teams Infrastructure team 5 dedicated staff 3 full stack developers 1 front end developer via ADI 1 strategist and a wider cast, including .75 User Experience consultant partial Site Reliability Engineer 0.25 Tier ~2 Help Desk and a wider cast Dedicated, focused, invested staff in for the long term is key to MyUW success, to being a team, to delivering our quality, confident service. 0.25 FTE focused on escalated support cases, documenting known issues, digesting support into actionable product intelligence: working great, key to MyUW’s success. Development teams 4 teams active developing MyUW frame-based apps MyUW Infrastructure MyUW Academic Applications ADI - Integrated Applications UW-Extension - Continuing Education, Outreach &amp; E-Learning Service team Infrastructure Scrum team, plus Service team lead Cybersecurity liaison MyUW Academic Applications liaison ADI - Integration Applications liaison DoIT Communications liaison UX Help Desk Site reliability engineer MyUW as serving the entire UW System 16 themes System-targeted 25 app directory entries ~15 apps for System staff ~10 apps for UW Extension CEOEL students MyUW and open source Return on investment The World Bank found a 200% return-on-investment in participating in open source. This is our strategy: build and collaborate on open source products in the hope of a positive return on this investment via collaboration, shared maintenance, and benefiting from the work of others. We develop more thoughtfully and more sustainably when we approach our work as building open source software products that are configured and adopted locally. 50 releases of 7 products MyUW posted 50 releases of 7 MyUW-led open source products in 2016. 1 Apereo board member MyUW team member Jim Helwig has long served on the Apereo Board of Directors. Taking a hand in the governance of Apereo is part of how we contribute to its sustainability and thus to the sustainability of the context in which we can realize a return on our open source investment. 2 uPortal steering committee members MyUW team members Jim Helwig and Andrew Petro serve on the Apereo uPortal steering committee. Taking a hand in the governance of uPortal is part of how MyUW contributes to its sustainability and thus to the sustainability of a context in which we can realize a return on our open source investment. 425 commits by others There were 425 commits in 2016 to Jasig/uPortal not by University of Wisconsin employees. In summary MyUW is a high-usage production service a complex system growing and with not-yet-fully-realized potential designed a team serving the entire University of Wisconsin system practicing open source Andrew Petro",
    "tags": "uPortal",
    "url": "/2017/06/20/myuw-2016-numbers/"
  },

  
  
  
  {
    "title": "CAS Codebase Overview",
    "text": "Over the past couple of weeks, I have received a lot of positive feedback on CAS codebase organization and management. This blog post attempts to provide an overview of the current codebase status and offers to explain the supporting rationale and the decisions made to cleanup, break down and decompose the monolithic structure of the CAS project whose latest release as of today is available here. The 1000-Foot View If you were to clone the CAS project on Github and count the provided subprojects, as of this writing you might see something like the following snippet: &gt; cd cas-server &gt; gradlew projects | wc -l 221 That’s a lot of projects! How is this managed and who can make sense of this beast? At a very high-level, the project is broken into the following categories: Module Description api CAS APIs that generically define the outline of a given behavior, such as authentication. core Implementations of said APIs. The presence of almost everything under this category is absolutely required for the CAS runtime to function correctly. docker Build configuration for automatic builds invoked by Docker Cloud. docs Project documentation artifacts managed by Github Pages. etc Miscellaneous configuration files used by the build or the documentation site. gradle Houses the gradle wrapper used for internal builds. style Guidelines and rules enforced and consumed by project’s various static analysis checkers, such as Checkstyle and Findbugs. support Extensions that enrich one’s CAS experience with lots and lots of functionality and integrations. (i.e. LDAP, MFA, etc) travis Configuration artifacts used by Travis CI. webapp-mgmt Artifacts that pertain to the configuration and deployment of the CAS Service Management Web Application. webapp Artifacts that pertain to the deployment of the core CAS web application and its many sisters. As you drill into each category, you are presented with a hierarchy and a naming scheme that intends to explain what each project folder is all about. Note that the above organization is not only rather pleasing to the eye, but it also tries to reduce the initial scare factor to some degree. All visitors, friend and foe alike, who happen to step into the project space on Github are not immediately greeted with a structure that demonstrates 221+ things, forcing them to endlessly scroll downward to finally get to the actual README.md file. So, this model is a representation of the project’s organization and essential components, gently and without risk to gradually boil the proverbial frog and get one acclimated for contributions. After all, that is what we want we to do. No Feature Left Behind Core CAS components aside, there are a lot of other individual modules (i.e. JAR artifacts) which act as support modules or more accurately put, intentions. What is that about? In order to ease the maintenance burden of both code and documentation and to create a sustainable development environment for the project to grow and keep up with the times and additions of new [more complicated] features (i.e. multifactor authentication), CAS 5 took an orthogonal approach where most if not all CAS features are automatically configured by CAS itself, given deployer’s consent, relieving the deployer from having to deal with manual configuration. This is a model referred to as Intention-driven configuration. Each support module essentially focuses on a single feature or intention or a particular variation of one. It latches onto the runtime and does what it should, inserting itself in all the right places dynamically in order to provide the intended functionality in an automated way. It’s nice that one can fiddle with a variety of configuration files to make something work. It’s a whole lot better though ambitious to automate once, run everywhere. Modules are super cheap and modest. Sometimes they only provide the necessary dependencies to provide functionality. Sometimes they provide a specific implementation for an existing feature, such as the ability to store device registrations into a relational database during multifactor authentication flows. Sometimes they actually provide essential functionality, such as multifactor authentication support via Google Authenticator. Whatever it may be, the question ultimately for the deployer is: I intend to do X with the software and there is a module that lets me. You want the feature? Drop the module in and it does stuff. You don’t want the feature? Remove the module and it will stop doing that. Is it perfect? Surely not, but it should be THAT simple. Not OSGiThe project structure might seemingly have you suppose that this all somehow stemmed from or was inspired by OSGi principals. While that claim is not entirely false, you should know that CAS today does [and has] nothing to do with OSGi. Delete: Such Joy One of the more important advantages of such decomposition is that it allows one to write code that is very easy, nay, a joy to delete. If the configuration and logic of a given behavior are all housed inside a subproject, you should be able to press delete at any given time without causing mass chaos in other parts of the codebase. This is the concept of encapsulation and self-containment. With proper design and organization, removing cruft should be as easy as striking the appropriate key on the keyboard. Challenges Of course, not everything is peachy all the time. There are a number of concerns that one needs to take into account. Summarily, here are a few: Circular Dependencies As the codebase is broken apart, it will slowly become apparent that certain modules require a dependency on other modules. If not done carefully, these relationships very quickly turn into an unending cat-and-mouse game. Tread lightly. When Enough Is Enough In certain literatures, it is argued that managing one big thing is much easier, conceptually, than managing 100 small things. That’s not entirely false. It, decomposition, requires not only skill and command but also capacity, availability and self-control. All good things are usually done in moderation; so do not overdo. The boundaries of where one module stops and another begins should be designed and apparent at reasonable granular levels and no more, where you decide what reasonable and granular mean. Talk Is Cheap; Show Me The Code Don’t suggest code improvements. Code your suggested improvements. Remember that nothing is perfect; Improve and iterate as often as possible. There will always be better ways. There will always be better ideas. Jot them down and encourage friend and foe to starting executing on such ideas rather than merely suggesting them. So… I hope this brief overview was of some assistance to you. If you happen to come across other ideas and innovative solutions that would make all our CAS lives easier, by all means and without hesitation, please get involved. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/06/12/cas-codebase-overview/"
  },

  
  
  
  {
    "title": "CAS 5 Load Tests by Lafayette College",
    "text": "Contributed ContentCarl Waldbieser (&lt;waldbiec [at] lafayette.edu&gt;), an active member of the CAS community, was kind enough to share this analysis. Overview Deployment Architecture The Test Swarm The Trials Trial 1 Trial 2 Trial 3 Trial 4 Trial 5 Trial 6 Conclusions Overview Load testing trials were conducted on the CAS stage environment in order to provide insight into what kind of sustained load the production CAS service will be able to carry. All trials were carried out against the same deployment architecture, with all nodes configured identically. Deployment Architecture The deployment architecture itself consists of 3 virtual machine nodes. Each node has 3.7 GiB real memory available to it and 2 CPUs. The characteristics of the CPUs are as follows: Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 2 On-line CPU(s) list: 0,1 Thread(s) per core: 1 Core(s) per socket: 2 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 42 Model name: Intel Xeon E312xx (Sandy Bridge) Stepping: 1 CPU MHz: 1899.999 BogoMIPS: 3799.99 Hypervisor vendor: KVM Virtualization type: full L1d cache: 32K L1i cache: 32K L2 cache: 4096K NUMA node0 CPU(s): 0,1 The nodes are deployed behind an Nginx+ proxy in an active-active-active configuration. The nodes share ticket information using encrypted Hazelcast messages, a feature built into the CAS software, so any application state is shared. The Test Swarm The testing framework used was locust.io, a Python based load testing framework. The test suite deploys a fixed number of “locusts” against a web site. To lean more about locust, please see this guide. The initial population ramps up with a configurable “hatch rate”. In the tests, locusts were conceptually divided into 3 “lifetime” categories: Short-lived locusts live approximately 60 seconds. Medium-lived locusts last for approximately 5 minutes. Long-lived locusts exist for approximately 2 hours. The category to which a given locust is assigned is randomly determined with a ratio of short : medium : long being 7:2:1. Ideally, 70% of the population is short-lived, 20% is medium lived, and 10% is long-lived. The lifetime of a locust determines how long it will retain and make use of a single web SSO session. Short-lived locusts discard their sessions quickly. Long-lived locusts hold on to them for considerable time. All locusts are only 25% likely to log out upon their deaths. The CAS service must continue to track TGTs of locusts that have not logged out until the ticket expires, so this behavior can put pressure on the memory storage resources of the nodes. Each locust uses credentials taken randomly from one of 9 test accounts. Each locust has a 1% chance of entering an erroneous password for an account. Locusts that fail to authenticate will die immediately. When a locust dies, it is reborn immediately. Its lifetime category remains the same, but its SSO session and all other random parameters are reset. The Trials Trial 1 # of Locusts Hatch Rate 300 10/s The first trial produced authentication events at a rate of over 3,500 event/minute. The majority of these were service ticket creation and validation events. By 13:40 (~5 hours into the trial), degraded performance became noticeable. By 15:50 (~7 hours in), the nodes were swamped. The trial was discontinued shortly thereafter. Trial 2 # of Locusts Hatch Rate 300 10/s The 2nd trial was similar to the first, but the number of locusts was briefly increased to 500 for a 3 minute duration. The characteristics of trial 2 are very similar to those of trial 1. After responding to ~3,500 / minute for close to 6 hours, the nodes were overwhelmed. Trial 3 # of Locusts Hatch Rate 150 10/s The 3rd trial used half the number of locusts used in the first 2 trials. The sustained event rate was ~1,700 authentication events per minute. Unlike the previous 2 trials, this trial was concluded prior to the nodes becoming overwhelmed. It is unknown whether the nodes could continue to sustain responding to events at this rate indefinitely. Trial 4 # of Locusts Hatch Rate 50 10/s The 4th trial showed the nodes were capable of sustaining a ~600 authentication events/minute rate for a full 24 hours. Because the maximum lifetime of a TGT is 8 hours, there is some reason to believe this rate could have been sustained indefinitely. Trial 5 # of Locusts Hatch Rate 25 10/s This trial was useful in establishing the mean rate of 291 events per minute given a swarm of 25 locusts. This test and test 6 are notably shorter in duration than the other tests, as it is assumed at this point the nodes can sustain the loads indefinitely. Trial 6 # of Locusts Hatch Rate 10 10/s The mean rate of authentication events for this trial is 118 events per minute. Conclusions Measurements taken from the production CAS service from April 17-21, 2017 during normal business hours (9am to 5pm) have the following characteristics: Mean Median Mode Max Min Std Dev 149 events/minute 139 events/minute 126 events/minute 494 events/minute 2 events/minute 68 While there appears to be some “burstiness” in the rate of authentication events, all 3 types of averages are well below the the expected threshold which the trials suggest are indefinitely sustainable. Even the maximum rate of 494 events per minute is well below the sustained rate of trial 4 (~ 600 events / minute). The data suggests that the production CAS service is operating well under the maximum sustainable load, and should have plenty of capacity to spare for temporary spikes in utilization.",
    "tags": "CAS",
    "url": "/2017/06/09/cas5-perfresults-LafayetteCollege/"
  },

  
  
  
  {
    "title": "Shibbolizing Apereo CAS",
    "text": "This is a brief overview that explains how to shibbolize the Apereo CAS server; that is to let the CAS server be protected by an instance of the Shibboleth Service Provider, where the SP is then tasked to delegate authentication requests to a remote SAML2 identity provider. The entire SAML2 interaction is kept between the SP and the IdP while CAS on the return trip eventually picks up the user profile from the SP in form of special headers, etc. But…Why? This is a very elaborate setup, yes. The goal originally was to let CAS simply and directly delegate authentication requests to the SAML2 identity provider. This can very easily be done, except that in this particular case the SAML2 identity provider only supported a very specific and rather complicated variation of the SAML2 protocol, whose support is absent in CAS today. Convincing the identity provider to provide support for the more-mainstream SAML2 WebSSO Browser Profile led to a path riddled with uncertainties. After further analysis, we came to the conclusion that implementing built-in support for the IdP-supported SAML2 profile variation in CAS is unnecessarily complicated, needlessly expensive and possibly soon-to-be obsolete. Of course, it is certainly possible to do. If you have to ask: all you need is love, coffee and access to decent hair conditioning products. So the path to least resistance turned out to be a deployment with a few additional components and with a clear separation of boundaries. Thanks to Docker and outstanding help from colleagues, we managed to get this working. Read on. How Starting out with a proof of concept, we came up with a dockerized deployment as such: CAS Server 5.1.0-SNAPSHOT, running inside an embedded Apache Tomcat Shibboleth Service Provider for Apache Apache Web Server A sample CASified PHP application Shibboleth Identity Provider 3.4.x running inside Jetty Shy of a pretty sequence diagram, here’s how the interaction between the above components works: Client browser attempts to access the sample CASified PHP application. Requests to the CAS /login endpoint are intercepted by the SP and Apache. The SP, configured to speak the special SAML2 protocol, routes the request to the IdP. The IdP accepts user credentials and posts back the response to the SP. The SP passes the response back to the CAS /login endpoint. CAS is configured to trust the response and proceeds to extract user profile data from the request. CAS proceeds to issue an ST for the PHP application that initiated the request. Having received and validated the ST, user is granted entry to the PHP application. CAS We also applied a few minor patches to CAS: Ensure CAS could easily lend itself to be intercepted by Apache when running in embedded mode. Ensure user profile data can correctly be recognized from the SP. Ensure attributes collected from the SP can be merged and combined with CAS’ own, in cases where supplementary attribute sources are directly defined inside CAS. The trusted authentication piece is already handled by CAS today. How Do I…? All patches are contributed back to the CAS project. You are most welcome! :-) So… Special thanks to @jtgasper3 for beautifully cementing the deployment foundation of each component via Docker, big kudos to @scalding for making the integration magic work seamlessly and to @apetro for having previously worked on the trusted authentication piece in CAS. Of course, I intend to take all the credit. Misagh Moayyed",
    "tags": "CAS SAML",
    "url": "/2017/05/26/cas-shibsp-samlidp/"
  },

  
  
  
  {
    "title": "Easier CLA submission",
    "text": "Now it is easier to submit a contributor licensing agreement (CLA) to Apereo, with online forms, one for each type of agreement, linked from the licensing page. Contributor agreements allow Apereo to sublicense your contributions to others under flexible terms, including under the open source licenses adopted by the Apereo projects. The Apereo Foundation collects and maintains licensing agreements and grant assignments at the institutional and individual level and publishes the results publicly. With thanks especially to John Lewis and Neal Caidin for the JotForm implementation of these online forms. -Andrew Petro",
    "tags": "Apereo Licensing",
    "url": "/2017/05/05/jotform-clas/"
  },

  
  
  
  {
    "title": "CAS 5.0.x Integration w/ Apache ZooKeeper",
    "text": "Contributed ContentGiovanni Morelli (Email: giannimorell at gmail.com, Github: @GiovanniMorelli) was kind enough to share this guide. I have created a cas-server-core-configuration-cloud-zookeeper module for CAS 5.0.4 based on cas-server-core-configuration-cloud-mongo When CAS is started, it reads all properties under zookeeper’s path: /cas/config/cas without the need to configure cas.properties. The project source code is available here. Configuration Add parameter cas.spring.cloud.zookeeper.uri=localhost:2181 in bootstrap.properties Add configurations on Zookeeper. Example: cas.server.name: https://localhost:9327 Start CAS. Build Download the codebase for CAS 5.0.4 first and add the project source code into the core directory. Make the following changes: settings.gradle (Root project) Add include \"core:cas-server-core-configuration-cloud-zookeeper\" gradle.properties (Root project) Update version zookeeper : zookeeperVersion=3.4.10 Add springCloudZookeeperVersion=1.0.4.RELEASE build.gradle (into project cas-server-core-configuration-cloud-zookeeper) description = \"Apereo CAS Core Configuration - Zookeeper\" dependencies { compile libraries.springboot compile libraries.spring compile libraries.springcloud compile libraries.zookeeper } Classes used in the ZooKeeper project: /cas-server-core-configuration-cloud-zookeeper/src/main/java/org/apereo/cas/ZookeeperPropertySource.java /cas-server-core-configuration-cloud-zookeeper/src/main/java/org/apereo/cas/ZookeeperPropertySourceLocator.java /cas-server-core-configuration-cloud-zookeeper/src/main/java/org/apereo/cas/config/ZookeeperCloudConfigBootstrapConfiguration.java Build the codebase with gradlew clean build --parallel -x test -x javadoc -x check. Overlay Add this configuration in pom.xml: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-configuration-cloud-zookeeper&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; TODO When you add a new configuration to Zookeeper, reload the configuration property automatically in CAS.",
    "tags": "CAS",
    "url": "/2017/04/30/cas50-zookeepercfg/"
  },

  
  
  
  {
    "title": "CAS 5.1.0 RC4 Feature Release",
    "text": "The official CAS 5.0.0 GA was released on November 7th 2016. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.1.0. This post intends to highlight some of the improvements and enhancements packed into the fourth release candidate in the 5.1.0 series. The in-development documentation of CAS 5.1.0 is available here. The release schedule is also available here. The release policy is available here. If you are looking for additional info on the previous release candidate, please see this post. SAML2 Service Providers CAS Demos Surrogate Authentication SAML2 NameID Qualifiers Scripted Attribute Release Distributed Tracing Encrypted Service Usernames Automated Docker Cloud Builds Eureka Service Discovery Spring Cloud w/ Apache ZooKeeper Logging Enhancements Spring Boot Administration Server Multifactor EntityID Trigger Principal ID As Attribute Groovy Attribute Value Filters Documentation Minor Changes Community Contributions Others Library Upgrades What’s Next? Get Involved Das Ende SAML2 Service Providers A few more SAML2 service providers are added to this release namely Adobe Cloud, AcademicWorks, Infinite Campus, Slack, Gartner, Zendesk and more. CAS Demos CAS demos are neatly organized and deployed on Heroku. Surrogate Authentiction The ability to authenticate on behalf of another user, so called Surrogate Authentication, is now included in this release. SAML2 NameID Qualifiers SAML2 service definitions are now allowed the option to override the name qualifiers for a given subject’s name id. Scripted Attribute Release Scripted attribute release policies are now able to accept an inlined groovy script as well. Distributed Tracing CAS embraces Spring Cloud Sleuth which implements a distributed tracing solution for Spring Cloud. Encrypted Service Usernames CAS username providers are now able to encrypt the resolved username using the service public key. Applications are expected to decrypt of course using their paired private key. Automated Docker Cloud Builds CAS is now taking advantage of Docker Cloud’s automated builds to auto-publish CAS images for the latest and all other relevant tagged releases. Eureka Service Discovery Thanks to Spring Cloud, CAS provides integration support for Eureka Service Discovery. Spring Cloud w/ Apache ZooKeeper More of a documentation enhancement and thanks to community contributions and expertise, the CAS Spring Cloud configuration server is now able to use Apache ZooKeeper as the backend storage service to house CAS settings. Logging Enhancements Another documentation improvement, the CAS logging guide introduces a few new sections to explain logging layouts. There is also some verbiage that describes how to integrate CAS logs with Papertrail. Spring Boot Administration Server Starting with this release, the actuator endpoints provided by Spring Boot can be managed remotely via the Spring Boot Admin server dashboard. Multifactor EntityID Trigger In cases where authentication is delegated to CAS most commonly from a Shibboleth Identity Provider, the entityId is passed to CAS as an extra request parameter to indicate the service provider. In this release, CAS begins to recognize the entityId parameter and treat it as a normal service that is linked to the CAS service registry which can then be assigned different access strategy and multifactor authentication policies. Principal ID As Attribute A small enhancement to CAS attribute release policies where now, the principal id itself can be released as a custom attribute of your own choosing on a per-service basis. Groovy Attribute Value Filters Attribute values for release policies can now take advantage of Groovy scripts to weed through the released collection dynamically. Documentation Additional docs are now available to explain: How to extend the CAS configuration How to extend the CAS webflow How to design custom triggers for multifactor authentication How to design custom authentication strategies Additionally, common CAS configuration settings that apply to more than one module are given their own dedicated space. Minor Changes A number of small bug fixes and improvements have been incorporated into this feature release: Community Contributions Acceptable Usage Policy is now able to correctly accept and store user decisions. Hazelcast ticket registry is now able to properly decode and find encrypted tickets. Minor updates to CAS messages bundles for non-english languages. Support for configuration of container-managed JDBC connections is added to this release candidate. Minor fixes to how OAuth/OpenID Connect tickets are deserialized and stored in JSON-based ticket registries. Google Apps integration correctly should handle the inResponseTo attribute. X509 authentication should correctly route the user back to the login form in cases of authentication failures. Google authenticator backed by JDBC should properly create and name databasse tables. Minor fixes to OpenID module to ensure views can proper render for ticket validation and other requests. Minor fixes to OpenID Connect module to ensure scopes can properly be filtered, and that clients are fully loaded and management via the services management web application. Others MDC logging is now respecting nullable properties of the HTTP request. Authy as a multifactor authentication provider gains the ability to specify the country code for the user phone number. MFA flows are now able to correctly handle scenarios where authentication produces warnings. OAuth2 password grant type is now correctly able to issue user profiles. Ticket registry cleaner is no longer scheduled as a no-op if it’s disabled in the configuration. A regression; CAS should resume supporting the duration syntax (i.e PT20S) for settings. Documentation additions to explain how to generate various signing and encryption keys for CAS manually. Library Upgrades Apache Tomcat Spring Cloud Hazelcast Thymeleaf Log4j Spring Hibernate HSQLDB AWS SDK Spring Boot What’s Next? The development team is working to make sure the CAS 5.1.0 release is on schedule. This is the last release candidate in the 5.1.x release and the project will gear up to perform a few more rounds of testing and validation before the official GA release is tagged and made available. Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Review and suggest documentation improvements. Review the release schedule and make sure you report your desired feature requests on the project’s issue tracker. Das Ende A big hearty thanks to all who participated in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2017/04/28/rc4-release/"
  },

  
  
  
  {
    "title": "CAS 5.1.0 RC3 Feature Release",
    "text": "The official CAS 5.0.0 GA was released on November 7th 2016. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.1.0. This post intends to highlight some of the improvements and enhancements packed into the third release candidate in the 5.1.0 series. The in-development documentation of CAS 5.1.0 is available here. The release schedule is also available here. The release policy is available here. If you are looking for additional info on the previous release candidate, please see this post. Embedded Container Modules Hazelcast Ticket Registry Embedded Tomcat SSL Valve Administrative Endpoint Security Scripted Username Attribute Providers SPNEGO Webflow Authentication JPA Ticket Registry Ticket Metadata and Catalog Embedded Tomcat Default Connector Settings Code Cleanup and Optimization Configuration Panel Spring Cloud Configuration Server DynamoDb Ticket Registry CAS Heroku Demos Attribute Repositories &amp; Attributes AWS CloudWatch Support Sass Auto Compilation REST Authentication via X.509 X.509 Principal Resolution WS-Fed Protocol Attribute Filtering Policies Jasypt Support DynamoDb Service Registry Minor Bug Fixes Community Contributions Others Library Upgrades What’s Next? Get Involved Das Ende Embedded Container Modules In previous feature releases, the CAS server web application module shipped automatically with an embedded Tomcat container. This presented a few difficulties to folks who wanted to step outside the box and get the CAS web application deployed in alternative containers such as WebSphere, JBoss, etc. Starting with this release candidate, the CAS server web application switches back to its original vanilla state where nothing is embedded by default. This should allow you to deploy CAS to any container that is servlet-spec compliant by CAS requirements. However, additional modules are provided for embedded containers that are Apache Tomcat, Jetty and Undertow. If you had been previously working with the embedded container and running Apache Tomcat natively, you do need to switch the webapp module to one that contains an embedded container of your choice. Note that embedded-container modules may be deployed to externally-configured containers too. CAS should detect the external instance and auto-disable the embedded container from bootstrapping itself, regardless of container type. Hazelcast Ticket Registry Thanks to community contributions, the Hazelcast Ticket Registry is reorganized to improve its performance, by splitting the underlying cache in half. Work is also done to ensure the registry is prepped to handle additional ticket types dynamically. Embedded Tomcat SSL Valve Thanks to community contributions, the embedded tomcat container gains support for configuration of the SSL Valve. This should be useful if you are trying to handle X.509 authentication at the servlet container level. Administrative Endpoint Security Individual endpoints that are exposed by the CAS admin panels each have their own security settings. To make the configuration easier, there now exists a single block that may control the security of all settings globally, while still allowing individual overrides to take over. As an additional option, endpoints that are secured with Spring Security now can take advantage of JAAS authentication. Scripted Username Attribute Providers Username attribute providers linked to a service definition are enhanced to accommodate further scripting techniques via Groovy. Also, a number of providers are now able to apply transformations on the final username returned back to the application, such as turning the id into all caps, etc. SPNEGO Webflow Authentication The SPNEGO functionality still had a few references and instructions on how changes that needed to be manually applied to the webflow. Those are now removed and automated internally to match the manual steps. JPA Ticket Registry The JPA ticket registry no longer requests a hardcoded dependency link to the OAuth module. In the past, the registry simply auto-created OAuth tables and entities given the components were found and scanned automatically as a result of that dependency link. Today, that chain is removed and the registry shall only recognize and act upon OAuth functionality, if the functionality is explicitly turned on. Ticket Metadata and Catalog Traditionally, ticket types in CAS are mostly concerned with ticket-granting tickets, service tickets, proxy tickets, etc. These are distinct types that are defined as first-class citizens of the CAS public API. Over time, there have emerged additional tickets types that represent various other forms of tokens to CAS, such as OAuth codes, access tokens, refresh tokens, etc. Each ticket type has its own lifespan and other settings too. How do ticket registries deal with additional types, given their presence and functionality can only be discovered at runtime dynamically? Some took shortcuts. For instance, the JPA ticket registry created a hard-link to the OAuth module (described above) so it could ensure OAuth tickets were stored in separate tables as distinct entities, etc. It asked for pre-authorized knowledge of the CAS API, even though the functionality controlled by that API may not even be in use at all. Is there a reason the registry should handle OAuth-related functionality even when OAuth is not even enabled or required by the deployment? Not a trick question. So the target goal is that each registry implementation (and all of CAS really) should be able to dynamically realize what ticket types are used by the CAS runtime and what ticketing-related functionality is actually enabled by the deployer. The discovery mechanism should provide enough information, as a catalog, to the relevant modules about known types, their metadata and various other required properties so each registry can dynamically and generically look up that metadata and regroup itself to handle each unique type. Advantages of this approach are: No need to establish static linkage between CAS modules to teach each about various ticket types exposed in the module API. As you can imagine, over time given new tickets types that have emerged and the list of registries supported by CAS, static linking is simply non-maintainable and core logic in each registry can get very messy if it were to deal with 8+ different ticket types, caches, storage requirements, etc. Given no static linking, LOC will be reduced down to the bare minimum and what may be auto-discovered at runtime. Given no static linking, maintenance and extensions to the CAS API can be done much more comfortably. Given no static linking, the amount of extra [yet needless] work that would be carried out by each registry is only activated IIF the feature is actually utilized by the deployment. So starting with this release candidate, modules that intend to provide their own special flavors of tickets when necessary register the relevant types into the “global ticket catalog” as it were. Registries are then freed up look into the catalog and reorganize themselves as needed to handle all ticket types. Embedded Tomcat Default Connector Settings In the event that you decide to run CAS without any SSL configuration in proxying mode and perhaps on a non-secure port, there are now additional settings exposed in the configuration that allow you to control the behavior of the connector linked to the port, to mark it as secure with a scheme of https, etc. Code Cleanup and Optimization Thanks to community contributions, the CAS codebase is revitalized ever more to make sure most if not all underlying components adhere to proper coding standards and design practices. Changes in this area include adjustments to style guidelines, constructor-based dependency injections and better adherence to the native Java 8 Collections and Lambda APIs. Configuration Panel A number of enhancements are applied to the CAS configuration panel to ensure it can detect properties that are changed manually in configuration sources (i.e cas|application.properties). The panel is also able to now immediately apply configuration changes. This item is closely related to the changes done, described below, to externalize the deployment of the Spring Cloud Configuration Server. Spring Cloud Configuration Server &times; BewareThis may be a breaking configuration change. Consult the docs to learn more. In previous versions and release candidates, CAS shipped with an embedded configuration server backed by Spring Cloud. While extremely powerful, this added a number of complications such as bootstrap start-up times and extra care around securing various endpoints, etc. In this release candidate, the configuration server functionality is pulled out of the main CAS server web application and is produced as a separate project with its own overlay. Deployments may choose to run CAS in a standalone mode or they may wish to let CAS become a client of the centralized configuration server consuming settings from multiple sources for a variety of profiles, etc. Note that if you’d deployed CAS with the understanding of reading configuration files from the default /etc/cas/config, then you should have very little, if anything, to worry about if and when you make the jump. If you have deviated from the defaults and decided to go your own way, please consult the documentation to learn about needed readjustments. DynamoDb Ticket Registry CAS gains support for DynamoDb as yet another option for its ticket registry. This feature might look more attractive for those who wish to use AWS as the deployment environment and take advantage of native platform services and offerings. CAS Heroku Demos Demo instances of both the CAS server and CAS Management server web applications have been updated to run the latest versions of CAS 5. Attribute Repositories &amp; Attributes &times; BewareThis may be a breaking configuration change. Consult the docs to learn more. A requested improvement from the 5.0.x days; Deployments that cannot not rely on the attribute retrieval mechanism done during the same authentication request/transaction typically use separate attribute repositories to define retrieval rules. This allows one to for instance say: Authenticate against a JDBC source, but retrieve attributes from separate LDAP and Groovy sources. Or a bit more advanced: Authenticate against an LDAP source, but retrieve attributes from multiple LDAP repositories yet map attributes for each differently depending on the authentication source. So long story short, attributes that were to be retrieved from such sources were all defined in one common block global to all repositories. In this release, the attributes are removed from the global common block in CAS configuration settings and made specific for each attribute repository instance that is defined. This provides a much more flexible configuration where one could for instance then say: Authenticate against a JDBC source, but define two LDAP sources for attributes where one is only allowed to request/retrieve attributes A,B,C while the other can only request/retrieve X,Y,C. Oh…map these attributes for each source differently. Then merge it all together and resolve conflicts. Have fun while doing it! Fun times. AWS CloudWatch Support CAS gains support to route logs automatically to AWS CloudWatch. You can review this guide here to learn more. You are also allowed to use other logging and monitoring tools such as Sentry, Syslog and Logstash to manage and route CAS logs in addition to all the usual options. Sass Auto Compilation Sass files are now automatically and as part of the build compiled to .css files for the main CAS server web application. REST Authentication via X.509 CAS REST Protocol gains the ability to authenticate credentials via X.509, thanks to community contributions. X.509 Principal Resolution Thanks to community contributions, X.509 principal resolution by serial number is now able to support HEX and other configurable radixes. WS-Fed Protocol Starting with this release candidate, CAS gains modest support for the WS-Fed protocol, acting both as an identity provider and security token service. Attribute Filtering Policies A number of new attribute filters are worked into this release that provide support for selectively applying patterns to attributes values to allow or disallow them. Jasypt Support Running CAS in standalone mode now allows you the option to place encrypted settings into the CAS configuration files and then have them be decoded automatically. This feature is brought to you by CAS taking advantage of Jasypt. DynamoDb Service Registry CAS gains support for DynamoDb as yet another option for its service registry. This feature might look more attractive for those who wish to use AWS as the deployment environment and take advantage of native platform services and offerings. Minor Bug Fixes A number of small bug fixes have been incorporated into this feature release: Community Contributions SAML2 InResponseTo field is now correctly set in response. JDBC data sources are massaged to correctly handle the minimum number of idle connections. YAML properties are now correctly loaded both from the embedded web application as well as externalized sources. Regressions that made service properties in the CAS management webapp dysfunctional are now removed/fixed. LDAP authentication removes the need for separate SASL authentication type option, folding it neatly into AUTHENTICATED. Documentation improvements to explain the proper encoding used for .properties and .yml files. Others OAuth services are now properly recognized during the logout process. SAML2 authenication statements should now properly include a session index. CAS cookies are set to httpOnly by default with options to control this behavior externally. SAML2 attribute statements should now correctly use the SAML2 prefix when constructing attribute values. SAML2 ECP functionality gets a brand new pass to resolve a series of issues with encodings and responses. Library Upgrades Spring Hazelcast Spring Boot Apache Tomcat Spring Cloud Hibernate Log4j HJSON Metrics Groovy JodaTime … What’s Next? The development team is working to make sure the CAS 5.1.0 release is on schedule. Additional release candidates and more updates will likely be released prior to the official GA release. Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Review and suggest documentation improvements. Review the release schedule and make sure you report your desired feature requests on the project’s issue tracker. Das Ende A big hearty thanks to all who participated in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2017/03/31/rc3-release/"
  },

  
  
  
  {
    "title": "CAS 5.0.x Deployment - WAR Overlays",
    "text": "This is a short and sweet tutorial on how to deploy CAS via the WAR Overlay method. This tutorial specifically requires and focuses on: CAS 5.0.x Java 8 Overlay…What? Overlays are a strategy to combat repetitive code and/or resources. Rather than downloading the CAS codebase and building it from source, overlays allow you to download a pre-built vanilla CAS web application server provided by the project itself, override/insert specific behavior into it and then merge it all back together to produce the final (web application) artifact. You can find a lot more about how overlays work here. The concept of the WAR Overlay is NOT a CAS invention. It’s specifically an Apache Maven eature and of course there are techniques and plugins available to apply the same concept to Gradle-based builds as well.You are free to choose between Maven or Gradle. For this tutorial I opted into the Maven WAR overlay. Once you have forked and cloned the repository locally, you’re ready to begin. NoteRemember to switch to the appropriate branch. Today, the master branch of the repository applies to CAS 5.0.x deployments. That may not necessarily remain true when you start your own deployment. So examine the branches and make sure you checkout the one matching your intended CAS version. Overlay’s Anatomy Similar to Grey’s, a Maven WAR overlay is composed of several facets the most important of which is the pom.xml file. This is a build descriptor file whose job is to teach Apache Maven how to obtain, build, configure (and in certain cases deploy) artifacts. KISSYou do not need to download Apache Maven separately. The project provides one for you automatically with the embedded Maven Wrapper. The pom.xml is composed of several sections. The ones you need to worry about are the following. Properties &lt;properties&gt; &lt;cas.version&gt;5.0.4&lt;/cas.version&gt; &lt;springboot.version&gt;1.4.2.RELEASE&lt;/springboot.version&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; This is the bit that describes build settings, and specifically here, what versions of CAS, Spring Boot and Java are required for the deployment. You are in practice mostly concerned with the &lt;cas.version&gt; setting and as new (maintenance) releases come out, it would be sufficient to simply update that version and re-run the build. This might be a good time to review the CAS project’s Release Policy as well as Maintenance Policy. Dependencies The next piece describes the dependencies of the overlay build. These are the set of components almost always provided by the CAS project that will be packaged up and put into the final web application artifact. At a minimum, you need to have the cas-server-webapp module available because that is the web application into which you intend to inject your settings and customizations, if any. Also, note that the module declarations are typically configured to download the CAS version instructed by the property ${cas.version}. Here is an example: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Including a CAS module/dependency in the pom.xml simply advertises to CAS your intention of turning on a new feature or a variation of a current behavior. Do NOT include something in your build just because it looks and sounds cool. Remember that the point of an overlay is to only keep track of things you actually need and care about, and no more. RememberKeep your build clean and tidy. A messy build often leads to a messy deployment, complicates your upgrade path and is a documented cause of early hair loss. Keep changes down to the absolute essentials and document their need for your deployment. If you review the configuration a year from now, you should have an idea of why things are the way they are. And What About…? There are many other pieces in the pom.xml, such as repositories, profiles, plugins, etc that I skipped. For everything else, there is MasterCard…and of course the official Apache Maven guides. Enjoy! The Build Now that you have a basic understanding of the build descriptor, it’s time to actually run the build. An Apache Maven build is often executed by passing specific goals/commands to Apache Maven itself, aka mvn. So for instance in the the terminal and once inside the project directory you could execute things like: cd cas-overlay-template mvn clean …which may be a problem if you don’t have already have Apache Maven downloaded and installed. While you can do that separate install, the WAR Overlay project provides you with an embedded Apache Maven instance whose job is to first determine whether you have Maven installed and if not, download and configure one for you based on the project’s needs. So you can replace that command above with: cd cas-overlay-template mvnw clean …which may be a problem because, how are you supposed to know what commands/goals can be passed to the build? You can study them for sure, but the project provides you with a shell script that wraps itself around the Maven wrapper and provides an easy facade for you to remember commands and their use. This is the build.sh file, which you can run as such: cd cas-overlay-template ./build.sh help Usage: build.sh [copy|clean|package|run|debug|bootrun] What do these commands do? Type Description copy Copies the configuration from the local etc/cas/config directory to /etc/cas/config. See this guide to learn more. clean Deletes any previously-built and leftover artifacts from the target directory. package Runs clean and copy. Then packages the CAS web application artifact and run through the overlay to inject local customizations. The outcome is a target/cas.war file which is ready to be deployed. run Invokes package and then deploys and runs the CAS web application via its own embedded server container. debug Same thing as run, except that you can remote-debug the CAS web application over port 5000. bootrun Same thing as run, except the deployment is managed by the Spring Boot Maven plugin. This command has very specialized and limited use cases. Please review this issue to learn more. RememberDocs grow old. Always consult the overlay project's README file to keep to date. As an example, here’s what I see if I were to run the package command: ./build.sh package Creating configuration directory under /etc/cas Copying configuration files from etc/cas to /etc/cas/config etc/cas/config/application.yml -&gt; /etc/cas/config/application.yml etc/cas/config/cas.properties -&gt; /etc/cas/config/cas.properties etc/cas/config/log4j2.xml -&gt; /etc/cas/config/log4j2.xml [INFO] Scanning for projects... [INFO] [INFO] Using the MultiThreadedBuilder implementation with a thread count of 5 [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building cas-overlay 1.0 [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ cas-overlay --- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ cas-overlay --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /cas-overlay-template/src/main/resources [INFO] [INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ cas-overlay --- [INFO] No sources to compile [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ cas-overlay --- [INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /cas-overlay-template/src/test/resources [INFO] [INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ cas-overlay --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ cas-overlay --- [INFO] No tests to run. [INFO] [INFO] --- maven-war-plugin:2.6:war (default-war) @ cas-overlay --- [INFO] Packaging webapp [INFO] Assembling webapp [cas-overlay] in [/cas-overlay-template/target/cas] [info] Copying manifest... [INFO] Processing war project [INFO] Processing overlay [ id org.apereo.cas:cas-server-webapp] [INFO] Webapp assembled in [786 msecs] [INFO] Building war: /cas-overlay-template/target/cas.war [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 2.504 s (Wall Clock) [INFO] Finished at: 2017-03-23T14:57:11+04:30 [INFO] Final Memory: 12M/441M [INFO] ------------------------------------------------------------------------ You can see that the build attempts to download, clean, compile and package all artifacts, and finally it produces a /cas-overlay-template/target/cas.war which you can then use for actual deployments. RememberYou are allowed to pass any of Maven's native command-line arguments to the build.sh file. Things like -U or -X might be useful to have handy. Configuration I am going to skip over the configuration of /etc/cas/config and all that it deals with. If you need the reference, you may always use this guide to study various aspects of CAS configuration. Suffice it to say that, quite simply, CAS deployment expects the main configuration file to be found under /etc/cas/config/cas.properties. This is a key-value store that is able to dictate and alter behavior of the running CAS software. As an example, you might encouter something like: cas.server.name=https://cas.example.org:8443 cas.server.prefix=https://cas.example.org:8443/cas logging.config=file:/etc/cas/config/log4j2.xml …which at a minimum, identifies the CAS server’s url and prefix and instructs the running server to locate the logging configuration at file:/etc/cas/config/log4j2.xml. The overlay by default ships with a log4j2.xml that you can use to customize logging locations, levels, etc. Note that the presence of all that is contained inside /etc/cas/config/ is optional. CAS will continue to fall back onto defaults if the directory and the files within are not found. Keep Track It is VERY IMPORTANT that you contain and commit the entire overlay directory (save the obvious exclusions such as the target directory) into some sort of source control system, such as git. Treat your deployment just like any other project with tags, releases and functional baselines. Overlay Customization If I cd into the target/cas directory, I can see an exploded version of the cas.war file. This is the directory that contains the results of the overlay process. Since I have not actually customized and overlaid anything yet, all configuration files simply match their default and are packaged as such. So as an example, let’s change something. Digging further down, I notice there exists a /target/cas/WEB-INF/classes/messages.properties file, which is the default message bundle. I decide that I am going to change the text associated with screen.welcome.instructions. RememberDo NOT ever make changes in the target directory. The changesets will be cleaned out and set back to defaults every time you do a build. Follow the overlay process to avoid surprises. First, I will need to move the file to my project directory so that Apache Maven during the overlay process can use that instead of what is provided by default. Here we go: cd cas-overlay-template mkdir -p src/main/resources cp target/cas/WEB-INF/classes/messages.properties src/main/resources/ Then I’ll leave everything in that file alone, except the line I want to change. ... screen.welcome.instructions=Speak Friend and you shall enter. ... Then I’ll package things up as usual. ./build.sh package ... [INFO] --- maven-war-plugin:2.6:war (default-war) @ cas-overlay --- [INFO] Packaging webapp [INFO] Assembling webapp [cas-overlay] in [/cas-overlay-template/target/cas] [info] Copying manifest... [INFO] Processing war project [INFO] Processing overlay [ id org.apereo.cas:cas-server-webapp] [INFO] Webapp assembled in [1005 msecs] [INFO] Building war: /cas-overlay-template/target/cas.war [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS ... If I look at target/cas/WEB-INF/classes/messages.properties after the build, I should see that the overlay process has picked and overlaid onto the default my version of the file. RememberOnly overlay and modify files you actually need, and try to use externalized resources and configuration as much as possible. Just because you CAN override something in the default package, it doesn't mean that you should. Deploy You have a number of options when it comes to deploying the final cas.war file. This post should help. So… I hope this brief tutorial was of some assistance to you. It’s important that you start off simple and make changes one step at a time. Once you have a functional environment, you can gradually and slowly add customizations to move files around. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/03/28/cas5-gettingstarted-overlay/"
  },

  
  
  
  {
    "title": "CAS 5 LDAP AuthN and Jasypt Configuration",
    "text": "This is a short and sweet tutorial on how to configure CAS for LDAP authentication and secure bind credentials via Jasypt encryption. Most of the material is based on the available documentation here and here. This tutorial specifically focuses on: CAS 5.1.0-RC3-SNAPSHOT Java 8 Docker 1.13.x Apache Tomcat 8.5.x Jasypt CLI. You can download the distribution from here. This tutorial assumes that you are running CAS in its standalone mode, described here. LDAP Setup For this tutorial, I am using a 398-ds LDAP server from this docker image. Once you have the image running, you can connect to the underlying LDAP server at localhost:10389 with cn=Directory Manager and password. The LDAP server is also prepped with a users.ldif file that contains the test account jsmith:password. docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0f2a75441fb5 jtgasper3/389ds-basic \"/bin/sh -c '/usr/...\" 11 days ago Up 6 minutes 0.0.0.0:10389-&gt;389/tcp ldap-server Sweet! Moving on… Deploy CAS Hop over to the overlay installation and get CAS built and deployed. The CAS version I am using today is 5.1.0-RC3-SNAPSHOT. It does not matter whether you end up using Maven or Gradle. Choose what fits you best. When you have a baseline functioning build, continue on. Configure CAS Once you have added the LDAP module to your build as is described here, you then need to teach CAS about the running LDAP server. Here is what I did in the cas.properties file, along with all the other usual suspects: cas.authn.ldap[0].type=AUTHENTICATED cas.authn.ldap[0].ldapUrl=ldap://localhost:10389 cas.authn.ldap[0].useSsl=false cas.authn.ldap[0].baseDn=ou=People,dc=example,dc=edu cas.authn.ldap[0].userFilter=uid={user} cas.authn.ldap[0].bindDn=cn=Directory Manager cas.authn.ldap[0].bindCredential=password I also need to disable static authentication. It would also be very nice if I could turn on DEBUG logs and see what CAS attempts to do: logging.level.org.apereo=DEBUG cas.authn.accept.users= Build and Deploy Once you get CAS built and deployed, logs should indicate something like this: 2017-03-22 16:01:06,915 INFO [o.a.c.c.LdapAuthenticationConfiguration] - &lt;Ldap authentication for [LdapAuthenticationHandler] is to chain principal resolvers via [[org.apereo.cas.authentication.principal.resolvers.ChainingPrincipalResolver@1452f4cb[chain=[org.apereo.cas.authentication.principal.resolvers.PersonDirectoryPrincipalResolver@1b7c5e6a[returnNullIfNoAttributes=false,principalAttributeName=&lt;null&gt;], org.apereo.cas.authentication.principal.resolvers.EchoingPrincipalResolver@6824495c[]]]]] for attribute resolution&gt; Great. Next, pull up CAS in your browser and log in with jsmith and password and you should be in. Viola! Jasypt Encryption You may have noted that the LDAP bindCredential is put into the cas.properties file in plain-text. As the next steps: We will first encrypt the bindCredential value via Jasypt and put it into CAS. We will instruct CAS to decrypt the setting at runtime invisibly and resume as usual. Note that there is nothing stopping you from encrypting any other setting! Encrypt via Jasypt Once you download the Jasypt CLI, at a minimum you need to decide which algorithm you want to use for encryption and what your encryption key/password should be which is the thing that is later taught to CAS to decode the value. In the bin directory of the distribution, you can invoke ./listAlgorithms.sh|bat to see what may be possible for algorithms and then use the ./encrypt.sh|bat to encrypt values. So for me to encrypt the value of bindCredential, I ran the following command: ./encrypt.sh input=password algorithm=PBEWithMD5AndTripleDES password=MySuperPassword ----ENVIRONMENT----------------- Runtime: Oracle Corporation Java HotSpot(TM) 64-Bit Server VM 25.121-b13 ----ARGUMENTS------------------- algorithm: PBEWithMD5AndTripleDES input: password password: MySuperPassword ----OUTPUT---------------------- mqWuN+/U7oofNhdSVNcEgmVcwGmxiOaS I can also confirm that this value can be decoded as well: ./decrypt.sh input=mqWuN+/U7oofNhdSVNcEgmVcwGmxiOaS algorithm=PBEWithMD5AndTripleDES password=MySuperPassword ----ENVIRONMENT----------------- Runtime: Oracle Corporation Java HotSpot(TM) 64-Bit Server VM 25.121-b13 ----ARGUMENTS------------------- algorithm: PBEWithMD5AndTripleDES input: mqWuN+/U7oofNhdSVNcEgmVcwGmxiOaS password: MySuperPassword ----OUTPUT---------------------- password Cool. Let’s move on. Configure CAS So now that I have encrypted value in the OUTPUT section, I am going to slightly massage my configuration as such: ... cas.authn.ldap[0].bindCredential={cipher}mqWuN+/U7oofNhdSVNcEgmVcwGmxiOaS ... Finally, we need to teach CAS to handle the reverse of this operation. Consulting the docs here, I ended up adjusting my configuration as such: cas.standalone.config.security.alg=PBEWithMD5AndTripleDES Using the embedded tomcat container, I configured my “run CAS” command to pass along the encryption key as a command-line parameter. If you prefer, you could do the same thing with environment variables and system properties. java -jar target/cas.war --cas.standalone.config.security.psw=MySuperPassword Next time when attempt to deploy and run CAS, you should be able to bind and connect to LDAP and authenticate as before. That’s it! Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/03/24/cas51-ldapauthnjasypt-tutorial/"
  },

  
  
  
  {
    "title": "CAS 5 SAML2 Delegated AuthN Tutorial",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. This is a short and sweet tutorial on how to configure CAS to delegate authentication to an external SAML2 identity provider. Most of the material is based on the available documentation. This tutorial specifically focuses on: CAS 5.1.0-RC3-SNAPSHOT Java 8 Apache Tomcat 8.5.11 Okta Developer account Deploy CAS Hop over to the overlay installation and get CAS built and deployed. The CAS version I am using today is 5.1.0-RC3-SNAPSHOT. It does not matter whether you end up using Maven or Gradle. Choose what fits you best. When you have a baseline functioning build, continue on. Configure CAS Add the required module specified here in the documentation to your build. Next, we need to teach CAS about the external SAML2 Identity Provider. The configuration displayed below simply wants to have CAS act as a sevice provider with its own unique entity id, keystore, etc. CAS itself will generate the relevant service-provider credentials, keystores and metadata and will then examine the identity provider metadata document to learn about endpoints, etc. So you only really have to provide the values and let the software handle the rest. cas.authn.pac4j.saml[0].keystorePassword=pac4j-demo-passwd cas.authn.pac4j.saml[0].privateKeyPassword=pac4j-demo-passwd cas.authn.pac4j.saml[0].serviceProviderEntityId=urn:mace:saml:pac4j.org cas.authn.pac4j.saml[0].serviceProviderMetadataPath=/etc/cas/config/sp-metadata.xml cas.authn.pac4j.saml[0].keystorePath=/etc/cas/config/samlKeystore.jks cas.authn.pac4j.saml[0].identityProviderMetadataPath=https://dev-12345.oktapreview.com/app/486ngfgf/sso/saml/metadata Note that the above settings are indexed, which means that if you needed to, you could delegate authentication to more than one identity provider. Also remember that metadata, keystores and such are only created if they are absent from the specified locations. You can certainly hand-massage them if needed, and CAS will let them be as they are without complaints. Configure Okta Follow the documentation described here to create a developer account and add a new application as a SAML2 IdP. At a minimum, you need to provide Okta with the SSO (ACS) url and entity id of the service provider, that being CAS in this case. You do have the entity id above and the ACS url takes on the following form: https://sso.example.org/cas/login?client_name=SAML2Client The configuration would look something like the following image: Finally you need to assign people/users to the SAML2 Identity Provider application to allow for authentication: Okta is then able to provide you with a metadata for this instance, which you can then use to plug back into the above settings. That’s It When you deploy CAS, your default logs (though you could certainly turn on DEBUG to observe a lot more) would indicate something along the following lines: 2017-03-22 13:33:59,147 INFO [o.a.c.s.p.c.s.a.Pac4jAuthenticationEventExecutionPlanConfiguration] - &lt;Located and prepared [1] delegated authentication clients&gt; 2017-03-22 13:33:59,182 INFO [o.a.c.s.p.c.s.a.Pac4jAuthenticationEventExecutionPlanConfiguration] - &lt;Registering delegated authentication clients...&gt; …and when you get to the login page, you will see the following: The same strategy simply applies to all other forms of delegated authentication, such as social identity providers or other CAS servers. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/03/22/cas51-delauthn-tutorial/"
  },

  
  
  
  {
    "title": "Busting the Myth - GA Release",
    "text": "If you are a member of an open source community, currently waiting for something to be officially tagged as a GA release so you can begin planning your production deployments and schedule, this post is for you. You are holding it wrong. The GA Release A GA release is typically the last step in the software release life cycle. It is the point where the overall developer and user communities have reasonable confidence in the viability of the software and consider the release physique to generally be in a good-enough shape. How is a release beaten into shape? A GA release typically follows after one or more release candidates. The release candidate is a beta version of the software with potential to be a final product unless significant bugs are discovered during trials. Release candidates provide opportunities for the community to begin testing new and old product features to the extent and interest reasonable, until show-stopper defects are all evaluated and possibly removed. To GA or Not to GA There are a number of risky assumptions made about GA releases that typically end up affecting the overall [production] deployment schedule in negative ways. Here is what I have learned. No Magic Some deployments tend to consider a GA release as “This is good to go”. This statement may be true in larger communities (and not even then) with many active participants, testers and enthusiasts who get involved and step forward to test features, troubleshoot and diagnose issues, provide feedback and patches. After all, that’s how one develops confidence for a release, right? “This was tested by 20 people and in the end they were all found with a smile on their face.” If your community and your membership does not filter through those parameters and yet you’re planning your production rollouts and schedules based on the availability of that release, I promise, you have set yourself up for surprises. Of course, some tend to assume that confidence in a given release somehow stems from the deep chasms of the Misty Mountains. While an avid hiker myself and having not visited the place for certain, I find that claim to be suspicious. A GA tag is just a tag. That’s all….Yes, it’s just a tag. It holds no magical powers. Really. Love Thyself I might be stating the obvious here… The only person that really cares about you…is you. Why does that matter and how is that relevant? When you begin to plan your production deployment, you inevitably have to make a number of assumptions about your overall environment. You may be upgrading from a previous version and need to figure out how to transition the old to the new. The product may also bring about a few new features in which you may want to invest and then have other applications and systems utilize. You may have to strengthen and modify the infrastructure, security policy, integrations, high-availability and scalability requirements, etc. It’s not an easy thing. Are you willing to trust your plans with the (possible, if any) test results of other beta testers in the community? Does your community even have beta testers? Do you know if they might have the same interests and needs in the software capabilities as you? Do you have access to their test results? Are you aware of their testing policies? What sort of tests anyway? Integration tests, functional tests, HA tests, accessibility tests, smoke tests…? In my experience, it’s much more effective to take direct control of the situation beforehand. Community members and testers test and spend time on features they care about. That may not necessarily include yours. Another Left Turn Sigh. This is my least favorite thing to jot down. Here’s how it goes: You are waiting for others (developers, beta testers, goblins, etc) to test features before it’s to become GA. Others are waiting for you and others to test features before it’s to become GA. Tail-recursion back to #1. Something eventually breaks that cycle; it’s usually the release schedule. Most development communities find themselves saying “We have tested what we could. Nobody else has reported anything. It’s been 6 months. This is good-enough”. Do not put yourself in situations where you have to face the question of the falling tree not having any witnesses. Your time is better spent elsewhere on other things…like testing! OK. What Now? In short, I have learned that early involvement is tremendously valuable. Sure, it is very helpful to rely on others’ vote of confidence and make plans. It’s immensely better if YOU are that confidence. Misagh Moayyed",
    "tags": "Blog",
    "url": "/2017/03/08/the-myth-of-ga-rel/"
  },

  
  
  
  {
    "title": "CAS Vulnerability Disclosure",
    "text": "Overview This is the public version of an Apereo CAS project vulnerability disclosure describing an issue in CAS where an adversary may be able to bypass certain administrative endpoints, in spite of CAS access rule in place. The following administrative endpoints are exposed and vulnerable to this attack: /configserver/ /cas/status/metrics Affected Deployments The attack vector specifically applies to all deployments of CAS 5.0.x deployments. If you have deployed any version of CAS 5.0.x, you MUST take action to upgrade. If you have deployed any other versions of CAS, disregard this announcement. Severity This is a serious issue where successfully exercising this vulnerability allows the adversary gain insight into the running CAS software, collect stats and metrics and potentially observe the collection of configured CAS settings in configuration files. Patching Patch releases are available to address CAS 5.0.x deployments. Upgrades to the next patch version for each release should be a drop-in replacement. The patch simply ensures that the exposed endpoints honor the CAS access rules, and otherwise block attempts. When you have applied the patch, please double check all endpoints and ensure access is appropriately controlled. Timeline The issue was originally reported to the CAS application security team on February 20, 2017. Upon confirmation, CAS was patched on February 22, 2017 and released. The original release announcement is available here. Procedure Update Version Modify your CAS overlay to point to version 5.0.3.1. A snippet of a pom.xml for a CAS overlay follows: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.jasig.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;cas.version&gt;5.0.3.1&lt;/cas.version&gt; &lt;/properties&gt; Double check your cas.properties file for the following setting: # cas.adminPagesSecurity.ip=the-authorized-ip-pattern Adjust Overlay If your CAS build has overlaid the src/main/resources/bootstrap.properties file, make sure the following line is corrected there: spring.cloud.config.server.prefix=/status/configserver Alternatives If you are unable to apply the patch, it’s then best to ensure the outlined endpoints are blocked completely via load balancers, proxies, firewalls, etc. Support If you have questions on the details this vulnerability and how it might be reproduced, please contact security@apereo.org or cas-appsec-public@apereo.org. Resources CAS Security Vulnerability Response Model",
    "tags": "CAS",
    "url": "/2017/03/06/moncfgsecvulndisc/"
  },

  
  
  
  {
    "title": "CAS 5.1.0 RC2 Feature Release",
    "text": "The official CAS 5.0.0 GA was released on November 7th 2016. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.1.0. This post intends to highlight some of the improvements and enhancements packed into the second release candidate in the 5.1.0 series. The in-development documentation of CAS 5.1.0 is available here. The release schedule is also available here. The release policy is available here. If you are looking for additional info on the previous release candidate, please see this post. Authentication Sequence Monitoring/Status Protection with Spring Security SAML IdP Metadata Generation Code Cleanup and Optimization XML Test Configuration MongoDb Ticket Registry CAS Documentation Improvements Custom Password Encoders Management Webapp Authorization FIDO U2F MFA Microsoft Azure MFA Principal SCIM Provisioning Internal Support for Kotlin Clearpass Internal Encryption Database Audit Default Catalog/Schema OpenID Connect JWKS Caching OpenID Connect Scope-based Claim Release Grouper Groups as Principal Attributes OpenID Connect Encrypted ID Tokens Native Configuration Monitoring OpenID Connect Implicit Profile Dynamic Acceptable Usage Policy X509 Authentication: LDAP CRL Fetching Google Authenticator Token Tracking Delegated Authentication Providers Google Authenticator JSON Storage CAS Banner &amp; Git Commit Id Multifactor Authentication Trigger via Authentication Attribute LDAP Authentication Search Entry Resolvers Domain Services Manager SAML SP Integrations Python/Javascript Attribute Release Policies Graphical User Authentication SAML InCommon R&amp;S Attribute Release Database Password Policy Enforcement REST Password Management Management Webapp Minor Bug Fixes Library Upgrades What’s Next? Get Involved Das Ende Authentication Sequence At runtime, CAS maintains a collection of authentication handlers/strategies that typically execute one after another. Each CAS module that presents a form of authentication strategy will simply insert itself into this collection at bootstrap time. This means the sequence of authentication execution is very much non-deterministic upon server restarts. At the end of the process, the result of all authentication transactions is collected and optionally processed by an authentication policy where success/failure of certain strategies/sources may be taken into account to fully satisfy the authentication requirements. Starting with this feature release, the collection of authentication handlers tries to preserve order in a rather more deterministic way. Authentication handlers can be assigned a weight/order value thereby explicitly positioning themselves in the collection and controlling executionsequence. At this time, the LDAP and JDBC authentication handlers are the only ones that have qualified for an order setting via the usual CAS properties. Monitoring/Status Protection with Spring Security CAS endpoints that provide monitoring and diagnostics features are now able to support various modes of authorization/authentication backed by Spring Security. Additional modes now include backend authentication support via LDAP or JDBC storage facilities. SAML IdP Metadata Generation The process of generating SAML2 metadata has been smoothened much better to ensure endpoints, ports and url in the metadata correctly match pre-defined CAS settings in order to reduce/remove manual work. Code Cleanup and Optimization Thanks to community contributions, the CAS codebase is revitalized ever more to make sure most if not all underlying components adhere to proper coding standards and design practices. Changes in this area include adjustments to style guidelines, constructor-based dependency injections and navigating to the native Java 8 lambda APIs. XML Test Configuration CAS test infrastructure continues to move away from XML configuration files and towards the facilities provided by Spring Boot. This will allow the project to mirror the deployment runtime configuration as much as possible while troubleshooting and fixing regressions, if any. A number of small enhancements have also gone into the core build system to ensure tests can be built and run in parallel modes via Gradle, which would cut down a full build/release cycle in half (i.e. close to 20 minutes). This is rather helpful when adopters wish to be quick enough to try out SNAPSHOT releases during defect trials. MongoDb Ticket Registry CAS gains support for MongoDb as a storage mechanism for its ticket registry backend. You can learn more about the registry behavior via this guide. CAS Documentation Improvements Most if not all CAS documentation is reviewed to make sure various features properly point to their respective settings/properties via relevant anchor links. Additional work will be done on the settings as well to ensure all properties are properly explained as much as possible. Custom Password Encoders The collection of supported authentication password encoders now allows for the specification of a fully qualified com.example.MyPasswordEncoder implementation class to handle custom encoding use cases. Management Webapp Authorization Authorized access to the management webapp via LDAP now allows for groups and roles in addition to a single search for the user and attributes. FIDO U2F MFA Another multifactor authentication option; basic support is added to provide FIDO U2F. Microsoft Azure MFA As an extra multifactor authentication provider, CAS adds support for Microsoft Azure. A limited number of options are available to verify credentials with Azure that today include: A phone call to a predefined phone number, as an attribute, where user has to press # only. A phone call to a predefined phone number, as an attribute, where user has to provide a CAS-generated token that is presented on the page. Integration with Azure mobile applications may be worked out in future releases based on interest and demand. Principal SCIM Provisioning CAS gains the ability to provision the authenticated principal via SCIM. Internal Support for Kotlin The internal gradle build for the CAS codebase is adjusted to allow compilation of Kotlin’s .kt files, if any. Clearpass Internal Encryption Captures of credential password via Clearpass gain the option to encrypt the password internally via pre-defined keys. The credential upon release in decoded internally in memory and then encrypted with the service’s public key defined in the registry. Database Audit Default Catalog/Schema Database audits are now able to take advantage of new settings that control the default catalog and schema. OpenID Connect JWKS Caching Small improvements have been put in to ensure JWKS resource fetching can go through caching channels to help with processing keystores and performance. OpenID Connect Scope-based Claim Release Additional attribute and claim release policies are now provided to ensure a given OpenID Connect service can release attributes based on pre-defined scope bundles. Grouper Groups as Principal Attributes Thanks to Person Directory’s built-in support of Internet2’s Grouper, CAS is now able to collect a Grouper subject’s groups as principal attributes and perhaps further use them in authorization decisions. OpenID Connect Encrypted ID Tokens ID tokens generated by CAS are now able to be encrypted, provided the client/service is configured appropriately in the registry. Native Configuration Monitoring In the event that the native configuration profile is enabled, CAS is able to automatically monitor the relevant configuration directories and refresh the context upon change. Note that not all CAS components that process settings can be auto-reloaded. YMMV. OpenID Connect Implicit Profile Support for OpenID Connect’s implicit workflow is worked into this release. Dynamic Acceptable Usage Policy Sometimes deployments of CAS’ Acceptable Usage Policy consist of several policies that may be shown to the user depending on membership, affiliation and even perhaps objectclass. In this release, CAS makes the fully resolved Principal available to AUP-related views and pages such that different views housing appropriate policies may be displayed depending on the resolved principal attributes. X509 Authentication: LDAP CRL Fetching A small improvement; an additional property is exposed to allow adopters the specification of the LDAP binary attribute that holds the certificate revocation list. Google Authenticator Token Tracking To prevent immediate OTP reuse while using Google Authenticator as the second authentication factor, CAS starts to track issued tokens that successfully were able to authenticate users. There are also built-in facilities that allow the underlying token-tracking repository to clean up after itself once the token’s expiration tag is removed. Delegated Authentication Providers Delegated authentication in CAS adds support for Bitbucket, Paypal, Wordpress and generic OAuth20 providers. Likewise, CAS should now allow delegating authentication to multiple CAS, SAML, OIDC and OAuth2 servers where before only single instances were supported. Google Authenticator JSON Storage To assist smaller deployments and to also allow for quicker testing and development, Google Authenticator gains support for a JSON storage facility that is able to quickly keep track of user registration records. CAS Banner &amp; Git Commit Id To facilitate testing of SNAPSHOT versions, the CAS banner on startup attempts to demonstrate the Git commit id of the release so adopters and developers may exactly determine the version of the source code deployed. CAS Version: 5.1.0-RC2-SNAPSHOT CAS Commit Id: 0b75fabbb0f865c497327695e30ecf08b6f15e63 CAS Build Date/Time: 2017-01-09T21:27:28Z Spring Boot Version: 1.4.3.RELEASE Apache Tomcat Version: Apache Tomcat/8.5.9 Additionally, the set of diagnostics messages are also printed when one deploys the CAS Management web application. Multifactor Authentication Trigger via Authentication Attribute Title says it all. CAS has had a number of options for triggering multifactor authentication based on a principal attribute. This release adds an additional trigger that allows CAS to directly look into the authentication object to find metadata/attributes captured during the authentication event. This metadata in form of authentication attribute can be used to trigger multifactor authentication events. This is useful in scenarios where the underlying authentication machinery may signal back additional requirements in order for the authentication to fully succeed or, as another example, you may wish to trigger multifactor authentication if the captured authenticationDate matches a certain pattern of your own choosing, etc. LDAP Authentication Search Entry Resolvers CAS adds support for configuring search entry resolvers for LDAP authentication. Additional properties are exposed to support the full range of resolvers that are made available to CAS. Domain Services Manager Thanks to @tsschmidt, the default services manager implementation in CAS that acts as the orchestrator on top of the service registry has been switched out to group service definitions by domain. This is the first step in allowing not only making a more performant CAS when dealing with large collections of service definitions, but also presents a nice opportunity for the management webapp and its UIs to organize definitions in a more sane way. SAML SP Integrations CAS adds support for a few additional built-in SAML SP integrations: Zoom, Asana, Tableau and Evernote. Python/Javascript Attribute Release Policies Additional attribute release policies are worked into CAS that allow one to filter attributes for applications based on external python or javascript files. Graphical User Authentication There now exists basic/modest support for GUA. SAML InCommon R&amp;S Attribute Release There are dedicated attribute release policies now in CAS that allow one to release the required attribute bundle to InCommon’s R&amp;S service providers. Database Password Policy Enforcement Thanks to community contributions, database authentication gains modest support for enforcing password policy rules. REST Password Management Password Management capabilities of CAS begin to support REST APIs and endpoints that wish to take over the maintenance of the user account and updates to the password. Management Webapp The service management web application is enhanced to support a few more additional settings added to the CAS service model for SAML2 and OpenID Connect services. Settings are also organized and grouped by categories that should be easier to find: Minor Bug Fixes A number of small bug fixes have been incorporated into this feature release: Database schema update/generation accounts for more accurate column types and lengths. Google Authenticator QR code generation is remapped in the Spring Boot configuration. Expiration policy of OAuth refresh tokens is now taking into account the correct time unit of measure. Credential validation failures in multifactor authentication scenarios prompt error messages back to the user. Password change actions are now recorded in the CAS audit log. Service ticket creation based on authentication sessions established via renew are now correctly honored. Removed the need to re-create LDAP connection pools during LDAP authentication for entry resolution, etc. SAML assertion encryption is now able to properly locate the encryption credential. Added missing view for CAS responses that require POST. Library Upgrades Cryptacular JodaTime MongoDb Driver Spring Boot Apache Tomcat Log4j2 … What’s Next? The development team is working to make sure the CAS 5.1.0 release is on schedule. Additional release candidates and more updates will likely be released prior to the official GA release. Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Review and suggest documentation improvements. Review the release schedule and make sure you report your desired feature requests on the project’s issue tracker. Das Ende A big hearty thanks to all who participated in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2017/02/24/rc2-release/"
  },

  
  
  
  {
    "title": "CAS 5 Database Authentication Tutorial",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. This is a short and sweet tutorial on how to configure CAS to authenticate against a database and then resolve/release attributes. Most of the material is based on the available documentation. This tutorial specifically focuses on: CAS 5.1.0-RC2-SNAPSHOT HSQLDB 2.3.4 Java 8 Apache Tomcat 8.5.11 Database To keep things rather simple, we’ll be installing an instance of HSQLDB. For this exercise, I am running 2.3.4, though note that the recipe is for the most part the same when dealing with other database instances as well, whether installed manually or run in a dockerized fashion. So running HSQL shows me: [Server@2ff4acd0]: [Thread[main,5,main]]: checkRunning(false) entered [Server@2ff4acd0]: [Thread[main,5,main]]: checkRunning(false) exited [Server@2ff4acd0]: Startup sequence initiated from main() method [Server@2ff4acd0]: Could not load properties from file [Server@2ff4acd0]: Using cli/default properties only [Server@2ff4acd0]: Initiating startup sequence... [Server@2ff4acd0]: Server socket opened successfully in 46 ms. [Server@2ff4acd0]: Database [index=0, id=0, db=file:mydb, alias=xdb] opened successfully in 349 ms. [Server@2ff4acd0]: Startup sequence completed in 396 ms. [Server@2ff4acd0]: 2017-02-21 13:44:37.717 HSQLDB server 2.3.4 is online on port 9001 [Server@2ff4acd0]: To close normally, connect and execute SHUTDOWN SQL [Server@2ff4acd0]: From command line, use [Ctrl]+[C] to abort abruptly Great. Moving on… Create Schema In my setup, I have two tables: one called USERS where user accounts are kept and another called USERATTRS where user attributes are kept. My USERS table is rather simple, but the USERATTRS follows something of a multi-row setup. You want to learn more about this setup here. So here goes the SQL: DROP TABLE IF EXISTS USERS; DROP TABLE IF EXISTS USERATTRS; CREATE TABLE USERATTRS ( id INT NOT NULL IDENTITY , uid VARCHAR(50) NOT NULL, attrname VARCHAR(50) NOT NULL, attrvalue VARCHAR(50) NOT NULL ); CREATE TABLE USERS ( id INT NOT NULL IDENTITY , uid VARCHAR(50) NOT NULL, psw VARCHAR(50) NOT NULL ); INSERT INTO USERS (uid, psw) VALUES ('mmoayyed', 'TheBestPasswordEver'); INSERT INTO USERATTRS (uid, attrname, attrvalue) VALUES ('mmoayyed', 'firstname', 'Misagh'); INSERT INTO USERATTRS (uid, attrname, attrvalue) VALUES ('mmoayyed', 'lastname', 'Moayyed'); INSERT INTO USERATTRS (uid, attrname, attrvalue) VALUES ('mmoayyed', 'phone', '+13476452319'); Note that for the time being, I am just keeping the password as plain-text in the table. No encoding or anything has taken place. Deploy CAS Hop over to the overlay installation and get CAS built and deployed. The CAS version I am using today is 5.1.0-RC2-SNAPSHOT. It does not matter whether you end up using Maven or Gradle. Choose what fits you best. When you have a baseline functioning build, continue on. Configure CAS Follow the steps described here to add the needed CAS modules. Once the module/dependency is added to your build, hop over to the settings page and add the properties. Note that I did not have to add any additional JARs and such for database drivers. CAS ships with a few automatically and by default For this tutorial, this is what I actually needed to make this work: cas.authn.jdbc.query[0].sql=SELECT * FROM USERS WHERE uid=? cas.authn.jdbc.query[0].url=jdbc:hsqldb:hsql://localhost:9001/xdb cas.authn.jdbc.query[0].dialect=org.hibernate.dialect.HSQLDialect cas.authn.jdbc.query[0].user=sa cas.authn.jdbc.query[0].password= cas.authn.jdbc.query[0].driverClass=org.hsqldb.jdbcDriver cas.authn.jdbc.query[0].fieldPassword=psw I also need to disable static authentication. It would also be very nice if I could turn on DEBUG logs and see what CAS attempts to do: logging.level.org.apereo=DEBUG cas.authn.accept.users= Build and Deploy Once you get CAS built and deployed, logs should indicate something like this: 2017-02-21 14:20:18,267 DEBUG [org.apereo.cas.configuration.support.Beans] - &lt;No password encoder shall be created given the requested encoder type [NONE]&gt; 2017-02-21 14:20:18,277 DEBUG [org.apereo.cas.adaptors.jdbc.config.CasJdbcAuthenticationConfiguration] - &lt;Created authentication handler [QueryDatabaseAuthenticationHandler] to handle database url at [jdbc:hsqldb:hsql://localhost:9001/xdb]&gt; Log in with mmoayyed and TheBestPasswordEver and you should be in. Viola! Password Encoding As an extra bonus exercise, let’s turn on MD5 password encoding. The MD5 hash of TheBestPasswordEver is ca541f57a3041c3b85c553d12d3e64a8. So we will update the database accordingly. UPDATE USERS SET psw='ca541f57a3041c3b85c553d12d3e64a8' WHERE uid='mmoayyed'; Then configure CAS to handle MD5 password encoding: cas.authn.jdbc.query[0].passwordEncoder.type=DEFAULT cas.authn.jdbc.query[0].passwordEncoder.encodingAlgorithm=MD5 cas.authn.jdbc.query[0].passwordEncoder.characterEncoding=UTF-8 Build and Deploy Once you get CAS built and deployed, logs should indicate something like this: 2017-02-21 14:44:31,884 DEBUG [org.apereo.cas.configuration.support.Beans] - &lt;Creating default password encoder with encoding alg [MD5] and character encoding [UTF-8]&gt; Build and deploy. Log in with mmoayyed and TheBestPasswordEver and you should be in. Logs may indicate: 2017-02-21 14:45:55,517 DEBUG [org.apereo.cas.util.crypto.DefaultPasswordEncoder] - &lt;Encoded password via algorithm [MD5] and character-encoding [UTF-8] is [ca541f57a3041c3b85c553d12d3e64a8]&gt; 2017-02-21 14:45:55,517 DEBUG [org.apereo.cas.util.crypto.DefaultPasswordEncoder] - &lt;Provided password does match the encoded password&gt; 2017-02-21 14:45:55,519 DEBUG [org.apereo.cas.authentication.AbstractAuthenticationManager] - &lt;Authentication handler [QueryDatabaseAuthenticationHandler] successfully authenticated [mmoayyed]&gt; Good job! Lets get some attributes now. Attributes Because the USERATTRS follows something of a multi-row setup, we want to make sure CAS can understand the specifics of this schema model. Today, CAS is unable to retrieve attributes as part of authentication directly so we need to set up a separate attribute repository instance that CAS will contact once the user is fully authenticated. In our case, the attribute repository is the same database instance. So the configuration may look something like this: cas.authn.attributeRepository.jdbc[0].singleRow=false cas.authn.attributeRepository.jdbc[0].sql=SELECT * FROM USERATTRS WHERE {0} cas.authn.attributeRepository.jdbc[0].username=uid cas.authn.attributeRepository.jdbc[0].url=jdbc:hsqldb:hsql://localhost:9001/xdb cas.authn.attributeRepository.jdbc[0].columnMappings.attrname=attrvalue Once CAS understands the schema, we should then specify which attributes really should be retrieved by CAS. cas.authn.attributeRepository.attributes.firstname=firstname cas.authn.attributeRepository.attributes.lastname=lastname # cas.authn.attributeRepository.attributes.phone=phone Note how I am skipping over phone. The above says, Retrieve attributes firstname and lastname from the repositories and keep them as they are. If we wanted to, we could virtually rename the attributes to for instance TheFir$tN@me and simpleL@stnam3. Release Attributes There are multiple ways of releasing attributes. For this tutorial, I am going to release them globally to all applications: cas.authn.attributeRepository.defaultAttributesToRelease=firstname,lastname Note how I am skipping over phone. Build and Deploy For this to actually be tested, we need a client to which we can release attributes, right? You can use whatever client/application you like, as long as it’s able to retrieve attributes. I ended up using this. When attempting to access the application, I get redirected to CAS. Once I log in and return, I see the following in the CAS logs on startup: 2017-02-21 14:54:04,885 DEBUG [org.apereo.cas.config.CasPersonDirectoryConfiguration] - &lt;Configured multi-row JDBC attribute repository for [jdbc:hsqldb:hsql://localhost:9001/xdb]&gt; 2017-02-21 14:54:04,889 DEBUG [org.apereo.cas.config.CasPersonDirectoryConfiguration] - &lt;Configured multi-row JDBC column mappings for [jdbc:hsqldb:hsql://localhost:9001/xdb] are [{attrname=attrvalue}]&gt; 2017-02-21 14:54:04,890 DEBUG [org.apereo.cas.config.CasPersonDirectoryConfiguration] - &lt;Configured result attribute mapping for [jdbc:hsqldb:hsql://localhost:9001/xdb] to be [{firstname=firstname, lastname=lastname}]&gt; Which shows that CAS has been able to understand the schema and map columns to attributes. Logging into the client application also shows me: So… I hope this brief tutorial was of some assistance to you. Remember that the point here is not to enumerate best practices and such. It’s just to show the possibilities. It’s important that you start off simple and make changes one step at a time. Once you have a functional environment, you can gradually and slowly add customizations to move files, tables and queries around. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/02/22/cas51-dbauthn-tutorial/"
  },

  
  
  
  {
    "title": "Intro To CAS Auto Configuration Strategy",
    "text": "The post specifically applies to CAS 5.1.x which, as of this writing today, is still in development. If you scan the recent literature on CAS configuration model and strategy, you would notice that there is a great amount of emphasis on letting CAS modules dynamically alter the application context at runtime to activate features, massage webflow definitions and move settings around without asking for a whole lot of manual input. How does this all work? Java-based Configuration Given CAS’ adoption of Spring Boot, most if not all of the old XML configuration is transformed into @Configuration components. These are classes declared by each relevant module that are automatically picked up at runtime whose job is to declare and configure beans and register them into the application context. Another way of thinking about it is, components that are decorated with @Configuration are loose equivalents of old XML configuration files that are highly organized where &lt;bean&gt; tags are translated to java methods tagged with @Bean and configured dynamically. Sidestepping irrelevant details, here is an example: package org.apereo.cas.config; @Configuration(\"casCoreMonitorConfiguration\") public class CasCoreMonitorConfiguration { @ConditionalOnMissingBean(name = \"healthCheckMonitor\") @Bean public Monitor healthCheckMonitor() { final List&lt;Monitor&gt; monitors = new ArrayList&lt;&gt;(); // Add monitors to the list as needed dynamically return new HealthCheckMonitor(monitors); } } The above done in XML form manually in a monitors-configuration.xml file would roughly translate into the following: &lt;bean id=\"healthCheckMonitor\" class=\"org.apereo.cas.monitor.HealthCheckMonitor\"&gt; &lt;property name=\"monitors\"&gt; &lt;list&gt; &lt;!-- Add monitors to the list as needed dynamically. --&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; @Configuration Registration How are @Configuration components picked up? Each CAS module declares its set of configuration components as such, per guidelines laid out by Spring Boot: Create a src/main/resources/META-INF/spring.factories file Add the following into the file: org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.apereo.cas.config.CasCoreMonitorConfiguration The above done in XML form would roughly translate into the following: &lt;import resource=\"monitors-configuration.xml\"/&gt; Note that the you can use the same exact technique in CAS overlays to register your own configuration components, or remove/disable CAS’ auto-configuration strategy. For instance, if you prefer to not let CAS bootstrap its monitoring configuration automatically, you can remove it from the registration process in the application.properties file: spring.autoconfigure.exclude=org.apereo.cas.config.CasCoreMonitorConfiguration Overrides and @Conditional What if you needed to override the definition of that healthCheckMonitor bean to add/remove monitors? Or perhaps entirely remove and disable it? This is where @Conditional components come to aid. Most component/bean definitions in CAS are registered with some form of @Conditional tag that indicates to the bootstrapping process to ignore them, if a bean definition with the same id is already defined. This means you can create your own configuration class, register it and the design a @Bean definition only to have the context utilize yours rather than what ships with CAS by default: package org.custom.mine.config; @Configuration(\"MyOwnMonitorConfiguration\") public class MyOwnMonitorConfiguration { @Bean public Monitor healthCheckMonitor() { final List&lt;Monitor&gt; monitors = new ArrayList&lt;&gt;(); // Do what you will to replace the provided CAS monitor. return new HealthCheckMonitor(monitors); } } Make sure your component is registered: org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.custom.mind.config.MyOwnMonitorConfiguration The trick here is, in order to override a bean definition, you need to know its name as your own structure identified by the method name must exactly match that of CAS or the process fails. This is where you look into the CAS source code to learn about various beans, etc. I strongly advise against making this sort of change, unless absolutely warranted and reasonable (To learn why, please read on). What Else? Your @Bean definitions can also be tagged with @RefreshScope to become auto-reloadable when the CAS context is refreshed as a result of an external property change. @Configuration classes can be assigned an order with @Order(1234) which would place them in an ordered queue waiting to be loaded in that sequence. To be more explicit, @Configuration classes can also be loaded exactly before/after another @Configuration component with @AutoConfigureBefore or @AutoConfigureAfter tags and annotations. Why Spring Boot? That is a fair question; Why prefer a Java-based configuration model over XML. Isn’t XML, by intention and definition, more extensible and easier to modify and tweak? Why should you have to write Java-code to extend and modify the context? There are several advantages to this model. Compiled Often times when you build the CAS application package via Maven or Gradle, the build process simply outputs BUILD SUCCESS at the end somehow tricking you into thinking “Great! My changes are going to work.” where in fact that may be entirely false. All that message tells you is that the build tool was able to assemble and package a bunch of configuration files and form a binary archive at the end. The output is going to be all the same, even if you had a typo in the configuration, a missing tag or a bad configuration piece. Also, if a new CAS version decides [for whatever reason] to move that HealthCheckMonitor from org.apereo.cas.monitor into org.apereo.cas.monitors or even rename it to something else, then you end up with a broken configuration when you upgrade. Why? Because it’s exactly that; just configuration. A small piece of fragmented code that tells the application how to behave a tad too late in the deployment lifecycle. Java-based configuration components are the exact opposite. They are source code. They compile. Any typos, mistakes or repackaging of the components will immediately stop the build from succeeding. Think of it this way; if you are designing the electrical system of a building: Would you prefer the wiring system stop you from making potentially fatal mistakes as you attempt to connect the cables and wires together? Or would you prefer to do the whole thing in one go, turn on the lights, have the entire building blow up only to (possibly, maybe) succeed later after a few more iterations? Automated The above note really may not be all that attractive, unless you start to consider that Java-based configuration components can entirely automate the behavior of the application. They can be done once and for all, with small modest options here and there to tweak certain aspects of the feature, and then can ship with the application as first-class citizens only to be activated conditionally at deployer’s command. They are not affected by trivial mistakes, copy-paste errors, maintenance burdens and steep learning curves. XML is a terribly poor choice as a programming language to automate configuration conditionally. If you were asked to turn on and configure a few different features in the application: Would you prefer to go to your build script, declare feature modules, tweak settings and run? Or would you prefer to go to the documentation, copy various [and large] pieces of XML fragments into [perhaps many] configuration files, build and run, trusting that the documentation is accurate for the deployment version, hoping that it all works so you don’t have to understand what a &lt;bean&gt; is, praying you haven’t fat fingered an ending XML tag? Self-Documented The best advantage of configuration automation is that it removes the amount of boilerplate documentation one may have to apply or maintain. There is no longer a need to look after various XML fragments in the documentation, maintain and update them or try to verbosely explain their behavior and function in tutorials and guides [and thus duplicating what Spring or Spring Webflow may have already done in their own documentation!]. The technical details of how Spring or Spring Webflow or LDAP/JDBC libraries work have been abstracted away into what is now commonly referred to as Intentions. To see this in action, see the contents of this page and compare with this page. The former expects a lot more from the deployer while the latter simply translates a deployer’s intention into a small feature module/plugin. As a result, the documentation tends to get a lot more focused and compact. Modernized It would not be unfair to say that that CAS 3.x software, released almost over a decade ago, laid down the sweet architectural foundations for an open and extensible platform with flexible APIs and outlined public injection points. At the time, using technologies such as Spring, JSP and Spring Webflow were superbly attractive and significantly useful in allowing adopters to modify the platform decoratively and extend it programmatically. As a result, many extensions and add-ons and customizations flourished into existence based on the CAS 3.x platform, making the software that much more attractive [and perhaps more complicated to reason about] for adopters’ evaluation. Now a decade later, the CAS software has revitalized its roots and designs to ensure it can keep up with today’s demands and resources and future’s solid and stable technical trends. To that end, Spring Boot is simply the best choice available as a flexible and modern albeit opinionated platform on top of which CAS can continue to grow. With the shift towards cloud-friendly micro-services and such, CAS needed to stay on top of its game by allowing deployments to be self-contained and self-sufficient by employing technologies such as Spring Boot, Spring Cloud, Thymeleaf and such so development and maintenance could sustain given project’s resources and team availabilities and with the presence of more complicated use cases such as MFA, etc. Why Not? There are of course many difficulties and challenges inherent in this model as well, especially if you are new to Spring Boot and have an existing background with XML-based configuration. Learning Curve There is undoubtedly a learning curve here both for deployers and developers. Deployers who are used to the copy-paste XML configuration model may find the auto-configuration magic way too confusing and black-boxish while developers may find the same process to be composed of many moving and puzzling parts. Documentation One could argue that XML-based configuration given its explicit nature could be reasoned about easier where injections of properties and settings into XML beans and such could be more comfortably understood and then tweaked. This is perfectly true that while the documentation has removed the boilerplate fragments needed to activate features, there is still a most definitive need to document and explain away all the settings that activate and control behavior in CAS. The strategy certainly is not to downplay the importance of good documentation and guides; it’s to only highlight what is absolutely expected of the adopter to keep around and maintain in local deployments. It’s also evident that producing good documentation is very much a time-consuming and delicate process, given various levels of technical expertise and skill. It takes time as the platform is still very very young. So by all means, feel free to contribute. Customizations The XML configuration was right in front of you, right? All you had to do was to change an element here and a property there and you were done. It’s quite true that the old model provides easier flexibility though perhaps at the cost of complexity as the platform grows larger. It should be noticed that the ability to configure the CAS application context via XML is not removed. There still exists a deployerConfigContext.xml that may be of assistance for truly special and customized needs and requirements. However, most everything is translated into auto-configuration modules with a specific set of externalized properties and settings that control behavior. So what do you do if you wanted to code an extension, or plug in a component/setting to modify behavior? The following options come to mind: Talk to the project. Discuss use cases and requirements, open up issues and better yet contribute patches and pull requests to see your change become a first-class feature of the CAS product rather than something you specially have to control, maintain, document, teach and then understand. If the use case you have in mind truly applies to your own specific workflows and integration strategies, your best option is to not try to find a way based on the old XML-based configuration model to shoehorn your changes into CAS. That will simply result into long-term disastrous results. Follow the same pattern discussed here. If you find anything that is missing or have suggestions for things that need to be improved or made conditional to make extensions easier, discuss those with the project and contribute back. Write the code where it belongs. If none of those options appeal to you, it’s likely that you may be heavily disappointed with the CAS software. So… I hope this brief tutorial was of some assistance to you. If you have other suggestions for content and material or have questions about this particular post here, please get in touch. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/02/21/cas-autocfg-strategy/"
  },

  
  
  
  {
    "title": "On The Theory of Possibility",
    "text": "If you are a member of an open source community and have been developing, designing and maintaining open source code for some time, it is very likely that from time to time you may encounter requests, comments and questions such as this: We are starting with our deployment of [insert-name]. One of our major requirements is that once the user logs into the application, a request via our own very special protocol is submitted to his/her automobile to schedule a job with the vehicle’s IOT system to start up the A/C in 8 hours. When the user finishes work in a typical 8-hour work day, he/she can very comfortably get back into the car that is prepped with an exact and very personalized degree of temperature for all seasons. We’d also like the timespan to be configurable. Oh, we also use Active Directory. So far, very cool. Exciting, rather. I wonder if we could also automatically submit an order to Pizza Hut to deliver a large Hawaiian pizza to the user’s residence. That would be sweet. The post follows: Is it possible? If not, are there plans to support this? I don’t know about you, dear reader, but I posit that there is virtually nothing in life that is impossible. My half serious reaction, in my head, usually is something along the lines of the following: Dear [insert-name], All things are possible in open source. 4000 hours. Regards, Some things, however, are improbable [1]. Misagh Moayyed [1]There is no such thing as a ‘plan’. Just a pending pull request.",
    "tags": "Blog",
    "url": "/2017/02/18/onthe-theoryof-possibility/"
  },

  
  
  
  {
    "title": "Design CAS-Enabled Custom Protocols",
    "text": "That’s right. If you enjoy designing your own authentication protocols, integration strategies and workflows and then face the requirement of letting your Apereo CAS deployment support them, you have come to the right place. This is a guide for you. Today, Apereo CAS presents itself as a multilingual platform supporting protocols such as CAS, SAML2, OAuth2 and OpenID Connect. There are even plans and projections to provide support for the necessary parts of the WS-* protocol stack. Support and functionality for each of these protocols continually improves per every iteration and release of the software thanks to excellent community feedback and adoption. While almost all such protocols are similar in nature and intention, they all have their own specific bindings, parameters, payload and security requirements. So, in order for you to understand how to add support for yet another protocol into CAS, it’s very important that you first begin to study and understand how existing protocols are supported in CAS. The strategy you follow and implement will most likely be very similar. It all starts with something rather trivial: The Bridge. Pay attention. This one actually does go somewhere. The Bridge If you have ever deployed the ShibCas AuthN plugin to bridge the gap between the Shibboleth IdP and Apereo CAS, then you are very familiar with this pattern. The plugin simply acts as a link between the two platforms, allowing authentication requests from the IdP to be routed “invisibly” to CAS and then back. It sits between the two platforms and knows how to translate one protocol (SAML) to another (CAS) and then does it all in reverse order on the trip back to the SAML service provider. This is a neat trick because to the SAML Service Provider, that fact that authentication from the IdP is delegated to somewhere else is entirely irrelevant and unimportant. Likewise, the IdP also does not care what external authentication system handles and honors that request. All it cares about is, “I routed the request to X. As long as X gives me back the right stuff, I should be fine to resume”. So the bridge for the most part is the “control tower” of the operation. It speaks both languages and protocols, and just like any decent translator, it knows about the quirks and specifics of each language and as such is able to dynamically translate the technical lingo. So far, so good. CAS Supported Protocols If you understand the above strategy, then you would be glad to learn that almost all protocols supported by CAS operate with the same exact intentions. A given CAS deployment is equipped with an embedded “plugin” that knows how to speak SAML2 and CAS, OAuth2 and CAS, or OpenID Connect and CAS or whatever. The right-hand side of that equation is always CAS when you consider, as an example, the following authentication flow with an OAuth2-enabled client application: The CAS deployment has turned on the OAuth2 plugin. An OAuth2 authorization request is submitted to the relevant CAS endpoint. The OAuth2 plugin verifies the request and translates it to a CAS authentication request! The authentication request is routed to the relevant CAS login endpoint. User authenticates and CAS routes the flow back to the OAuth2 plugin, having issued a service ticket for the plugin. The OAuth2 plugin attempts to validate that ticket to retrieve the necessary user profile and attributes. The OAuth2 plugin then proceeds to issue the right OAuth2 response by translating and transforming the profile and validated assertions into what the client application may need. Notes The right-hand side of the flow is always CAS, because the plugin always translates protocol requests into CAS requests. Another way of looking at it is that all protocol plugins and modules are themselves clients of the CAS server! They are issued service tickets and they proceed to validate them just like any other CAS-enabled client. Just like above, to the OAuth2-enabled client all such details are totally transparent and as long as “the right stuff” is produced back to the client, it shall not care. Advantages There are some internal technical and architectural advantages to this approach. Namely: The core of the CAS authentication engine, flow and components need not be modified at all. After all, we are just integrating yet another client even if it’s embedded directly in CAS itself. (If you recall and are familiar, the original Clearpass integration via authentication proxying worked in very similar terms). …and because of that, support for that protocol can be very easily removed, if needed. After all, protocols come and go every day. That’s why you’re reading this blog post, right?! …and because of that and just like any other CAS client, all features of the CAS server are readily available and translated to the relevant client removing the need to duplicate and re-create protocol-specific configuration as much as possible. Things like access strategies, attribute release, username providers, etc. Challenges This process is rather difficult to get right, because just like any other decent translator, you do have to learn and speak both languages just-in-time. The plugin module needs to be designed generically and with a reasonable degree of abstraction such that it can dynamically insert itself into the right core areas of CAS without getting too entangled in the internal architecture. Your Road to Fame So if you mean to build support for your very own authentication protocol, you’d do well to follow in the same footsteps. Take inspiration from the approach that current plugins and modules implement and design your own plugin that itself is the client of the CAS server hosting and housing it. Happy Designing. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/02/17/cas-custom-protocols/"
  },

  
  
  
  {
    "title": "Design Authentication Handlers in CAS 5.1.x",
    "text": "While authentication support in CAS for a variety of systems is somewhat comprehensive and complex, a common deployment use case is the task of designing custom authentication schemes. This post describes the necessary steps needed to design and register a custom authentication strategy (i.e. AuthenticationHandler) in CAS 5.1.x. Audience This post is intended for java developers with a basic-to-medium familiarity with Spring, Spring Boot and Spring Webflow. This is NOT a tutorial to be used verbatim via copy/paste. It is instead a recipe for developers to extend CAS based on specialized requirements. Steps The overall tasks may be categorized as such: Design the authentication handler Register the authentication handler with the CAS authentication engine. Tell CAS to recognize the registration record and authentication configuration. Step 1: Design Authentication Handlers First step is to define the skeleton for the authentication handler itself. This is the core principal component whose job is to declare support for a given type of credential only to then attempt validate it and produce a successful result. The core parent component from which all handlers extend is the AuthenticationHandler interface. With the assumption that the type of credentials used here deal with the traditional username and password, noted by the infamous UsernamePasswordCredential below, a more appropriate skeleton to define for a custom authentication handler may seem like the following: public class MyAuthenticationHandler extends AbstractUsernamePasswordAuthenticationHandler { ... protected HandlerResult authenticateUsernamePasswordInternal(final UsernamePasswordCredential credential, final String originalPassword) { if (everythingLooksGood()) { return createHandlerResult(credential, this.principalFactory.createPrincipal(username), null); } throw new FailedLoginException(\"Sorry, you are simply a big huge failure!\"); } ... } Review Authentication handlers have the ability to produce a fully resolved principal along with attributes. If you have the ability to retrieve attributes from the same place as the original user/principal account store, the final Principal object that is resolved here must then be able to carry all those attributes and claims inside it at construction time. The last parameter, null, is effectively a collection of warnings that is eventually worked into the authentication chain and conditionally shown to the user. Examples of such warnings include password status nearing an expiration date, etc. Authentication handlers also have the ability to block authentication by throwing a number of specific exceptions. A more common exception to throw back is FailedLoginException to note authentication failure. Other specific exceptions may be thrown to indicate abnormalities with the account status itself, such as AccountDisabledException. Various other components such as PrincipalNameTransformers, PasswordEncoders and such may also be injected into our handler if need be, though these are skipped for now in this post for simplicity. Step 2: Register Authentication Handlers Once the handler is designed, it needs to be registered with CAS and put into the authentication engine. This is done via the magic of @Configuration classes that are picked up automatically at runtime, per your approval, whose job is to understand how to dynamically modify the application context. So let’s design our own @Configuration class: package com.example.cas; @Configuration(\"MyAuthenticationEventExecutionPlanConfiguration\") @EnableConfigurationProperties(CasConfigurationProperties.class) public class MyAuthenticationEventExecutionPlanConfiguration implements AuthenticationEventExecutionPlanConfigurer { @Autowired private CasConfigurationProperties casProperties; @Bean public AuthenticationHandler myAuthenticationHandler() { final MyAuthenticationHandler handler = new MyAuthenticationHandler(); /* Configure the handler by invoking various setter methods. Note that you also have full access to the collection of resolved CAS settings. Note that each authentication handler may optionally qualify for an 'order` as well as a unique name. */ return h; } @Override public void configureAuthenticationExecutionPlan(final AuthenticationEventExecutionPlan plan) { if (feelingGoodOnASundayMorning()) { plan.registerAuthenticationHandler(myAuthenticationHandler()); } } } Step 3: Register Configuration Now that we have properly created and registered our handler with the CAS authentication machinery, we just need to ensure that CAS is able to pick up our special configuration. To do so, create a src/main/resources/META-INF/spring.factories file and reference the configuration class in it as such: org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.example.cas.MyAuthenticationEventExecutionPlanConfiguration Note that the configuration registration is not of CAS doing. It’s a mechanism provided to CAS via Spring Boot and it’s an efficient way to pick up and register components into the runtime application context without the additional overhead of component-scanning and such. Review At runtime, CAS will try to automatically detect all components and beans that advertise themselves as AuthenticationEventExecutionPlanConfigurers. Each detected AuthenticationEventExecutionPlanConfigurer is then invoked to register its own authentication execution plan. The result of this operation at the end will produce a ready-made collection of authentication handlers that are ready to be invoked by CAS in the given order defined, if any. What’s Next? CAS 5.1.0 is not released today in GA form. The development team is working to make sure the CAS 5.1.0 release is on schedule. Additional release candidates and more updates will likely be released prior to the official GA release. Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Review and suggest documentation improvements. Review the release schedule and make sure you report your desired feature requests on the project’s issue tracker. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2017/02/02/cas51-authn-handlers/"
  },

  
  
  
  {
    "title": "Guy walks into an Auto Shop",
    "text": "A true story inspired by real events. Seriously. Bryan Cranston has been approached for the role of the “Guy”. A guy walks into an auto shop, calls over a mechanic and says: Hey there! I have been trying to use my car for the past 3 days. It doesn’t work. Drives very badly. I remember taking it to a car wash and then a friend drove it around for a while. After that, it stopped working. Can you help? Sure. Do you have your car with you? I am afraid I don’t. No problem. Do you know the model and the year of the car? I am not sure I do. My attorney handles all of that. OK. What symptoms does it show? I guess it just makes this weird noise when I honk the horn. When was the last time you took it to the shop? Any previous diagnostics, issues, history of failures? It was a while ago. My son asked me to get it checked out years ago. I suppose he worries too much. Do you think his worrying might have anything to do with the car sluggish performance? No. OK. Well, I really appreciate any suggestions you might have. What are your thoughts? My thoughts? Yes. Well, I think The Piano Guys are terrific. You should check them out. Pardon me? Mechanic walks away. Camera slowly fades away into the horizon with smooth piano music playing in the background. Misagh Moayyed",
    "tags": "Blog",
    "url": "/2017/01/20/theart-of-mechanics/"
  },

  
  
  
  {
    "title": "MyUW in 2016",
    "text": "MyUW had a great 2016. This post summarizes some highlights. Edits: adjusted to reflect the new name uPortal app framework and new repository location for what was previously known as uw-frame adjusted to reflect the new name uPortal home and new repository location for what was previously known as AngularJS-portal Open source software products MyUW develops several free and open source products in the course of delivering MyUW. uPortal home MyUW shipped 20 releases of uPortal home in 2016. uPortal home is an alternative front end for uPortal. Progress included: fixed accessibility bugs proved out multi-tenant support (as implemented in MyUW, this software serves each of the University of Wisconsin campuses) proved out unauthenticated experience support (this software delivers the public.my.wisc.edu experience) adopted Material Design redesigned search and header enhanced notifications and announcements detected and proactively handled expired sessions added more and better widget templates (search with links, RSS) eased adoption via overlay documented uPortal app framework MyUW shipped 22 releases of uPortal app framework in 2016, from version 2.0.1 to 3.0.3. uPortal app framework is the framework in which we develop uPortal home. uPortal app framework is also the framework in which we and other groups in the University of Wisconsin develop applications for inclusion in the portal. Writing a frame-based app is conceptually an alternative to writing a Java Portlet. adopted Material Design improved theme support handled session timeouts proactively cleaned up the way uPortal app framework is adopted in frame-based apps sourced dependencies from CDNs microservices The MyUW team shipped eight releases of a growing slate of supporting microservices in 2016. KeyValueStore lti-proxy rest-proxy rssToJson token-crypt We also participated directly in the development or release engineering of four Apereo WebProxy Portlet releases in 2016. MyUW services We develop these and other software products in order to operate them in the MyUW portal. MyUW delivered around 10,000,000 user sessions in the course of serving UW-Madison and the entire University of Wisconsin system in 2016. MyUW eases discovery of and navigation to other systems. In 2016, users followed a link in MyUW out to something outside MyUW more than 8,000,000 times. Besides helping users navigate to other applications, MyUW helps users understand what they need to do and where they might need to navigate. MyUW presented its full notifications experience (not just the indicator that the user has a notification) around 100,000 times in 2016. Not all MyUW content relevant to all users can fit on default home pages, so MyUW supports users searching and browsing the available content. MyUW presented the directory of applications around 100,000 times and provided search results in around 100,000 user sessions in 2016. Once you’ve searched or browsed to something interesting, you can add it to your home page. Users modified their home pages almost one hundred thousand times in 2016, including adding the new Wiscard Balance widget almost 6,000 times. Looking forward Let’s do more to serve the portal needs of higher education and the University of Wisconsin in 2017. Andrew Petro PS: Other ways to consume this content: on Apereo website (Alas, no hyperlinks). in January 2017 newsletter as posted to announcements email list (Alas, no hyperlinks). in January 2017 newsletter as posted in a Word doc (Alas, no hyperlinks).",
    "tags": "uPortal",
    "url": "/2017/01/19/myuw-2016/"
  },

  
  
  
  {
    "title": "CAS 5.1.0 RC1 Feature Release",
    "text": "The official CAS 5.0.0 GA was released about 6 weeks ago. Since then, the project has been moving forward with development of the next feature release that is tagged as 5.1.0. This post intends to highlight some of the improvements and enhancements packed into the first release candidate in the 5.1.0 series. The in-development documentation of CAS 5.1.0 is available here. The release schedule is also available here. The release policy is available here. Log Levels via CAS Properties Name Authentication Handlers JWS/JWE Compression Security Filters Enabled by Default CORS Security Filter Database AuthN BCrypt Encoder Duration as Unit of Measure Risk-Based Authentication AuthN Events in Audit Log Duo Security Account Checking Duo Security Multiple Configurations [1] Embedded Container Version Redis Ticket Registry Code Cleanup and Optimization Registered Service Legacy Definitions LDAP Search Filter Parametrization LDAP Connection Strategies MongoDb Authentication: Password Encoding Service Registry Performance LDAP Principal Attributes Merged with Attribute Repositories Internal Auto Configuration [1] Multiple Attribute Repositories [1] Attribute Repositories Order Service UI Info on Login Screen SAML2 ECP SAML2 InCommon Metadata SAML2/OAuth/OIDC Multifactor Authentication SAML2 IdP Metadata Signature Validation SAML2 IdP Metadata Location URI Service Registry JSON Auto-Init Embedded Container HTTP2 Support Internet2 Grouper MFA Trigger REST API Performance LDAP Validator Configuration Logging Panel Improved Hazelcast Configuration SAML2 IdP Handling of RelayState JSON Enhancements to CAS APIs Multifactor Authentication Bypass Per Service OIDC Delegated AuthN Scope LinkedIn Delegated AuthN Management Webapp Authorization Roles [1] OIDC Dynamic Client Registration JWTs as Service Tickets Delegated AuthN Auto Redirect Library Upgrades What’s Next? Get Involved Das Ende Log Levels via CAS Properties The configuration of CAS logging levels is traditionally done directly inside the log4j2.xml file. As an easier option and thanks to Spring Boot, log levels may also be specified via the normal CAS properties: logging.level.org.springframework.web=DEBUG logging.level.org.apereo.cas=DEBUG Name Authentication Handlers Additional CAS properties are exposed for all authentication handlers so they can individually be named. By default, handler names are set to the name of the defining Java class. Given the class name might change, it’s preferred if each adopter defines unique/custom names for each scheme. You generally do NOT have to worry about this behavior at all; It’s only relevant if you, for instance, have defined multifactor authentication bypass rules based on authentication handler names. JWS/JWE Compression CAS ciphers that deal with signing/encryption based on JWEs are now by default configured to force compression via the zip claim. Security Filters Enabled by Default CAS has long had options to enforce a number of request headers to enable XSS/HSTS/etc protection. These filters are turned on by default, starting from this release candidate. CORS Security Filter Much like the above option, CAS adds support for enabling a CORS filter that should help more with CAS enabled applications which are accessed via XHR/Ajax requests. This filter is off by default and needs to be explicitly configured by the adopter. Database AuthN BCrypt Encoder Thanks to community contributions, minor changes are made to the internal CAS authentication API to ensure password encoding can execute correctly specially when the BCrypt encoder is defined. Duration as Unit of Measure Thanks to community contributions, all CAS settings that deal with time units should start to support the duration syntax for full clarity on unit of measure: \"PT20S\" -- parses as \"20 seconds\" \"PT15M\" -- parses as \"15 minutes\" \"PT10H\" -- parses as \"10 hours\" \"P2D\" -- parses as \"2 days\" \"P2DT3H4M\" -- parses as \"2 days, 3 hours and 4 minutes\" Risk-Based Authentication CAS is able to track and examine authentication requests for suspicious behavior. Risk-based authentication allows CAS to detect suspicious and seemingly-fraudulent authentication requests based on past user behavior and collected authentication events, statistics, etc. Once and after primary authentication where the principal is identified, the authentication transaction is analyzed via a number of configurable criteria and fences to determine how risky the attempt may be. The result of the evaluation step is a cumulative risk score that is then weighed against a risk threshold set by the CAS operator. In the event that the authentication attempt is considered risky well beyond the risk threshold, CAS may be allowed to take action and mitigate that risk. You can learn more about this feature here. At this point, the changeset and accompanying modules are fairly experimental and are going through rounds of testing and patching. If this functionality interests you, by all means give it a trial run and share feedback as much as possible. AuthN Events in Audit Log CAS events are now routed to the CAS audit logs. This allows one, for instance, to learn when an MFA event is triggered and to note if MFA was successfully honored and executed: ============================================================= WHO: audit:unknown WHAT: [event=mfa-duo,timestamp=Mon Nov 14 12:01:17 MST 2016,source=RankedAuthenticationProviderWebflowEventResolver] ACTION: AUTHENTICATION_EVENT_TRIGGERED APPLICATION: CAS WHEN: Mon Nov 14 12:01:17 MST 2016 CLIENT IP ADDRESS: 110.5.75.1 SERVER IP ADDRESS: 110.2.75.1 ============================================================= Duo Security Account Checking Presently, if users are unregistered with Duo Security or allowed through via a direct bypass, CAS puts the user through multifactor authentication and simply validates the response internally and somewhat invisibly, allowing the application to receive an authentication context that indicates multifactor authentication did actually commence. In this release, CAS starts to query the user account apriori to learn whether user is registered or configured for direct bypass. If the account status matches either of those conditions or the user account is not registered yet the new-user enrollment policy allows folks to skip registration, CAS will bypass Duo Security altogether and will NOT report back a multifactor-enabled authentication context back to the application. Duo Security Multiple Configurations [1] CAS is now able to support different configuration blocks for multiple Duo Security instances: # cas.authn.mfa.duo[0].duoSecretKey= # cas.authn.mfa.duo[0].duoApplicationKey= # cas.authn.mfa.duo[0].duoIntegrationKey= # cas.authn.mfa.duo[0].duoApiHost= # cas.authn.mfa.duo[0].id=mfa-duo ... # cas.authn.mfa.duo[1].duoSecretKey= # cas.authn.mfa.duo[1].duoApplicationKey= # cas.authn.mfa.duo[1].duoIntegrationKey= # cas.authn.mfa.duo[1].duoApiHost= # cas.authn.mfa.duo[1].id=mfa-second-duo ... By default, a Duo Security provider in CAS is registered under mfa-duo noted by the above id. However, additional providers can now be registered with arbitrary identifiers. All MFA triggers shall function exactly as before and as long as they are configured to produce the right match for the right provider id, CAS will activate MFA for the Duo Security configuration that is linked to the selected identifier. At this point in time, Duo Security is the only provider in CAS whose configuration can be specified in blocks. However, [and this turned out to be a VERY non-trivial task], adjustments are made internally to ensure other providers can be configured in much the same way should there be demands. Embedded Container Version The embedded container version now shows up in the CAS banner on startup: CAS Version: 5.1.0-SNAPSHOT ... Container Version: Apache Tomcat/8.5.x Redis Ticket Registry Thanks to community contributions, CAS gains support for Redis as a storage machenism for its ticket registry backend. Redis is an open source in-memory data structure store, used as a database, cache and message broker. You can learn more about the registry behavior via this guide. Code Cleanup and Optimization Thanks to community contributions, the CAS codebase is revitalized ever more to make sure most if not all underlying components adhere to proper coding standards and design practices. Changes in this area include adjustments to style guidelines, constructor-based dependency injections and navigating from Guava Collections to the native Java 8 Collections/Lambda APIs. Registered Service Legacy Definitions Thanks to community contributions, CAS’ handling of legacy service registry definitions that are backed by JSON are now slightly improved to preserve backwards compatibility with prior CAS versions whose service definition was based on the old org.jasig namespace. LDAP Search Filter Parametrization A number of LDAP search filters for SPNEGO and attribute repository configurations are relaxed to be more consistent with other parameter names via supporting both {user} and {0} for both named and index parameter values. LDAP Connection Strategies Additional configuration options are now made available to allow users to define a connection strategy of their own choosing, should multiple LDAP urls be specified in the configuration. MongoDb Authentication: Password Encoding Minor bug fix; Improper construction of password encoders caused MongoDb authentication attempts to reject all user credentials, failing to apply proper hashing/encoding on the password for validation. This should now be fixed. Service Registry Performance Thanks to community contributions, there have been a number of performance improvement applied to the way CAS saves, updates and locates services internally. Likewise, improvements are applied to the way CAS services handle regex pattern matching when responding to requests. LDAP Principal Attributes Merged with Attribute Repositories LDAP authentication in CAS can be made to directly resolve attributes without involving external attribute repositories via Person Directory. While simple, this isn’t always the use case. For instance, if there is ever a requirement to additionally resolve attributes from a JDBC source, the adopter is to abandon attribute resolution directly as part of LDAP authentication and is then forced to define a separate LDAP attribute repository source alongside a JDBC source so the final result from both can be merged. This is now improved such that attributes retrieved as part of LDAP authentication are now merged with all other attributes retrieved from attribute repository sources, if any. Internal Auto Configuration [1] CAS 5 took the auto-configuration strategy to the next level, thanks to Spring Boot and Spring Cloud. The approach was to component-scan the application context under org.apereo.cas and load components and beans that were declared via the housing @Configurations. In this release, CAS entirely turns off component scanning and switches to Spring Boot’s auto-configure style. The strategy is more or less the same where @Configuration classes still register CAS components as @Beans. The difference is that each CAS module provides a spring.factories file in which configuration classes and application context initializers are placed. This strategy allows CAS to exactly control the set of configurations that are loaded very explicitly for each mdule and also helps with deterministic load behavior where configurations for instance can register themselves to be loaded before or after a particular component to accommodate runtime behavioral dependencies. This may partially help with start-up times as well when CAS is run via the embedded container, but so far tests show that performance more or less remains the same. Note that while this isn’t generally something that the average adopter needs to worry about, this is nonetheless a breaking change IIF you have designed Java components/classes that are auto-scanned under org.apereo.cas. Those will NO LONGER be picked up by CAS automatically and you will need to either manually register them as CAS does via your own spring.factories or set up a auto-scanning configuration under your own package names via @ComponentScan, etc. Multiple Attribute Repositories [1] Attribute repository sources that are controlled and managed via Person Directory have now turned into lists. This allows you to create more than one source if necessary and then have all sources be merged into a single repository automatically to resolve CAS principals and attributes. # cas.authn.attributeRepository.ldap[0].ldapUrl=ldaps://ldap1.example.edu,... ... # cas.authn.attributeRepository.ldap[1].ldapUrl=ldaps://ldap2.example.edu,... ... Attribute Repositories Order You have to consider that when you have more than one attribute repository source defined, there may be cases where two sources end up colliding as they both may produce the same attribute. In such cases, CAS already provides capabilities to merge the final result and take action to either add, replace or ignore subsequent attempts at producing an attribute, if one already is found and fixed. This becomes important as it directly impacts the execution order of sources. For instance, consider that you have sources S1 and S2 defined both of which are configured to produce an attribute A1. Policies are configured to note that if A1 is already found via one source, no other source should attempt to overwrite it. The question then really becomes: which source should execute and query for data first? To handle this, CAS allows you to order attribute repositories. Those with a lower order execute first and take priority in querying for attributes: # cas.authn.attributeRepository.ldap[0].ldapUrl=ldaps://ldap1.example.edu,... # cas.authn.attributeRepository.ldap[0].order=1 ... # cas.authn.attributeRepository.ldap[1].ldapUrl=ldaps://ldap2.example.edu,... # cas.authn.attributeRepository.ldap[1].order=10 ... Service UI Info on Login Screen In situations where CAS ends up playing proxy behind a protocol such as SAML2, OAuth or OIDC, the login screen wrongly displayed the UI metadata (i.e. logo, description, etc) about the proxying (callback) service. This is now corrected so relevant UI information about the real service/destination is displayed on the screen per the SAML metadata or the CAS service registry. SAML2 ECP CAS starts to support a rather modest implementation of the SAML2 ECP profile. At this point, the changeset and accompanying modules are fairly experimental and are going through rounds of testing and patching. If this functionality interests you, by all means give it a trial run and share feedback as much as possible. SAML2 InCommon Metadata A number of improvements are applied to the way CAS handles the retrieval and resolution of large SAML metadata files that are downloaded over the web. The download strategy is now handled over a multi-part multi-threaded connection which should boost performance and startup times quite a bit. InCommon SPs are now supported directly via the usual CAS configuration settings, while in the past adopters expicitly had to register InCommon in the CAS service registry. SAML2/OAuth/OIDC Multifactor Authentication CAS triggers for multifactor authentication have all been reorganized in much the same way as the above item to ensure that authentication requests via SAML2, OAuth or OpenID Connect may all go through multifactor authentication based on the real service and not the proxying (callback) url. SAML2 IdP Metadata Signature Validation Metadata signature validation can now be done both via public keys and certificate files. SAML2 IdP Metadata Location URI A trivial bug fix; the location of the metadata for CAS’ SAML2 IdP functionality can now be specified in URI format as well. (i.e. file://etc/cas/somewhere) Service Registry JSON Auto-Init Service registries can now take advantage of the auto-initialization feature in a more direct manner. The previous behavior only populated a given registry if it was left empty by the adopter. However, in certain cases CAS modules auto-insert service definitions into the registry and interfere with this auto-initialization behavior. This is now corrected to ensure the service registry, if permitted, can forcefully be populated regardless of size while gracefully ignoring duplicate entries that may already be present. Embedded Container HTTP2 Support The embedded container is now configured to automatically upgrade the protocol and support HTTP2. Note that activation of this feature for an external Apache Tomcat instance requires Apache Tomcat 8.5.6 or above. Internet2 Grouper MFA Trigger As an extra option, CAS can now integrate with Grouper and use a subject [CAS principal] groups’ to learn whether MFA should be triggered. As an example, you could devise a use case where all subjects who are assigned to an mfa-duo groups may be asked to execute MFA via Duo Security. If you have deployed Grouper, this may be a much more immediate option than to pick up changes based on a given principal attribute once after provisioning has had a chance to process. REST API Performance Thanks to community contributions, improvements have gone into the implementation of CAS REST APIs to ensure best coding practices are in-place, performance-wise. LDAP Validator Configuration Additional properties are now exposed to allow configuration of LDAP validators for ALL operations that deal with LDAP functionality. CAS supports both SEARCH and COMPARE modes. Logging Panel CAS provides an administrative screen to manage and review logs. This screen is now improved to allow one to update logger levels immediately from the UI and observe better CAS diagnostics data. Note that at present, changes applied to the configuration UI are only persisted in memory since the underlying framework does not yet provide a way to save changes back out to disk, etc. This means, once you restart the CAS server node all changes applied to logs via the configuration panel are lost. Improved Hazelcast Configuration Minor adjustments are made to the Hazelcast configuration to stop using deprecated settings for internal eviction policies. SAML2 IdP Handling of RelayState Thanks to community contributions, the SAML2 functionality of CAS is now able to properly retain the RelayState parameter. JSON Enhancements to CAS APIs Thanks to community contributions, CAS APIs are now slightly massaged to handle JSON serialization of core ticketing components. This is useful for ticket registry implementations that are based on NoSQL databases such as Apache Cassandra, which as a pending pull request may also soon become a first-class CAS ticket registry feature. Multifactor Authentication Bypass Per Service In this release CAS starts to provide options to selectively exclude a set of applications from multifactor authentication. This is useful in cases where you have turned on multifactor authentication globally. A number of other bugs also in this area have been fixed to ensure handler/authentication attribute names can correctly be defined to bypass multifactor authentication. OIDC Delegated AuthN Scope Having upgraded to early snapshots of Pac4J, additional CAS configurtion options are now made available to allow for providing scope when delegating authentication to an external OIDC provider. LinkedIn Delegated AuthN Thanks to the early Pac4J upgrade, CAS now starts to support delegating authentication to LinkedIn in addition to a variety of other social providers. Management Webapp Authorization Roles [1] The authorization roles for the management webapp and the administrative user interfaces are now modified to allow distinct roles for access without the need for extra data parsing: # cas.adminPagesSecurity.adminRoles[0]=ROLE_ADMIN ... # cas.mgmt.adminRoles[0]=ROLE_ADMIN # cas.mgmt.adminRoles[1]=ROLE_SUPER_USER OIDC Dynamic Client Registration OpenId Connect in CAS is now starting to support modest implementations of the dynamic client registration protocol. JWTs as Service Tickets Starting with this release candidate, CAS gains the ability to issue JWTs as service tickets. JWTs are entirely self-contained and include enough information about the authenticated principal and available claims for given application integration. Delegated AuthN Auto Redirect In the event that you have configured CAS to delegate authentication to an external [social] identity provider, options are now made available to automatically redirect the authentication flow to the provider bypassing the CAS login screen. This option today is only relevant and active if there is a single provider available. Library Upgrades Spring Spring Boot Spring Cloud Spring Security Thymeleaf Commons Lang Guava Pac4J Ldaptive MongoDb OpenSAML FindBugs Checkstyle Joda Time Couchbase Hibernate MySQL, MaridaDb and PostgreSQL Drivers Kryo What’s Next? The development team is working to make sure the CAS 5.1.0 release is on schedule. Additional release candidates and more updates will likely be released prior to the official GA release. Get Involved Start your CAS deployment today. Try out features and share feedback. Better yet, contribute patches. Review and suggest documentation improvements. Review the release schedule and make sure you report your desired feature requests on the project’s issue tracker. Das Ende A big hearty thanks to all who participated in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed [1] This is a breaking configuration change. Please consult the CAS docs to learn more.",
    "tags": "CAS Releases",
    "url": "/2016/12/23/51rc1/"
  },

  
  
  
  {
    "title": "uPortal 2016-11-14 Webproxy Portlet caching vulnerability",
    "text": "This is a public disclosure of a security vulnerability, near the tail end of applying the uPortal Security Incident Response Plan to this issue. Affected software products: Webproxy Portlet , versions 2.0.0 through 2.2.1 . 2.2.2 includes a fix. Recent uPortal versions ship with bugged Webproxy Portlet versions. Problem: Affected versions By default, cache proxied content, and Require a source code edit to turn off this default behavior, and Improperly compute the cache keys such that in some cases too little information is considered in computing cache keys. Consequence: Most adopters will not have locally turned off this caching strategy even if it is inappropriate for local usages, and Usages where different users proxy the same backing URL may yield improper cross-user cache hits, with user B seeing content proxied for user A. Saving graces: For security purposes, this only matters if the proxies are interesting, providing personalized content. Usages with unique URLs, such as where user attributes are conveyed as request parameters in the URL or the initial request in a typical Proxy CAS integration, will not yield improper cache hits. Solutions: Upgrade to Webproxy Portlet version 2.2.2 or later. Locally modify your Webproxy Portlet 2 implementation to turn off caching, by de-activating or removing CachingHttpContentServiceImpl and instead activating HttpContentServiceImpl. -Andrew",
    "tags": "uPortal",
    "url": "/2016/11/14/web-proxy-overcaching/"
  },

  
  
  
  {
    "title": "MyUW 2016-10-25 release",
    "text": "Today MyUW promoted a new release to production. This post highlights some aspects of this. Edits: Updated to reflect new name uPortal home and new git repository location for what was once called AngularJS-portal This release This release upgraded MyUW to uPortal home v5.4.1 from v5.2.4. Highlights for Apereo community Continued implementation of Material Design. Piggybacking on Google’s Material Design in higher education web applications is an opportunity to raise the baseline for design and consistency without having to invent and maintain that design guidance using scarce higher education resources. To the extent feasible, we’re trying to use MyUW design resources on unique-to-MyUW design problems rather than on web-application-general design problems. Also, Material Design theming is rocking the skinning problem, supporting different color treatments across the many Wisconsin system campuses MyUW serves. Continued development of lightweight notifications technology. Notifications now have optional associated actions and more options for priority treatment and end-user option to dismiss unneeded notifications. Lessons to learn Semantic versioning is important. We had a hiccup in this release because a rest-proxy change wasn’t backwards-compatible as regards endpoints.properties. In retrospect, the properties file configuring this product is its API so breaking changes would be better signaled with a MAJOR version change (and avoided when not strictly necessary). Deep linking is important, enabling better communication about and leverage of content in your portal. This release fixed support for deep links into uPortal home content. Calls to action Talk about what you are doing. It is only possible to discover opportunities to collaborate, to share code, to compare notes on the practices of portals in higher education if we talk about what we are doing. Adopt and collaborate on microservices. You don’t have to adopt everything MyUW has adopted to find something that would add value to your local projects. KeyValueStore rest-proxy Token Crypt : A project that can encrypt/decrypt tokens and files using public/private key pairs. Likewise, maybe you’ve got some microservice projects and products we could be collaborating on if we knew about them. Adopt uPortal home. uPortal home is a modern user experience layer to plop down in front of your uPortal. You don’t have to adopt it all at once, for everyone, for every user experience in your portal. MyUW variously implemented it as opt-in, opt-out, at certain hostnames, for certain identities, for certain experiences within MyUW. It’s been a long walk using the new technology for more and more experiences, and we’re still using the traditional uPortal rendering pipeline to render some maximized portlet user experiences. uPortal home is engineered to be flexible because it had to be. You don’t have to stay stuck on AngularJS 1. We too want to migrate forward to AngularJS2, when time and technology allow. Andrew Petro",
    "tags": "uPortal Releases",
    "url": "/2016/10/25/myuw-release/"
  },

  
  
  
  {
    "title": "CAS Vulnerability Disclosure",
    "text": "Overview This is the public version of an Apereo CAS project vulnerability disclosure, describing an issue in CAS where an adversary may be able to bypass certain administrative endpoints, in spite of CAS access rule in place. The following administrative endpoints are exposed and vulnerable to this attack: /statistics/ping /statistics/threads /statistics/metrics /statistics/healthcheck /statistics/ssosessions and all sub endpoints Affected Deployments The attack vector specifically applies to all deployments of CAS v4.2.x deployments. If you have deployed any version of CAS 4.2.x, you MUST take action to upgrade. If you have deployed any other versions of CAS, disregard this announcement. Severity This is a serious issue where successfully exercising this vulnerability allows the adversary gain insight into the running CAS software, collect running threads, DOS the server repeatedly via pings and potentially observe the collection of active SSO sessions and meddle with user single sign-on activity. Patching Patch releases are available to address CAS v4.2.x deployments. Upgrades to the next patch version for each release should be a drop-in replacement. The patch simply ensures that the exposed endpoints honor the CAS access rules, and otherwise block attempts. When you have applied the patch, please double check all endpoints and ensure access is appropriately controlled. Timeline The issue was originally reported to the CAS application security team on September 27, 2016. Upon confirmation, CAS was patched on September 28, 2016 and released. The original release announcement is available here. Procedure Modify your CAS overlay to point to version 4.2.6. A snippet of a pom.xml for a CAS overlay follows: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.jasig.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;cas.version&gt;4.2.6&lt;/cas.version&gt; &lt;/properties&gt; Double check your cas.properties file for the following setting: # cas.securityContext.adminpages.ip=127\\.0\\.0\\.1 Make sure the correct IP pattern is authorized to access admin pages. Alternatives If you are unable to apply the patch, it’s then best to ensure the outlined endpoints are blocked completely via load balancers, proxies, firewalls, etc. Support If you have questions on the details this vulnerability and how it might be reproduced, please contact security@apereo.org or cas-appsec-public@apereo.org. Resources Original Announcement CAS Security Vulnerability Response Model",
    "tags": "CAS",
    "url": "/2016/10/24/servlvulndisc/"
  },

  
  
  
  {
    "title": "Activating MFA in CAS 5",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Perhaps one of the more attractive features of CAS 5 is the ability to support multifactor authentication via a number of providers/vendors that can be triggered in many ways. While support for triggers may seem extensive, there is always that edge use case that would have you trigger MFA based on a special set of requirements. Here is what you can do. Audience This post is intended for java developers with a basic-to-medium familiarity with Spring, Spring Boot and Spring Webflow. This is NOT a tutorial to be used verbatim via copy/paste. It is instead a recipe for developers to extend CAS based on specialized requirements. Stop Coding Hearken to the reed flute, how it complains, lamenting its banishment from its home: “Ever since they tore me from my osier bed, my plaintive notes have moved men and women to tears. I burst my breast, striving to give vent to sighs, and to express the pangs of my yearning for my home. He who abides far away from his home is ever longing for the day he shall return. [The Reed Flute’s Song, Rumi, 1207-1273] Before diving into code, I MUST emphasize that developing custom extensions/addons, while certainly keeewl and exciting, would eventually lead to long-term maintenance/upgrade burdens. Consider direct contributions to the project if/when feasible and solve the problem where it needs solving. If you are going to write code, you might as well write it where it belongs. Requirements You will need to have compile-time access to the following modules: org.apereo.cas:cas-server-core-webflow org.apereo.cas:cas-server-core-web These are modules that ship with CAS by default and thou shall mark them with a compile or provided scope in your build configuration. Create MFA Triggers You should create an event resolver that houses and implements your special requirements for MFA. A typical example might be: Activate MFA provider mfa-duo if the request client IP address matches the pattern 123.+ package org.apereo.cas.custom.mfa; public class CustomWebflowEventResolver extends AbstractCasWebflowEventResolver { @Autowired private CasConfigurationProperties casProperties; @Override protected Set&lt;Event&gt; resolveInternal(final RequestContext context) { final RegisteredService service = WebUtils.getRegisteredService(context); final Authentication authentication = WebUtils.getAuthentication(context); final HttpServletRequest request = WebUtils.getHttpServletRequest(context); final Map&lt;String, MultifactorAuthenticationProvider&gt; providerMap = WebUtils.getAllMultifactorAuthenticationProviders(this.applicationContext); // Somehow, select a provider based on the above map... final MultifactorAuthenticationProvider provider = ... if (areWeDoingMfa()) { final Event event = validateEventIdForMatchingTransitionInContext(provider.getId(), context, buildEventAttributeMap(authentication.getPrincipal(), service, provider))); return ImmutableSet.of(event); } logger.warn(\"Not doing MFA, sorry.\"); return null; } } Note that you have full access to the resolved CAS authentication, the principal associated with it, the service requesting authentication as well as the original web request. You also have access to the full body of CAS configuration settings, should you need to externalize values. Register MFA Triggers Your trigger then needs to be registered. We do this via CAS’ native auto-configuration strategy, which scans the application context for relevant annotations inside org.apereo.cas sub-packages. If you change package names, you MUST account for the custom context scan too. package org.apereo.cas.custom.config; @Configuration(\"SomethingConfiguration\") public class SomethingConfiguration { @Autowired @Qualifier(\"initialAuthenticationAttemptWebflowEventResolver\") private CasDelegatingWebflowEventResolver initialEventResolver; @RefreshScope @Bean public CasWebflowEventResolver customWebflowEventResolver() { return new CustomWebflowEventResolver(); } @PostConstruct public void initialize() { initialEventResolver.addDelegate(customWebflowEventResolver()); } } We simply register our trigger as a Spring @Bean and add it to the chain of event resolvers that kick into action as part of CAS authentication machinery. So… Note that: You are really not doing anything custom. All CAS triggers behave in the same exact way when they attempt to resolve the next event. The API is completely oblivious to multifactor authentication; all it cares about is finding the next event in the chain in a very generic way. Our custom implementation of course makes the next event be concerned about MFA but in theory we could have resolved the next event to be hello-world and CAS would not have cared. Happy Coding! Misagh Moayyed",
    "tags": "CAS MFA",
    "url": "/2016/10/19/mfacas5-extcfg/"
  },

  
  
  
  {
    "title": "Bootiful CAS 5 Overlay",
    "text": "Overview As you may know, the recommended strategy to start a CAS deployment today is via the WAR Overlay Installation Method. The idea is that a deployment gets to keep only local customizations and inherits everything else from a pre-built pre-configured instance. Not only this allows one to keep track of intentional changes, but also makes it easier to upgrade the software in place by simply bumping the CAS version in the overlay script. CAS 5 itself is entirely based on Spring Boot. Today, CAS 5 overlays for both Maven and Gradle too are modified to accommodate easier deployment options via Spring Boot. Here’s how. Bootiful Overlay Today, adopters are given 3 choices to deploy an overlay: Run the CAS web application as an executable WAR via a java -jar &lt;cas-war-file&gt; type of command. Deploy the &lt;cas-war-file&gt; into an external container of choice, such as Apache Tomcat. [NEW] Run the CAS web application as an executable WAR via the Spring Boot’s Maven/Gradle plugin, though you may be interested in this issue. The 3rd option is similar to the native java -jar ... command with the main difference that the Spring Boot plugin is able to recognize the presence of Spring Boot’s devtools that is shipped with CAS by default and allows for ad-hoc live monitoring of CAS resources. This is specially helpful perhaps during UI design; such that you could keep modifying html, css, and js resources and CAS will auto-detect changes and allows you to see them via a simple refresh of your browser. Lots quicker! Misagh Moayyed",
    "tags": "CAS",
    "url": "/2016/10/04/casbootoverlay/"
  },

  
  
  
  {
    "title": "CAS 5.0.0-RC3 Released",
    "text": "We are excited to announce the 3rd release candidate in the CAS 5 series. There are a few items packed into this release that are worthy to publicize. So here it goes. Before we get started, it should be pointed out that releases of CAS 5 are available to adopters to try. Deployers are more than welcome to try out the milestone releases and share feedback. The current in-development documentation of CAS 5 is also available here. MFA A series of patches have been applied to address issues related to multi-factor authentication: Activating MFA based on multi-valued principal attributes Activating MFA for non-interactive authentication flows such as SPNEGO Password Management The CAS self-service password management functionality is patched to better report back password policy requirements on the screen, and changes have gone in to ensure password updates can successfully be executed against Active Directory. Delegated AuthN Summary of fixes are: Better reporting of authentication failures in case a provider (i.e. Facebook) denies user access. Better management of locating resources through CAS properties, specially when dealing with delegated SAML AuthN. Admin UIs Some adjustments have been made to the way admin user interfaces are protected via CAS itself. A few additional screens have also been worked into the interface to display the CAS audit log as well as a list of trusted devices/browsers registered for MFA bypass. CAS Attributes Additional validation checks are now in place to ensure CAS attributes are properly formatted, encoded and named in the final validation response. For instance, CAS is now able to detect the proper syntax if it’s configured to release an attribute that is system:people:admins:something. Groovy-based Attributes When it comes to mapping attributes conditionally at release time, CAS is now able to correctly and more accurately support groovy-based attribute definitions, whether inline or as a full standalone groovy script file. JWT AuthN Thanks to Pac4J, a number of fixes have gone in to ensure JWTs can successfully be validated based on customizable encryption and signing algorithms, which can now be specified for a given CAS service definition. Additional checks are also in place to report on the validity of the JWT itself and its required fields such as the sub. Dependency Upgrades We have taken a pass at the core CAS dependencies to ensure we are running on the latest stable component releases, some of which include: Spring Core Spring Boot Spring Cloud Thymeleaf Pac4J Tomcat Hazelcast …and plenty more. What’s Next? Short of a few more last rounds to ensure everything is tested as much as possible, we should be gearing up for the official GA release shortly. The release schedule will likely be adjusted to note the correct final release date, and when all is said and done, there will be planning sessions to discuss the project roadmap for the next upcoming release. Yes, there is plenty of more work left to do! How can you help? Do NOT wait for the final GA release to begin your deployment. If you do discover a problem after the GA is out, it may be a while for you to receive the next upgrade with the fix in place. Now is the best time to start trying out the release candidates and report back findings. The software is only as stable and bug-free as it is reported back to the community. So: Start your early CAS 5 deployment today. Try out features and share feedback. Better yet, contribute patches. Review and suggest documentation improvements. Review the release schedule and make sure you report your desired feature requests on the project’s issue tracker. Das Ende A big hearty thanks to all who participated in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2016/10/01/cas5rc3-release/"
  },

  
  
  
  {
    "title": "Singing “I Love Bug Reports”",
    "text": "Having been involved in the open-source space for some time, I have noticed that various communities and software engineers react differently to bug reports and issue submissions. Some tend to discuss issues and shortcomings of the software in private as developers may consider those defects cause for embarrassment and failure! Some tend to disregard issues and close the conversation loop immediately, routing the user to other appropriate channels and reemphasizing a this is not a bug mentality without any sort of user education or guidance. Some welcome bug reports in all shapes and sizes and consider those an acknowledgement and positive feedback even when/if the underlying reported problem turns out to be moot. Here is my personal recipe. If you are about to submit a bug Data, Data, Data Always ensure you have enough diagnostics data in your report. Are you reporting the exact version numbers that exhibit the seemingly-faulty behavior? Have you described your deployment/development environment in enough detail? Have you included error logs, screenshots and other useful snippets of your configuration to demonstrate the issue? Have you included steps to explain how one might duplicate the problem? Unit tests to recreate the issue? Put another way; readers of your case aren’t necessarily housed in your head! They don’t know what you know. Help them out. Would you want to respond to your own report? Think about that before you press submit. Is this a bug? Research the issue and be sure to do your due diligence. Have you scanned the web archives for similar cases? Have you looked at the project’s documentation to find better explanations? Have you reviewed the project’s mailing lists, chatrooms and other facilities to find possible solutions? Should I submit? Some projects consider their issue tracking system as a placeholder to track genuine traceable issues and tasks. If you have a general question about the workings of the software, or if you’re unsure how something is supposed to work and are in need of an analysis and further discussion, consider choosing alternative vessels for contact. Use mailing lists, chatrooms, Stackoverflow and other similar tools to engage with the project owners. When the dust has settled and you have arrived at a legitimate theory to explain the root cause of the problem, file a submission. Be part of the solution If you can, always volunteer to post a patch and work up a solution. Be prepared to follow up to test the produced patch in your environment and always try to provide a confirmation. Simply complaining about something and letting it sit in the issue tracker for someone else to handle isn’t going to get you much. If you find something that you deem worth someone else’s time to fix for you, be sure to demonstrate the issue is first and foremost worth your own time as well. “It ain’t a problem for me if it ain’t a problem for you”, sort of thing. If you are responding to a bug Collaborate Bugs are an opportunity for collaboration. They allow you to engage with the community and start a conversation. It’s a two-way street. After all, that’s why you’re involved in open-source, right? Marketing Bug reports are the perfect opportunity for marketing. It’s free data! You get to learn which entities and companies from which industry sectors use the software. And how. The more you get involved, the more advertising and marketing is going to flood your way and that might radically change the way you think about the original platform requirements. Learn Bug reports are fun; you learn how people are actually using the software in ways you had never imagined, which may influence you more on a technical level to rethink design, implementation and learn about new integration prospects and partners. Be nice This is perhaps the most important bit of all. Do NOT ever create an atmosphere where the user community feels like they are being treated as buffoons with severe visual impairments who are dispossessed of the ability to read your perfect documentation and walkthroughs. As far as you should be concerned, [albeit a tad too extreme perhaps], if someone can’t figure out how to use the solution in reasonable time, then the bug is on you. Resist the urge to call out folks on their “stupid mistakes” and don’t be inclined to respond to every single “foolish” post. Eat something sweet. The feeling will pass, I promise you. Be nice. Welcome bug reports with open arms. Misagh Moayyed",
    "tags": "Blog",
    "url": "/2016/09/26/love-thy-bugs/"
  },

  
  
  
  {
    "title": "CAS Git Repository Maintenance",
    "text": "If you have managed to clone the CAS Github repository recently, you would notice that the repository is obscenely large; 1.2GB large that is. Depending on your connection bandwidth, the initial git clone operation could take a very long time specially time that could otherwise be spent wisely to catch Pokémon. Over the years, the CAS development has collected a lot of history in the git commit log. Given the upcoming CAS 5 release, we feel this is a good time to do a little bit of housekeeping to compress the repository and leave it in a functional efficient state. Here are the details. What does this mean to adopters? If you are a CAS deployer and have started your CAS deployment using a WAR overlay method, this will have absolutely NO IMPACT on your deployment and future upgrades. None whatsoever. Keep building, patching and upgrading. If you are a CAS deployer and have started your CAS deployment via building directly from source, you MIGHT be in trouble. We certainly recommend all CAS deployments start with the official and suggested deployment strategy, but if you wish to stick to your own ways, read on. What does this mean to developers? Well, we are simply creating history here. Here is the issue tracking this particular task. One of the caveats of cleanup process is that the commit log is massaged to rewrite the project history. This means that all project activity remains in place along with commit messages, authors and dates yet SHAs will be replaced and regenerated. This also implies that anyone else with a local clone or fork of the CAS repository will need to either use git rebase or create a fresh clone. If you fail to do so and manage to push again, old history is going to get pushed along with it and the repository will be reset to the state it was in before! So nuke your existing clones and forks and start again. Note that the cleanup process affects not just master but all CAS repository branches, and there are quite a few. This means that before you start over with a fresh clone, you will need to make sure lingering branches in your local fork of the CAS repository are either: Safely backed up and stored somewhere else, so they can be reworked later into the fresh clone. Merged into the canonical CAS repository prior to the cleanup effort. How do we do this? We plan to follow this guide. Initial experiments seem to demonstrate that repository size would shrink down to about 500MB, which is quite an improvement. Prior to the cleanup process, we plan to store the existing CAS repository in a separate git repository for safekeeping as a backup. When do we do this? The cleanup process takes a while to complete, somewhere between 2-4 hours. Announcements will follow on the CAS mailing lists to give developers a headsup on the individual milestones within the cleanup task. Keep an eye out. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2016/09/21/gitrepo-maint/"
  },

  
  
  
  {
    "title": "September 2016 Apereo Newsletter",
    "text": "This newsletter, dated September 15th, was published to the Apereo Announcements Google Group. It is re-published here as an experiment in publishing using Jekyll / Markdown. This content is lightly edited and hyperlink-enhanced to take advantage of this publishing medium. Upcoming Events 1) UCLA and Unicon Webinar on Identity &amp; Access Management, Hosted by Internet2 2) Virtual Sakai Conference: Wednesday, November 2 3) Request for Volunteers: Open Apereo 2017 Conference Planning Group 4) Apereo Africa 2017 Announcements 5) uPortal Announces Supporting Subscription Model 6) Ra11y Plan for Sakai Accessibility Phase 1 Complete Project News &amp; Releases 7) News from the Opencast Community 8) Karuta Portfolio Ready To Replace OSP in Sakai 11 9) uPortal 5 Roadmap 10) Xerte Online Toolkits v3.3: Expanded SCORM Tracking! 11) CAS 5 Available by Late September Case Studies: Early Sakai 11 Implementation at Three Institutions 12) MCI’s roadmap to an early Sakai 11 update 13) Migrating to Sakai 11 at HEC Montréal 14) Sakai 11 Early Adopter: Notes from the Trenches at Marist College From the Editor: A new semester is underway, bringing with it releases, project news, and new opportunities to collaborate and share. Remember that the Apereo newsletter provides an important opportunity for communicating within and across the many projects in our community. This is your vehicle to share what you’re doing and invite others to join. Our newsletter is also an important place for sharing strategies and success stories for pursuing an open source philosophy in educational technology. We are looking for contributions of all kinds – examples might include (but are not limited to) articles, video clips, screencasts, graphics, or short announcements on: How you’re using software produced by an Apereo community at your institution Major releases or minor tweaks Ideas for new projects you’d like to get feedback on or gauge interest in Important discussions of general educational technology issues that emerge on community email lists Contributions of all lengths, from snippet to think pieces, are welcome. Send your submissions (and any questions!) to newsletter@apereo.org. The newsletter will publish on or about the 15th of the month, with items due by the 10th. – Lucy Appert, Newsletter Editor Upcoming Events 1) UCLA and Unicon Webinar on Identity &amp; Access Management, Hosted by Internet2 September 21, 2016 – 2 p.m. EST http://bit.ly/2cd4SwN Join UCLA and Unicon for an interactive webinar, hosted by Internet2, to discover how open source Grouper and Shibboleth are meeting UCLA’s identity and access management needs. This webinar will also give an update on open source project customizations for Grouper and Shibboleth (completed by Unicon for its clients) that have been donated back to the open source community. – Lisa Di Pietro 2) Virtual Sakai Conference: Wednesday, November 2 Make plans now to attend the Sakai Virtual Conference on Wednesday, November 2nd from 9AM to 5PM EDT (-4 GMT). The conference will be held entirely online, and will have an emphasis on pedagogy and best practices. Join us for a faculty-friendly day of learning, sharing, and community building with your fellow Sakai users around the globe, all without the need to travel! For more details, visit the conference website. – Neal Caidin, Sakai Community Coordinator, Apereo Foundation – Wilma Hodges, Sakai Virtual Conference 2016 Planning Committee Chair – Ian Dolphin, Executive Director, Apereo Foundation 3) Request for Volunteers: Open Apereo 2017 Conference Planning Group The Open Apereo Conference will be held between the 4th and 8th of June 2017, in sunny Philadelphia. As with every Apereo conference, community engagement is the key to a successful event. Key to this engagement are community volunteers who serve on the conference planning group. Please consider volunteering. The planning group meets for around an hour every two weeks, and consists of volunteers, Foundation staff, and our conference planners, Concentra. Joining the group is a great way to get involved, and work with other community members to shape the conference program and social activities. If you’re interested, contact me directly at ian.dolphin@apereo.org . – Ian Dolphin 4) Apereo Africa 2017 Mark your calendars! Apereo Africa 2017 conference will be held in Cape Town next year on the 9th and 10th of May Contact details: tshego@opencollab.co.za or elsabe@opencollab.co.za. Kind regards Elsabe Botha Announcements 5) uPortal Announces Supporting Subscription Model The new Apereo membership model consists of two elements. The first is a Core Foundation Subscription, paid by all members. This covers key services Apereo provides for all its software communities – technical infrastructure, legal and licensing support, community coordination, events, and outreach. The second is a Supporting Subscription for specific Apereo Projects. This is an important way that organizations can substantively and collectively support projects they use and depend on. External to Apereo, organizations may also subscribe to commercial support offerings which address local support and targeted development. All three of these mechanisms address different but important needs. The uPortal Steering Committee is responsible for determining how subscription funds will be used. Our primary use is in support of securing a uPortal Community Liaison and Release Lead. This person would focus on: Coordination and engineering of releases Testing Bug fixing Fit and finish of code and documentation pull requests Welcoming and bootstrapping new developers and community participants The uPortal Steering Committee has developed a tiered rate for uPortal Supporting Subscriptions that gives institutions flexibility to determine what level of financial support they would like to demonstrate for uPortal. Supporting subscriptions are annual, on top of the standard Apereo Member/Affiliate rates. uPortal Supporting Subscription Rates: $1,000 bronze, uPortal Friend $5,000 silver, uPortal Booster $10,000 gold, uPortal Sustainer $20,000 platinum, uPortal Champion All uPortal Supporting Subscribers are entitled to: Vote for a uPortal Supporting Subscriber representative on the uPortal Steering Committee Being recognized as a uPortal Supporting Subscriber on the project web site The gratitude from the uPortal Community for their valuable support By becoming a uPortal Supporting Subscriber, you can help support continued improvements to the uPortal project such as releases that are more frequent, more complete, more stable, and better documented. Your support also helps make possible additional contributions from the community as potential contributors feel more welcome and encouraged. By coming together as a community through uPortal Supporting Subscriptions we can collectively ensure that uPortal better meets the needs of higher education organizations and beyond. We encourage you to consider becoming an Apereo Member/Affiliate organization and a uPortal Supporting Subscriber. – Jim Helwig 6) Ra11y Plan for Sakai Accessibility Phase 1 Complete Dear Community, Thanks to you, Phase 1 of the Ra11y plan is complete! What does this mean? It means that we completed a substantive review of the accessibility of the Sakai system by contracting out the assessment to a reputable 3rd party, SSB Bart. Improving Sakai’s accessibility means making it easier for people of all abilities to use our system. Our aim, as it always has been, is to make the system genuinely as accessible as possible, which directly impacts students, instructors, and other users in a positive way with a better user experience. We also wish to achieve WCAG 2 certification, which validates the community’s hard work in this area. A double win! The good news is that Sakai, as it stands now, is assessed at 74% compliant, which is not a bad starting point. Also we have gone painstakingly through the 453 identified issues and consolidated them into 51 Jiras . We are off to a great start and we don’t want to lose the momentum! Deadline Now we are in phase 2 and we have a deadline to complete the work to address issues identified by January 28, 2017. Contributions Please consider contributing to this FARM project either with a cash contribution, resources to fix bugs, or QA resources to help test Accessibility fixes. At the moment, resources for fixing bugs is the most urgent. We would like to target Sakai 11.2 or Sakai 11.3 maintenance release to complete this project, though we realize this might be ambitious. Why Contribute? Accessibility reflects our values as a community; probably reflects your institutional values; and I am guessing that for most of us, reflects our personal values too. Accessibility is becoming a must-have requirement for institutions looking to adopt a learning management system. Many institutions will not consider a learning management system that is not accessible. Legal compliance in many countries Accessibility is the right thing to do. Accessibility in most cases, if not all, benefits ALL users of our system. Consequences of not meeting the end of year date If we don’t meet our goal of 100% compliance by the January 2017 deadline then we can still get a conditional certification based on the percentage of completion we do make. But then if we want the full WCAG2 certification and don’t meet the deadline , we will have to start the process over, which will be more time-consuming, will require another round of funding, and will mean the overall cost to complete might as much as double. Approach Collaborating with developers and with SSB Bart, the Accessibility team aims to identify the best way to fix certain types of accessibility issues, and to document these approaches to make it as easy as possible for our developer community to participate and help fix bugs. The documentation will be in our community wiki, Confluence. More details to come. Invitation Every little bit helps. If you think your institution might be able to contribute in any way, please contact our Accessibility chair, Matt Clare, for more information, matt.clare@brocku.ca. Thanks for your attention, The Sakai Accessibility WG Project News &amp; Releases 7) News from the Opencast Community On September 26-27, the annual meeting of the German speaking Opencast community will take place. This time, the conference is hosted by the University of Stuttgart. More details will be released soon. The annual Opencast community summit will take place March 1-3 2017 at Universitat Politécnica de Valencia. This event will coincide with a meeting of the Spanish/European Sakai/Apereo community. Expect to hear more over the next couple of months. Opencast 2.2.2 is expected to be released on Monday, September 12th,2016 Bruno Seoane (Teltek) and Lars Kiesow (ELAN e.V.) have been elected as Opencast 2.3 release managers. Feature freeze is set to October 1st and the final release is expected on December 13th. – Lars Kiesow 8) Karuta Portfolio Ready To Replace OSP in Sakai 11 The Karuta Open Source Portfolio 2.0 stands ready to replace (and upgrade!) your OSP implementation – now that OSP is not included in Sakai 11. From the Resources page on the Karuta website, you can access our sandbox instance, try out a customization involving the AAC&amp;U Value Rubrics, download our two designer workbooks to help you build your own customization, and/or download the Karuta 2.0 code. You can also access demos of Karuta Karuta YouTube channel Sakai Showcase Webinar Series: Karuta Open Source Portfoloio For LTI Integration with Sakai 2015-11-04 15:20 Karuta 1.1 - A Complete Portfolio Solution LTI Integrated with Sakai Karuta Open Source Portfolio: a flexible architecture for assessment, accreditation and much more (French language) Screencast ePortfolio IUT2 KARUTA 2015 The Karuta Project under the umbrella of the Apereo Foundation also offers online demos for groups at your institution. Please let us know if you are interested in checking out Karuta! – Janice A. Smith 9) uPortal 5 Roadmap The uPortal Steering Committee, project committers, and uPortal adopters met virtually in early September to discuss the uPortal roadmap and plans for uPortal 5. The overall theme for this next version is to make the project more “modern” for today’s IT professionals. It includes an overhaul of the way the uPortal project sources are organized and how the project is built and deployed. Our high level goals are to: Shift the customary deployment paradigm away from building on each portal server Allow multiple adopters to deploy the same, Apereo-provided binaries Move uPortal toward “cloud native” Make uPortal easier to work with for developers, especially new developers – uPortal Steering Committee 10) Xerte Online Toolkits v3.3: Expanded SCORM Tracking! On behalf of the wonderful people of the Xerte developer community, we are pleased to announce that the latest version of Xerte Online Toolkits, v3.3 is now available. The most significant aspect of this release provides support for SCORM tracking for a much wider range of interactions. The following page types can now all be tracked: Dictation Matching pairs / Timeline Matching text Interactive Text Media lesson Gap fill Sortable Grid Drag &amp; Drop Quiz MCQ Additional New Features A new interactive page type, Word Search has been added to the ‘Games’ category. Display of learning objects has been improved for iPhone. Pages can now be hidden from view until you are ready to publish them into the learning object. You can now add JavaScript to a learning object for custom functionality. The card graphics in Memory Game can now be customised. When exporting zip packages, the filename now reflects the project exported. Workspace has been enhanced to make the best use of the available screen resolution. New features added to Decision Tree. MathJax is now usable in Decision Tree. Interface enhancements to the Bootstrap pages to better handle projects with many pages. This release contains a large number of other fixes and enhancements. Upgrading is highly recommended. – Julian Tenney 11) CAS 5 Available by Late September The CAS development team is marching towards a major release – CAS 5. The first release candidate has been available for some time and the project intends to officially make the release available by late September. Adopters are encouraged to try the release candidate and report back issues as early as possible. The CAS 4.2.x release line is also actively maintained and 4.2.5 is the current and most recent version that is recommended for production deployments. Also the CAS PMC recently approved of the CAS maintenance and EOL policy that describes how CAS releases are generally maintained. It’s important for adopters to understand how long their particular deployment is set to receive patches and attention from the developer community. – Misagh Moayyed Case Studies: Early Sakai 11 Implementation at Three Institutions 12) MCI’s roadmap to an early Sakai 11 update At MCI (MCI Management Center Innsbruck) we are proud to be among the very first institutions having upgraded to Sakai 11 - including a new Morpheus compatible skin for a responsive UI and MCI-specific adaptations and processes. Our user feedback has been great so far! We really would like to thank the Apereo Foundation, the Sakai community, and the developers who did a terrific job and made this possible! For this update, the available time frame at MCI was smaller than usual – less than 5 months, of course with maintaining the 10.6 instance alongside. Changes in development and the community processes of Sakai 11 made it possible to keep a tighter schedule than ever before! We do believe that the change to GIT source code management was one of the most important factors making more timely local releases including adaptations possible. Up to Sakai 10 we used a local subversion repository with a vendor-branch approach for keeping our source code in sync with the official Sakai versions. Importing the new community source code was an error-prone and tedious process and as a consequence was done only few times a year. Important security patches were integrated manually, bigger updates are only implemented twice a year. The time cost of the workflow enforced a sequential workflow that meant that we always had to wait for a Sakai release to have gold release status before we started work on source code integration and adaptation. With GIT we were able to start adaptation, testing and integration in parallel to community development. In order to be up-to-date, we regularly rebased our changes on the 11.x-code instead of the tags. Implementing it this way, we already finalized our local adaptations when Sakai 11 was released officially. Timeline: Summer 2015 First local tests of Morpheus February 2016 Last update Sakai 10 (10.6) March 2016 Download 11.x, still without local GIT workflow Change of development environment to Tomcat 8 and Java 8 First local instance of Sakai 11.x Risk assessment for planned update in summer April/May 2016 Introduction of GIT repositories for development at MCI Concept for removal of previous adaptations (especially for navigation, UI) Final strategic decision for summer update to Sakai 11 June/July2016 Local Git-Rebase workflow and documentation created, based on remote 11.x upstream and local multi-developer git repository Morpheus skin adaptations (mixture of scss-config and injection of a custom.css which contains our skin code not configurable with the existing scss-variables) July 22, 2016 Integration of latest blocker bugfixes and last git-rebase to 11.x before update. July 23, 2016 Official Apereo Sakai 11 release July 25, 2016 Update of sakai.mci4me.at to Sakai 11 (we didn’t really plan to be that close to the official release date, we decided to use 25/7 about 1 month before :-) ) The update started at 13:00 CEST and was finished at about 15:00 CEST. Administrative tasks during the update process were: Backup (filesystem snapshot, fast) update of required environment (Java, …, fast) uploading new configuration files (sakai.properties and init scripts, debugging necessary, took most of the time) Deployment of new Sakai build (fast) configuring and resetting user workspaces with a webservice-script (debugging necessary, took some time) repairing the Favorite Sites of every user with the conversion script: java -cp \"lib/*\" -Dtomcat.dir=\"$PWD\" org.sakaiproject.user.util.ConvertUserFavoriteSitesSakai11 (easy and fast) The contrib-tools we are using are the following: Dashboard (using that one since summer 2013): Still not a core tool, but it just works fine for our needs, is placed on every users starting page and is everybodys favorite timesaver. Lots of trouble, but lots of benefit. YAFT: Still in triage (so no real user feedback), but it seems to work with Sakai 11. CLOG: Introduced that with Sakai 11, so no conversion experience. Contentreview/TII: We highly customized this one in Sakai 10, and simply kept that for 11, since the switch to the LTI-tool is coming soon (we guess). Thank you once again &amp; best wishes from the Alps! IT-Services team @ MCI If there is further interest in particular aspects of our update-roadmap, feel free to send a request to our developers: Thomas.Lampert@mci.edu Wolfgang.Rohregger@mci.edu In cases of organizational questions, you can also contact our IT-Lead: Peter.Mirski@mci.edu 13) Migrating to Sakai 11 at HEC Montréal HEC Montréal went live with Sakai 11 on August 10th. Our migration from a Sakai 2.9/10 hybrid went smoothly. We took the decision in April to forge ahead with our migration process without knowing the release date of Sakai 11. We were confident that the community would put tremendous effort to get the release out before the fall semester and we were not disappointed! It was very important for HEC to migrate to Sakai 11 this summer since we plan to use 2017 summer to release a new course outline tool to our users. This new Sakai tool called ‘TenJin’ is currently under development at HEC and we plan to make it available to the Apereo Community as an open source project. – Philippe Rancourt 14) Sakai 11 – Early Adopter: Notes from the Trenches at Marist College We didn’t think we would go first. In fact, we were hoping to be somewhere in the middle of the pack, a bit out towards the front. It had been several years since Marist College had a major Sakai upgrade and it was critical we move as quickly as possible off of Sakai 2.9.4 to a new version. Pressure had been mounting since student and faculty feedback indicated the system seems “dated” and “clunky” and of course, it didn’t work on mobile devices. Sakai 11 included “must have” features like “Lessons”, GradebookNG, and a pleasant, user-centric, responsive design. To assure success, we partnered with Longsight, who worked with us in preparation for the upgrade and who was instrumental on the day of our upgrade. With our deadline looming, we charged on. As a result we learned from our successes as well as our failures. Here’s are some of the lessons we learned. Prepare, if you can. In 2015, we knew we would be upgrading at some point and changed our old 2.9.4 skin to be reflective of Sakai 11 in an effort to prepare faculty and students for the change to the User Interface (UI). We made a copy of our production database and ran the Sakai 10 and 11 upgrade scripts against it. This gave us a chance to see, in advance, if we would have any data issues as part of the upgrade. We actually ran into an issue with the Job Scheduler tables; this issue was fixed as a Community Jira, saving others from running into the same problem. Lesson learned: Give yourself a bit more time than you think you need to get your existing skin(s) into Morpheus. It does take some trial and error to get buttons and some other features set the way you want. You will also need to go through all the tools to make sure that they are themed the way you want. We ended up with a few buttons that had the text color the same as the button color. This was not the best user experience. The more skins you have, the more time you will need to dedicate to the Morpheus conversion especially if your skins are heavily customized. Be aware of deprecated tools. We started a bit late out of the gate in locating a solution for our faculty to migrate their Melete content into the Lessons tool. However, once a process was in place, we took initiative to reach out to our faculty, especially to those who teach fully online courses and were the heaviest users of these tools. Communication took the form of announcements, email, newsletters, and workshops. We also created pages dedicated to the upgrade on our website. We directed all customers there for the latest information related to the upgrade. Timing is everything. An important question arose: do we allow faculty to begin creating their fall courses prior to the upgrade? This meant jumping through some hoops to make sure that tools available to faculty building courses in 2.9.4 would be supported in Sakai 11. We switched from Gradebook 2 to Gradebook 1 as it was supported in both versions. After the upgrade we ran a script against the database to convert all the courses with Gradebook 1 to GradebookNG. This was only possible because the database tables were the same between the two tools. This method eased the impact on faculty and students for courses running during the upgrade. Recommendations Create an inventory of tools with in both course and project sites. Identify outliers (tools that may be deprecated such as Clog or LTI tools). These are the issues we received the most critical calls about. We even had to bring back up a copy of Sakai 2.9.4 so that one instructor could grade the Clog content in his summer course. It may sound redundant, but prepare the faculty for what is about to change within each of the tools they use in various formats, such as documentation, outreach, and supplemental information. The jump from 2.9.4 to Sakai 11 turned out to be overwhelming for some faculty because of the changes in interface, tool behavior, and new tools coupled with impacts on course and content development and delivery. Don’t forget about the Adjunct Faculty. Many who teach once or twice a year may be completely unaware of the upgrade. Keep the Help Desk in the loop and make sure they have “how to clear your browser cache” documents handy, along with the extensive documentation regarding new features. Join the Sakai QA community and maintain continuous engagement. Participation offers the best opportunity to experience the latest version and prepare for new tool behavior and functional changes. Last but not least, keep up with the latest software. In other words, upgrade regularly. Although we had issues and missteps, the overall the feedback we have received has been quite positive and many of our initial concerns were able to be quickly addressed. We were not planning on being an early adopter, yet with the lessons we have learned from this successful upgrade, the idea may not be unusual in the future. – Dede Hourican",
    "tags": "Apereo",
    "url": "/2016/09/19/newsletter/"
  },

  
  
  
  {
    "title": "Veresk Software Architecture",
    "text": "I suspect you have never had a chance to visit the Veresk Bridge. That’s cool. Neither have I. But humor me please and take a peek at it here. Here is a slightly better-than-Wikipedia picture of the bridge: I am going to tell you about the part that my mom told me when I was a kid and it’s a story that likely most Iranians-by-origin know as well, though its authenticity is still somewhat questionable. The story goes that as the chief engineer, Mr. Walter Aigner, finished the architecture work and once the bridge construction was fully ready to be “tested”, he called upon Reza Shah (the head monarch of Iran at the time) to come visit the beauty in all its glory. He did also request that Reza Shah must have the honor of boarding the very first train ever to cross the bridge and cut the metaphorical ribbon with wheels on burning coal. The bridge was a very big deal at the time; a symbol of magnificence, pride and glory for the nation. The opportunity for the common folk to see their Shah up close and witness him take part in the community to “ride the train along with his countrymen” was going to be both advantageous to the administration and a note of joy and amusement for the people. So of course, he obliged. I also suspect that Reza Shah was not a big fan of testing things in production either. But he did ask that Mr. Aigner along with the rest of his family stand underneath the bridge and watch as he, aboard the train, crossed over. Remember; this was a first test. A smoke test that could have literally ended in smokes. Mr. Aigner was of course so confident in his design and implementation of the bridge that he accepted. His family patiently watched from 100 meters below while the train successfully crossed the bridge without any accidents. “Cheers to the Shah”, people must have yelled. So why am I telling you about all this? Because that’s exactly how I feel about software architecture and the responsibility of architects as they pass through iterations of design and implementation. If you are not willing to stand by your design and your ideas in confidence…if you are not able to execute in action what may only seem a pretty diagram on paper…if you are not willing to get hands-on and learn the nuances of implementing said ideas and weigh pros and cons of each in practice…none of that is of any use to anybody, really. Of course, let’s clarify that I: Have nothing against bridges, trains or crossing over things. Am not advocating for any sort of monarchy. Am not advocating for any kind of violence and hostility during software design. Am not advocating that you should gather your folks and sprawl out underneath the data center as you press the power button on your Pentium II. Seriously shall question your sanity if you go to production with Pentium IIs. All I am saying is, you should be held accountable. That’s all. Misagh Moayyed PS: The Chief Engineer, Austrian Walter Aigner, following his wishes, is today buried in the local cemetery of Veresk. ",
    "tags": "Blog",
    "url": "/2016/09/17/practical-soft-arch/"
  },

  
  
  
  {
    "title": "Hope for GitHub Pages",
    "text": "Short version “+1” for Apereo adoption of GitHub Pages for this website. I’m hopeful for applying this approach beyond blogging. Static site generators have lots of advantages. Those advantages align with Apereo values and realities. Call to action to use GitHub Pages more and better and thereby make Apereo websites better. +1 I’m really excited and supportive about Apereo’s adopting GitHub Pages for this website, and I’m hopeful about using it for more than just a blog. Not only do I concur that this is a good idea, (Which is to say, “+1”, in Apache parlance.) Advantages of static site generator websites Jekyll-driven GitHub Pages has tremendous advantages aligned with Apereo values and operations. Driving the website by a public Git repository improves transparency. It means anyone can inspect the content and history of the site to understand just what is being said and the history of saying it. And anyone can inspect the program that generates the site from the content files. Not just the open source technology used in the abstract - the specific configuration, instantiation of that automation. Driving the website by a public GitHub repository improves openness. It means anyone can propose a change. Anyone can even edit through the GitHub UI in a Web browser if working with text files locally is off-putting. Driving the website by a public GitHub repository improves meritocracy. It means when anyone proposes a change, that proposed change can be publicly evaluated on its merits. GitHub Pull Requests and their review features are a beautiful thing. Driving the website by a public GitHub repository improves collaboration. It means anyone can collaborate with anyone in any branches they need, in public or private forks if need be. Modeling the website content as text files in a public GitHub repository better enables (much) better tools for working on the content. Programmers edit text files. A website that is fundamentally text files as content is more amenable to programmers and technically minded people doing great things efficiently. grep and its kin are beautiful and powerful. As is your text editor of choice. Driving the website by an open and openly configured static site generator enables (much) better tools for working on the website framework. To the extent necessary, programmers can collaborate not just on the content but also on the “program” that generates the website from the content – the CSS, the templating, all the way through the free and open source static site generator framework itself. GitHub Pages is much better aligned with affordable and sustainable Apereo operations practices. Apereo runs very thin on infrastructure and even thinner on staff and volunteer bandwidth to wrangle infrastructure. GitHub Pages adds zero to Apereo’s server and database footprint. GitHub Pages websites are also free as in cheapness, which lines up well with Apereo funding levels. Apereo maybe should pay someone to develop awesome website content (arguable). Apereo definitely shouldn’t be paying anyone to host a website, operate its database, keep WordPress patched. Accept free-as-in-cheapness infrastructure for commodity website hosting and repurpose scarce resources for something more higher-ed-open-source-IT-aligned. Static site generators enable higher quality results. It’s easier for web developers to collaborate on making a website much sharper, much snappier, much better when using sharper tools. Using Jekyll-driven GitHub Pages eases future migrations. While GitHub Pages operates with panache, Jekyll is open source and generates a static website that can be served up from just about anywhere on just about any technology stack. Using GitHub Pages doesn’t entail vendor lock-in. Using Jekyll-driven GitHub Pages eases future migrations. If Apereo ever wants to port this content to a different website management platform, well, all the content is just text files. It’s hard to beat that as a friendly starting point for laying hands on this content and importing it into something else. (These are advantages of open source public-git-repository-driven static site generators more generally. Jekyll-driven GitHub Pages is a particularly nice implementation of an approach that can be achieved with more hassle using other specific technologies.) Examples of use of GitHub Pages, outside and within Apereo Okay, so GitHub Pages in particular, and static site generators more generally, are technically awesome. You might reasonably ask, why is this website nonetheless so very ugly? I want to assure that GitHub Pages sites can be beautiful, usable, arbitrarily comprehensive, etc. GitHub has a showcase of GitHub Pages examples. These are some of the more website-flavored examples: Electron react developer.github We need not look so far afield to find examples of using GitHub Pages to make websites happen: there are usages within Apereo already. CAS OpenDashboard OAE (note this demonstrates that GitHub Pages sites can have arbitrary hostnames, don’t have to be .github.io branded.) Tsugi Next steps Better is better. Make things better, and then make things better again. Repeat. I believe that static site generator approaches are better than database-backed-web-application approaches (WordPress, Drupal, even my beloved Ghost) for web sites, more often than not. GitHub Pages-driven oaeproject.org feels more awesome, more beautiful, more full of potential to me than does its equivalent pages within apereo.org. The next step is to do more of that. To keep making Apereo content better using better tools. And then to repeat. I hope these steps will add up to a walk will be a walk out of database-backed website solutions and into static site generator solutions, for the better productivity, quality, openness, transparency, and sustainability of Apereo website delivery. Disclaimer Opinions expressed are my own and are not necessarily those of Apereo, of my employer, of the uPortal project, or of other projects and organizations with which I am involved. Andrew Petro",
    "tags": "Blog",
    "url": "/2016/09/16/hope-for-gh-pages/"
  },

  
  
  
  {
    "title": "MyUW (University of Wisconsin) Build Process",
    "text": "During the most recent uPortal development meeting we were discussing how uPortal building and deployment currently works and ought to work. It came up that other campuses are checking out the project on each server, building the ear, and shipping it to Tomcat. UW does not take that approach and we thought it may be helpful to articulate what we do to maybe help steer the next generation uPortal project (aka uPortal 5). Edits: adjusted to reflect the new name uPortal app framework and new repository location for what was previously known as uw-frame adjusted to reflect the new name uPortal home and new repository location for what was previously known as AngularJS-portal The Now There are many pieces of technology that the UW uses. Here are the components and some other definitions that will be used in this technical document: CI : Continuous integration Jenkins : A platform to build and deliver projects Maven Repository : A storage application to place and retrieve built Java artifacts Gitlab : A git repository GUI (UW has an on-prem instance running in Docker, very easy) Maven Overlay : A process in maven where you can overlay files on top of a project to change things such as configuration. Docker : shipping containers with a single process* running in a encapsulated environment. Token Crypt : A project that can encrypt/decrypt tokens and files using public/private key pairs. We use Jenkins for two different reasons. First we build the project and deploy the snapshot to our maven repository. We also use Jenkins for CI. For example, let’s say that someone makes a change to our fork of uPortal. When we merge the merge request from Gitlab into master, we push out a post merge web hook to Jenkins. Then we have a Jenkins job that runs mvn deploy which packages all the artifacts for uPortal and deploys it to the snapshot maven repository. It is important to note that the artifact we ship to maven has no passwords or configuration files in it. These are environment agnostic artifacts. After the environment agnostic war has been shipped to the maven repository, we trigger a test uPortal war build. This build is just an overlay. It takes the environment agnostic war, unwraps it, injects in the configuration files for test, and wraps it back up. It is then stored in our server’s local .m2/repository. During this process we decrypt the tokens that are passwords using Token Crypt’s maven plugin. Since it has passwords at this point, it’s important to keep it local and not push it anywhere. At this point the ear job for test is triggered. This ear job is just a pom.xml that pulls in the artifacts from all the overlay projects for that given environment. You can see an example of said pom.xml here. All that happens is we run a mvn package and then ship the ear (exploded) to a directory on the build server. Do note that none of this is happening on a server that will run uPortal. So now we have a test version of our deliverable that we want to ship to our test instances. We use Docker for our servers, running on Linux VMs. We have a Docker container that has a preconfigured Java and Tomcat with an empty webapps directory. After the ear build runs with the test ear, we then can deliver it to test. We have a docker jenkins job that does this task. It does the following: Docker pull our latest container that has java/tomcat configured Copy the wars from the build directory to the running directory (versioned so we can always rollback) Take an instance offline and delete the container (e.g.: docker stop test1 &amp;&amp; docker rm test1 ) Do a docker run (e.g.: docker run myuw/tomcat7-java7:latest -v /runner/810/webapp:/home/of/tomcat/webapp) Water test the node to make sure tomcat started correctly Then trigger that instance back into the cluster, and rinse/repeat for other nodes Looking ahead to where we would like to go We like our current setup but we would like to improve on a few things. Here is our wish list. First we would love to stop having to fork uPortal to get our own skin and configuration (using the alternative uPortal home front end). If we could do a Docker overlay process that could be nice. We would also like to have it possible to ship the content of the webapp directory instead of depending on a volume mount from the host. In order to accomplish that we need to get rid of the hard coded passwords in the configuration files. We are looking toward using VaultProject for that. This would have the sided bonus of removing the complexity of maven overlays. During startup vault could go fetch the configuration for that given environment. It could also be interesting to be able to download a docker artifact containing a configured uPortal from docker hub. The only downside is we would like to be able to control the versions of Java and Tomcat. However, if we updated this often we could be alright with relieving that control. A single Docker container running a big JVM can be painful to scale. We would like to look into splitting out our webapps into many docker containers so we can scale only the things that need scaling. A great example of that is the wave of students who need to get to our campus course guide (which is currently a portlet). If we wanted to increase the bandwidth of that one portlet, we would need to stand up another 6GB JVM. We are migrating that application to a normal webapp so this is possible. It will still have a MyUW presence, but just through widgets and links. It will have the added bonus to look like it is part of the MyUW experience using shared angular components from uPortal app framework. We are also looking toward running on AWS, but this is in the very early stages. More Resources Github overlay sample project Tim Levett",
    "tags": "uPortal",
    "url": "/2016/09/15/myuw-build-now-and-future/"
  },

  
  
  
  {
    "title": "CAS 5.0.0-RC1 Release",
    "text": "CollaborateThe blog is managed and hosted on GitHub. If you wish to update the contents of this post or if you have found an inaccuracy and wish to make corrections, we recommend that you please submit a pull request to this repository. Based on the CAS project release schedule, today we are excited to announce the first release candidate in the CAS 5 series. There are a few enhancements packed into this release that are worthy to publicize. So here it goes. Before we get started, it should be pointed out that releases of CAS 5 are available to adopters to try. Deployers are more than welcome to try these out and share feedback. The current documentation of CAS 5 is also available here. OpenID Connect OIDC support in CAS gets a number of improvements and bug fixes thanks to Jérôme. Google reCAPTCHA Over the years, there have been several requests on the mailing list asking for guidance to enable a CAS integration with Google’s reCAPTCHA. While a recipe existed for enabling this feature for older CAS versions, over time it’d gotten rusty. In this release, CAS starts to support Google’s reCAPTCHA natively. Just like with all other features, there will be no need to modify the CAS login webflow or any other configuration file. Include the relevant module, and provide your settings for reCAPTCHA. This article may be of further interest to you. Default Redirect URL What happens when users accidentally and incorrectly bookmark the https://sso.example.org/cas/login url? They get to the CAS login page, authenticate and then are greeted with a warm welcoming message that redirects them to nowhere important. Phone calls and support tickets flood IT services reporting that CAS or this/that application are broken. That’s no fun. So to accommodate this briefly, CAS starts to support a default redirect URL to which you can redirect your audience if no target application is specified upon authentication. The URL can be just about anywhere, as long as you have authorized and registered it correctly. In most cases, it’s a redirect to some sort of portal page that lists all services integrated with CAS. Case Insensitive Attribute Release So you have set up CAS to retrieve attributes from your LDAP server and decided to retrieve the attribute givenName. You then register a few services and design them such that they would be allowed to receive givenName, yet nothing is released. Your logs show givenName is found and your LDAP queries and browsers all show that attribute has a valid value and all the right permissions are set. What’s happening? Is CAS secretly biased against that attribute? Some LDAP servers seem to change the case of the attribute name when they pass it back to the requesting application. CAS may submit givenName, yet it receives givenname. When the application asks for attributes CAS looks at the associated attribute policy and finds that it’s authorized to release givenName, yet the actual principal has no such attribute! It only has givenname. As a result, the application gets nothing. To accommodate this scenario, CAS starts to treat attributes that are specified in attribute release policies in a case insensitive manner. With this change, CAS may ask for givenName and the LDAP server is free to return givenname, GIVENNAME or a hyper-emo version of it, gIvEnNaMe. At release time, since case no longer matters the application will correctly receive givenName. If it matters that much, note that you can always control the exact case of the attribute released as well and override the CAS behavior. Also note that this behavior is applicable to all sources from which you retrieve attributes. It’s not limited to LDAP though the issue described most commonly affects LDAP. Geoprofiling Authentication Requests How do you block what you may consider a suspicious authentication attempt? For instance, you may wish to disallow requests from certain locations or IP addresses or even fancier, you may want those requests to pass through multifactor authentication for extra security. As a variant of adaptive authentication and starting with this release candidate CAS allows you to geoprofile authentication requests and then based on your devised rules, reject those or force them through a particular multifactor provider. Geoprofiling can be achieved via Maxmind or GoogleMaps, both of which are services that require a paid subscription for full API usage. Groovy, maaan! Furthermore, CAS starts to support attribute release via the Groovy programming language. In short, you can specify a groovy script that is executed upon attribute resolution and/or release to dynamically and programmatically decide which application should receive a selection of attributes. Note that attribute resolution could always be done via Groovy. This bit is not new. We have just made the configuration of it a whole easier. Also note that in CAS, attribute resolution is a separate process from attribute release. You can mix and match options that are available for both. Needless to say, the script is all Groovy and and is capable of executing any kind of operation the Groovy language itself is able to support. Spring Cloud: Vault &amp; MongoDb CAS adds support for Vault and MongoDb, as options that may be used to house CAS configuration. DuoSecurity WebSDK 2.3 Thanks to contributions from DuoSecurity, the Duo WebSDK module is now bumped to 2.3. Front Channel SLO While it has been and still is somewhat of an experimental feature, this release candidate improves the CAS front-channel single logout functionality. CAS attempts to collect applications that are defined to use front-channel logout and will use a bit of fancy javascript to contact each endpoint to pass along the logout notification request. The payload and syntax of the request is identical to the current back-channel logout, and status of each request is tracked and displayed in the user interface. SAML2 SP Integrations Now that CAS 5 starts to support the SAML2 protocol, you gotta ask: what if we could extend the auto-configuration strategy to provide built-in SP integrations? That is, much like anything else, you should be able to declare what your SP metadata is, what attributes it requires and so on in a simple .properties file. CAS should auto-register the SP and take care of all the other technical details. Right? Right! With this release, CAS starts to support the following SP Integrations out of the box: Dropbox Box Salesforce SAManage ServiceNow PowerFAIDS Net Partner Workday WebEx Office365 These are generally SPs for which the SAML2 integration recipe is quite simple. As we progress forward, we hope to start collecting more and more of such SPs, specially those that are more visible and used by the wider community often, such that we can configure once, run everywhere rather than document it repeatedly, maintain it separately and repeat it for every deployment forever. If you have SP suggestions, please feel free to share. Audit Log In certain cases and depending on the nature of the request, CAS would produce an audit:unknown in the audit log. Thanks to Dima, this behavior is corrected to ensure the audit log can produce a valid user id for all cases. Logging Dashboard CAS starts to allow its administrators, permissions granting, to observe logging configuration and view log outputs in real time. This is done via the magic of Web Sockets, where CAS and the browser establish a light-weight TCP connection to stream log data. Here are a few screenshots: Custom Error Pages Thanks to the magic of Spring Boot, CAS starts to present customized error pages based on http error codes. You can for instance design a simple 401.html to explain the error to your users better. Error pages can be defined in form of series as well, such as 5xx.html. Here are a few screenshots: Password Management Starting with this release, CAS provides very modest password management capabilities. This is an optional feature which allows users to change their password in-place when CAS detects an authentication failure due to a rejected password. LDAP is supported as a backend option for managing the account password, though you could always extend CAS to provide your own implementations of password management services for various backends. Note that this feature is off by default and without it, you simply get today’s CAS experience which is a link redirecting to your own password management tool. Here are a few screenshots: What’s Next? The development team is working to make sure the CAS 5 release is on schedule. At this point, all new development has been frozen and project is solely focusing on testing the release candidate and applying bug fixes based on community reports. There will likely be other release candidates but short of any major incidents or changes, the CAS 5 GA release should be available right on schedule. How can you help? Start your early CAS 5 deployment today. Try out features and share feedback. Better yet, contribute patches. Review and suggest documentation improvements. Review the release schedule and make sure you report your desired feature requests on the project’s issue tracker. Das Ende A big hearty thanks to all who participated in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2016/08/26/rc1-release/"
  },

  
  
  
  {
    "title": "Defining a Product Vision",
    "text": "A long long while ago, I was having a conversation with a good colleague of mine, discussing how to evolve the roadmap of an open-source project to define a vision and how to handle user expectations to an extent so developers could meet and deliver them. Our conversation sort of stuck with me afterwards in form of the following motto: Ask not what X can do for you. Ask what you can do with X. I realize there are lots of “It Depends!” buried there. That’s fine. You have to factor in the relevant context though. This was coined, as I remember it, to embody the true open source and community spirit of a software platform and its users’ ability to extend and modify its capabilities as they see fit without any restrictions or hassle. The platform would continue to remain true to its roots while allowing adopters and deployers to take their deployments to the extreme edges of the world and build on top of it features and functionality that would be very different from the original core vision. Very cool. I want to say something different here. While I like that motto quite a lot and I think it says it all within the right context, I have been thinking about its complement. While it’s good and a true sign of power when deployers and users can take the platform and do absolutely whatever they want with it, it would be even more fantastic and awesome if the product did “everything” they wanted in the first place forcing them to keep their customizations to a minimum. This perhaps sounds like stating the obvious, but in my view, it’s the very delineating factor between failure and success. Evolution is key to success, and any platform or product that wishes to stay alive and stay relevant must redefine its core mission and vision every once in a while and must always be in pursuit of new ground to explore newer and exciting opportunities to help its community. There is no point in maintaining and working on a “beautiful, elegant, small design” that pushes all the responsibility and the liability to its community. If you find yourself often repeating the phrase “That’s not our core concern”, it’s time for you to joggle priorities and reevaluate concerns ‘cause those are what your community cares about. Beautiful design, more often than not, is secondary. So, how do we deliver “everything”? How do we design the implementation of everything? Is it going to be a monolith? It’s going to be ugly? Big blob of mess and mud? Should it lead us to bloat? Must it be YOOOGE? Is nose-picking banned for the Philippines police? I don’t know. You figure it out. All I know is that my new motto is: Ask what X should do for you. Then ask what you can do with X. Misagh Moayyed",
    "tags": "Blog",
    "url": "/2016/08/24/soft-evolution/"
  },

  
  
  
  {
    "title": "CAS EOL Policy Proposal",
    "text": "The CAS project management committee has been reviewing a proposal on CAS release policies, maintenance and lifetime. In particular, this proposal attempts to provide answers to the following questions: How long should a CAS release be maintained? What is the appropriate scope for release maintenance once a release is retired? Today The project has been handling release management and maintenance in a semi-official capacity. Today’s release practices typically are: Patch releases, once every 30 days. Minor releases, once every 3-4 months. Major releases, where appropriate based on community demand and technical landscape. Security patches, whenever needed and preferably as soon as humanly possible. There is no official policy to indicate the lifespan of a CAS release. Maintaining multiple release lines in an adhoc fashion is a very time-consuming and difficult process where the development team has to ensure patches across releases are ported backward or forward correctly and that changesets are properly cherry-picked into the target release, tested, documented and made available. This process is simply not sustainable. Proposal To mitigate some of this pain, the following proposal and a decidedly simple one at that is in the making: CAS adopters MAY EXPECT a CAS release to be maintained for one calendar year, starting from the original release date. Maintenance during this year includes bug fixes, security patches and general upkeep of the release. Once the year is passed, maintenance of the release is STRICTLY limited to security patches and fixing vulnerabilities for another calendar year. The lifespan of a release MAY be extended beyond a single year, to be decided by the CAS PMC and the community at large when and where reasonable. By “CAS Release”, we mean anything that is a minor release and above. (i.e. 4.1.x, 4.2.x, 5.0.0, 5.1.0, etc). What does this mean? The above policy, once in effect, implies that the following CAS releases will transition into a security-patch mode (SPM) only and will be EOLed at the indicated dates. Release SPM Starting Date Full EOL 4.0.x October 31st, 2016 October 31st, 2017 4.1.x January 31st, 2017 January 31st, 2018 4.2.x January 31st, 2017 January 31st, 2018 5.0.x September 30th, 2017 September 30th, 2018 All past releases that are absent in the above table are considered EOLed. Misagh Moayyed",
    "tags": "CAS",
    "url": "/2016/08/08/eol-policy-proposal/"
  },

  
  
  
  {
    "title": "CAS 5.0.0-M3 Released",
    "text": "Based on the CAS project release schedule, today we are excited to announce the 3rd milestone release in the CAS 5 series. There are a few significant enhancements packed into this release that are worthy to publicize. So here it goes. Before we get started, it should be pointed out that such milestone releases of CAS 5 are available to adopters to try. Deployers are more than welcome to try out the milestone releases and share feedback. The current in-development documentation of CAS 5 is also available here. Type-safe Properties The entire collection of CAS settings are now redesigned to take advantage of Spring Boot’s typesafe properties. These settings are safely mapped to a corresponding SomeCasComonentProperties Java class at runtime, support lists, sets and maps and can easily be refactored to contain more than one batch of settings. As an example, to define LDAP authentication handlers: ... cas.authn.ldap[0].ldapUrl=ldaps://ldap1.example.edu,... cas.authn.ldap[0].baseDn=dc=example,dc=org cas.authn.ldap[0].userFilter=cn={user} cas.authn.ldap[0].bindDn=cn=Directory Manager,dc=example,dc=org cas.authn.ldap[0].bindCredential=Password ... Additional handlers can be defined by simply incrementing that 0 index. Furthermore, this release takes on a super comprehensive approach into allowing the adopter to control all aspects of authentication handlers via such typesafe properties. You can now define individual password encoders, principal transformers and password policy settings for a given handler all via the same collection set. No need to resort to any sort of XML configuration file. Note all that sensitive CAS settings can be encrypted and secured. At runtime, CAS will auto-decrypt settings, making the configuration that much easier to be shared centrally in a central repository of some sort. There are many other small little enhancements packed into this particular area that remove the need for explicit XML configuration. Things such as attribute resolution, PersonDirectory configuration, and more. As you observe, ALL CAS properties are now collected inside a single page on the documentation site; they are no longer spread around here and there. This makes it easier for project developers to maintain them, and for you as deployers to find them all in one spot. Bootiful Management Webapp The CAS management webapp is now bootified. It also boasts support for a few other additinal UI panes and sections that deal with MFA, OIDC, SAML, and more. Work continues to make sure all properties of a given CAS registered service can be configured and controlled via the UI. :cas-management-webapp:bootRun Listening for transport dt_socket at address: 5000 ____ _ ____ __ __ _ / ___| / \\ / ___| | \\/ | __ _ _ __ __ _ __ _ ___ _ __ ___ ___ _ __ | |_ | | / _ \\ \\___ \\ | |\\/| | / _` || '_ \\ / _` | / _` | / _ \\| '_ ` _ \\ / _ \\| '_ \\ | __| | |___ / ___ \\ ___) | | | | || (_| || | | || (_| || (_| || __/| | | | | || __/| | | || |_ \\____|/_/ \\_\\|____/ |_| |_| \\__,_||_| |_| \\__,_| \\__, | \\___||_| |_| |_| \\___||_| |_| \\__| |___/ Dependency Upgrades This milestone builds on top of some significant dependency upgrades that include: Spring Boot 1.4 * Ldaptive 1.2 * Pac4j 1.9.1 (*) These components are today in RC or SNAPSHOT mode, and will be switched to their appropriate GA release prior to the official CAS 5 release. I am most excited about Pac4j 1.9.1, which allows CAS easier support for delegated social authentication to: Github Dropbox Yahoo! FourSquare Windows Live Google Plus Digest AuthN Taking advantage of Pac4j 1.9, CAS now presents support for Digest authentication as another form of non-interactive authentication. WS-Fed Encrypted Assertions In this milestone, the WS-FED CAS module starts to support encrypted assertions issued by ADFS. This change is also ported to the 4.2.x release line. Authy OTP MFA Finally, CAS adds Authy to its collection of supported MFA providers. At this time, support is limited to Authy’s OTP REST API. Given community demand and interest, support for Authy’s OneTouch API may be worked out in the future. What’s Next? The development team is working hard to make sure the CAS 5 release is right on schedule. This is likely the last milestone for v5. As the milestones schedule shows, the project will be preparing for its first release candidate in about a month. Please keep an eye out for further announcements. How can you help? Start your early CAS 5 deployment today. Try out features and share feedback. Better yet, contribute patches. Review and suggest documentation improvements. Review the release schedule and make sure you report your desired feature requests on the project’s issue tracker. Das Ende A big hearty thanks to all who participated in the development of this release to submit patches, report issues and suggest improvements. Keep’em coming! Misagh Moayyed",
    "tags": "CAS Releases",
    "url": "/2016/07/23/m3-release/"
  },

  
  
  
  {
    "title": "CAS Survey Results",
    "text": "A while ago the CAS project management committee prepared a survey to help plan the future roadmap of the project. The primary objectives of the survey were to gain a better understanding of the current configuration pain points from a deployer point of view and learn what additional features and enhancements should have to be prioritized for development. In this post, I intend to provide a summarized view of the survey results and discuss what has or will be done to address the feedback. Results There were about 200 responses to the survey from both individuals and institutions. Some responses were submitted by consulting firms who provide CAS commercial services for their clients which indicates the actual number of deployers may be larger than the reported 200. Participants of the survey indicated that on average, they have been running CAS for more than 10 years in a variety of industry sectors such as Government, Higher-Ed, Insurance, Finance, Travel and Health. More than 50% of the results indicated a CAS server deployment size of more than 10K users which is considered a rather large deployment of the platform. The table below demonstrates what percentage of the community has chosen a given form of primary authentication: Method Adoption LDAP/AD 82% RDBMS 8% Other 10% The “Other” category being: NoSQL, X509, Rest, Social AuthN and many other forms of authentication supported by CAS. CAS Version The table below shows what percentage of the community is using a given CAS server version. Version Adoption 3.x 53% 4.0.x 22% 4.1.x 14% 4.2.x 4% Other 7% It’s important to note that CAS 3.x has been EOLed for almost 2 years. What this means is that CAS 3.x will no longer be maintained, fixed or (in case of security vulnerabilities) patched by the development team. Therefor, it is strongly recommended that those deployments switch and upgrade to a more recent and stable version of the platform, which at the time of this writing is CAS 4.2.x. Features Survey participants were also asked to vote on a number of proposed features on a 1-5 scale with 5 being most desirable. The following table shows an aggregated view of the results for each given feature where the adoption percentage is a summary of category 4 and 5 response types, indicating development should strongly focus on the completion or improvement of the proposed item. Feature Vote Admin UIs 60% SAML2 60% MFA 52% Surrogate AuthN 43% Adaptive AuthN 42% Rest APIs 40% GUI Wizard 33% Front-Channel SLO 33% WS-Fed 31% OIDC 29% OAuth2 28% FIDO 16% Dynamic Registration 11% Additional Feedback The following items were also reported by the community as areas that require improvement and clarification: Better Documentation The current CAS documentation assumes a high degree of familiarity with deployment tools such as Maven, Tomcat/Jetty, etc. The adopter also at times has to deal with multiple XML configuration files for enabling features such as LDAP authentication. This presents varying degrees of difficulty for a novice deployer to quickly get started with a CAS deployment. Step-by-step installation instructions, more samples and clarity in the documentation when it comes to dealing with specific CAS modules and features would be strongly desirable. A non-Maven deployment strategy could also be devised to relieve some of that pain when it comes to managing dependencies and CAS artifacts. Easier Upgrades The current CAS deployment strategy consists of constructing a Maven overlay in order to combine and merge local customizations with the original CAS distribution. This at times can morph into a complicated CAS upgrade process, specially if local customizations end up at odd conflicts with the new CAS distribution. Adopters are invariably forced to compare locally overlaid artifacts with their original version and fill in the gaps where necessary. Needless to say, this process for a novice deployer is less than obvious to understand and utilize. Other Features A number of other features were requested by participants that were not part of proposed scope. These included: JWT authentication Integrated Password Management Tracking and Geo-profiling authentication requests. Other registry types for managing CAS tickets and service definitions, such as YAML, Redis, ZeroMQ, etc. Response The CAS development team has been working on the next major release of the platform, that is 5.0.0. Taking into account the community survey and feedback, here are a few notes to help clarify how CAS 5 attempts to address some of the reported issues. Before we get started, it should be pointed out that early milestone releases of CAS 5 are available. Deployers are more than welcome to try out the milestone releases and share feedback. The current in-development documentation of CAS 5 is also available here. Features Core CAS 5 will have built-in support for: MFA based on Duo Security, Google Authenticator and more. SAML2 authentication, acting as an identity provider consuming and producing SAML metadata. OpenID Connect, acting as an OP producing claims for RPs. A YAML-based service registry. Delegating authentication to a remote REST endpoint. Recording and Geotracking authentication events. Since CAS 4.2.x, the platform has supported: JWT authentication. Delegating authentication to ADFS, CAS, SAML2 IdPs and a large variety of social authentication providers such as Facebook, Twitter and more. Ticket registry implementations based on Redis and Apache Cassandra. Auto Configuration Loudly pointed out by the survey, a much-needed overhaul of the CAS documentation is needed to enable configuration of CAS features in a more intuitive and sustainable way. To address this issue, CAS 5 takes an orthogonal approach where most if not all CAS features are automatically configured by CAS itself, given deployer’s consent, relieving the deployer from having to deal with XML configuration. This is a model we refer to as Intention-driven configuration. In the past in order to turn on a particular CAS feature, the adopter had to: Find and declare the module as a dependency Fiddle with a variety of XML configuration files to declare components Touch a few properties and settings supplying the appropriate values for those components. Repackage and redeploy. This process was much prone to errors and at times had to be repeated over and over again until the final works was in place. It also was extremely dependent on an accurate and reasonably detailed and clear documentation. It goes without saying that sustaining this model of development and configuration presents a high degree of difficulty for maintainers of the project and adopters of the platform. To remove some of this pain, CAS 5 presents the following approach to the deployer: Find and declare the feature module as a dependency, thus announcing your intention of enabling a particular feature in CAS. Optionally, configure the module by supplying settings via a simple .properties file. At deployment time, CAS will auto-determine every single change that is required for the functionality of declared modules and will auto-configure it all in order to remove the extra XML configuration pain. This is a strategy that is put into place for nearly ALL modules and features. This strategy helps with the documentation noise as well to a large degree because there is no longer a need to document every single XML configuration file and change required for each module for a given needed feature. The CAS 5 platform starts to have very low expectations of the adopter in terms of learning its internals and different configuration mechanics. Simply declaring an intention and optionally configuring it should be more than sufficient. This strategy also greatly assists with future upgrades because there would be very few, if any, local configuration files lying around in a deployment environment. The adopter should mostly care about the appropriate settings and values supplied to CAS that describe the core intended business functionality desired. As an example, in order to configure LDAP authentication, all an adopter has to do is declare his/her intention: &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-ldap&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;/dependency&gt; …and declare the relevant settings: ... # cas.authn.ldap[0].ldapUrl=ldaps://ldap1.example.edu,... # cas.authn.ldap[0].baseDn=dc=example,dc=org # cas.authn.ldap[0].userFilter=cn={user} # cas.authn.ldap[0].bindDn=cn=Directory Manager,dc=example,dc=org # cas.authn.ldap[0].bindCredential=Password ... That’s all. There is no other change required. This model would not have been possible without CAS taking full advantage of Spring Boot. Note that auto configuration of modules not only takes into account core what-used-to-be XML configuration but also any additions that may be required for the CAS webflows. Note that CAS 5 does not remove one’s ability to declare relevant changes and customizations in an XML file. There will be a deployerConfigContext.xml file, much like the old days, for those who feel more comfortable with an XML-friendly explicit form of configuration. However, for most if not ALL changes this strategy is completely unnecessary. Managing Configuration Previously, adopters had to repackage and redeploy the CAS web application if a configuration property (i.e. LDAP URL) had to be changed. This will no longer be true in CAS 5 where most if not ALL CAS components become reloadable. What this means is, specific endpoints (and administrative UIs) are exposed to adopters which can receive a reload request (permissions granting) and auto-configure the running CAS application context with the new state of the world WITHOUT the need to repackage and/or deploy the CAS software. This model would not have been possible without CAS taking full advantage of Spring Cloud. To learn more about how CAS manages the deployer configuration, particularly in a clustered environment, please review this page. Deployment Once packaged, adopters previously had to grab the final CAS web application and deploy it into a servlet container of choice such as Tomcat or Jetty. While this model is and will be supported, CAS 5 takes this one step further and ships with a built-in Tomcat container that can simply launch the CAS application directly from the command line. The recipe is as simple as: ... mvn clean package java -jar target/cas.war ... __ ____ _ ____ __ / / / ___| / \\ / ___| \\ \\ | | | | / _ \\ \\___ \\ | | | | | |___ / ___ \\ ___) | | | | | \\____|/_/ \\_\\|____/ | | \\_\\ /_/ CAS Version: 5.0.0.M3-SNAPSHOT Build Date/Time: 2016-06-26T20:55:15.345Z Java Home: C:\\Program Files\\Java\\jdk1.8.0_92\\jre Java Vendor: Oracle Corporation Java Version: 1.8.0_92 OS Architecture: amd64 OS Name: Windows 10 OS Version: 10.0 ... Every attempt has been made to ensure every aspect of the built-in Tomcat container (such as SSL, context path, etc) is configurable via the same .properties file that houses all other CAS configuration. Built-in containers are also available, optionally, for Jetty and Undertow. User Interfaces CAS 5 starts use to use Thymeleaf as a rendering engine for its user interfaces. Thymeleaf’s main goal is to bring elegant natural templates to your development workflow — HTML that can be correctly displayed in browsers. The old JSP model required adopters to test out UI-related changes directly inside a running servlet container such as Tomcat. Thymeleaf allows CAS to present HTML-native pages that can easily be viewed in the browser without requiring an underlying container engine. CAS 5 also attempts to improve the user experience for the administrator in a cloud-friendly manner. There are many administrative control panels that expose insight into the running CAS software. The screens report back on the health of the running CAS server, various configuration options and status of active SSO sessions, etc. There is also additional upcoming work to further improve these control panels, allowing the adopter to monitor and configure logs, adjust CAS settings and manage SSO sessions more effectively without resorting access to the native command-line. Of course if you wish, you can always resort back to the command-line if you wish to manually hand-massage the configuration. Here are a few screenshots of the new CAS 5 user interfaces: View post on imgur.com What’s Next? The development team is working hard to make sure the CAS 5 release is right on schedule. For the time being, CAS 4.1.x and 4.2.x release lines will be maintained by the development team. However, the primary development focus and time will be dedicated to CAS 5, addressing bugs and extending the platform to be a more comfortable experience specially for some of the brand new features presented in this release. How can you help? Start your early CAS 5 deployment today. Try out features and share feedback. Better yet, contribute patches. Review and suggest documentation improvements. Das Ende I would like to thank all survey participants. None of this would have been possible without your engagement and involvement in a vibrant community. Thank you for sharing. Thank you very much for all the kind words. On behalf of the CAS project, Misagh Moayyed",
    "tags": "CAS",
    "url": "/2016/06/26/survey-results/"
  },

  
  
  
  {
    "title": "Hello World",
    "text": "This is me trying out Github Pages as a blog. Echo. Echo. Echo.",
    "tags": "Blog",
    "url": "/2016/06/25/first-post/"
  },

  
  
  
  {
    "title": "CAS Vulnerability Disclosure",
    "text": "Remember This post is NOT new. I am just collecting it here so it’s publicly available. This was originally published as a secret gist on Github in April 2016. Overview This is an Apereo CAS project vulnerability disclosure, describing an issue in CAS’s attempts to deserialize objects via the Apache Commons Collections library. Affected Deployments The attack vector specifically applies to all deployments of CAS v4.1.x and v4.2.x deployments where the out-of-the-box default configuration of CAS is used for managing object serialization, encryption and signing of data. You are NOT affected by this issue, if: You have deployed a different CAS version, lower than v4.1.0. You have deployed CAS v4.1.x or v4.2.x, BUT you have removed the default CAS configuration for encryption/signing and have regenerated the appropriate settings for your own deployment. Exploiting the vulnerability hinges on getting the JVM to de-serialize Java objects from arbitrary serialized data. If the above conditions describe your deployment, we STRONGLY recommend that you take necessary action to patch your deployment based on the below instructions. Severity This is a very serious issue where successfully exercising this vulnerability allows the adversary to inject arbitrary code. This disclosure is about a specific exploit path involving a bugged version of Apache Commons Collections. This exploit path is only an instance of a larger JVM Java object deserialization security concern. Patching Patch releases are now available to address CAS v4.1.x and v4.2.x deployments. Upgrades to the next patch version for each release should be a drop-in replacement, with some effort to appropriately reconfigure CAS encryption/signing settings via the cas.properties file. CAS 4.1.x Overlay Modify your CAS overlay to point to version 4.1.7. A snippet of a pom.xml for a CAS overlay follows: ... &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.jasig.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;cas.version&gt;4.1.7&lt;/cas.version&gt; &lt;/properties&gt; ... TGC Settings Locate your cas.properties file and find the tgc.* settings. If your CAS deployment is NOT using the default encryption/signing keys provided by CAS and you have regenerated new keys and have replaced the default, you can safely ignore this step and leave your key configuration of signing/encryption in place without any further changes. If your CAS deployment IS using the default encryption/signing keys provided by CAS and you have NOT regenerated new keys to replace the default, you MUST take action to regenerate the keys. You can choose one of the two approaches described below to handle key regeneration. 1) Let CAS Generate Keys Blank/comment out the following tgc settings: # tgc.encryption.key= # tgc.signing.key= Build and deploy your CAS deployment once. Upon startup, CAS will notice that no keys are defined, and it will appropriately generate keys for you automatically. Your CAS logs will then show the following snippet: WARN [org.jasig.cas.util.BaseStringCipherExecutor] - &lt;Secret key for encryption is not defined. CAS will attempt to auto-generate the encryption key&gt; WARN [org.jasig.cas.util.BaseStringCipherExecutor] - &lt;Generated encryption key ABC of size ... . The generated key MUST be added to CAS settings.&gt; WARN [org.jasig.cas.util.BaseStringCipherExecutor] - &lt;Secret key for signing is not defined. CAS will attempt to auto-generate the signing key&gt; WARN [org.jasig.cas.util.BaseStringCipherExecutor] - &lt;Generated signing key XYZ of size ... . The generated key MUST be added to CAS settings.&gt; You should then grab each generated key for encryption and signing, and put them inside your cas.properties file for each now-enabled setting: tgc.encryption.key=ABC tgc.signing.key=XYZ 2) Manually Generate Keys Using a git client, clone and build the following project: git clone https://github.com/mitreid-connect/json-web-key-generator.git cd json-web-key-generator mvn clean package cd target # Encryption Key java -jar json-web-key-generator-0.3-SNAPSHOT-jar-with-dependencies.jar -t oct -s 256 # # Full key: # { # \"kty\": \"oct\", # \"k\": \"ABC\" # } # # Signing Key java -jar json-web-key-generator-0.3-SNAPSHOT-jar-with-dependencies.jar -t oct -s 512 # Full key: # { # \"kty\": \"oct\", # \"k\": \"XYZ\" # } You should then grab each generated key for encryption and signing, and put them inside your cas.properties file for each now-enabled setting: tgc.encryption.key=ABC tgc.signing.key=XYZ Webflow Settings Locate your cas.properties file and find the webflow.* settings. If you do not see them in your configuration, go ahead and define them: # webflow.encryption.key= # webflow.signing.key= You can choose one of the two approaches described below to handle key regeneration. 1) Let CAS Generate Keys Blank/comment out the following webflow settings: # webflow.encryption.key= # webflow.signing.key= Build and deploy your CAS deployment once. Upon startup, CAS will notice that no keys are defined, and it will appropriately generate keys for you automatically. Your CAS logs will then show the following snippet: WARN [org.jasig.cas.util.BinaryCipherExecutor] - &lt;Secret key for encryption is not defined. CAS will attempt to auto-generate the encryption key&gt; WARN [org.jasig.cas.util.BinaryCipherExecutor] - &lt;Generated encryption key ABC of size ... . The generated key MUST be added to CAS settings.&gt; WARN [org.jasig.cas.util.BinaryCipherExecutor] - &lt;Secret key for signing is not defined. CAS will attempt to auto-generate the signing key&gt; WARN [org.jasig.cas.util.BinaryCipherExecutor] - &lt;Generated signing key XYZ of size ... . The generated key MUST be added to CAS settings.&gt; You should then grab each generated key for encryption and signing, and put them inside your cas.properties file for each now-enabled setting: webflow.encryption.key=ABC webflow.signing.key=XYZ 2) Manually Generate Keys Using a git client, clone and build the following project: git clone https://github.com/mitreid-connect/json-web-key-generator.git cd json-web-key-generator mvn clean package cd target # Encryption Key java -jar json-web-key-generator-0.3-SNAPSHOT-jar-with-dependencies.jar -t oct -s 96 # # Full key: # { # \"kty\": \"oct\", # \"k\": \"ABC\" # } # # Signing Key java -jar json-web-key-generator-0.3-SNAPSHOT-jar-with-dependencies.jar -t oct -s 512 # Full key: # { # \"kty\": \"oct\", # \"k\": \"XYZ\" # } You should then grab each generated key for encryption and signing, and put them inside your cas.properties file for each now-enabled setting: webflow.encryption.key=ABC webflow.signing.key=XYZ XML Configuration If you have manually overridden the cas-servlet.xml file, you will need to make sure the following blocks are present in the configuration: Note that the Person Directory project requires the following configuration in CAS overlays: ```xml Note that the Person Directory project requires the following configuration in CAS overlays: ```xml &lt;bean id=\"loginFlowStateTranscoder\" class=\"org.jasig.spring.webflow.plugin.EncryptedTranscoder\" c:cipherBean-ref=\"loginFlowCipherBean\" /&gt; &lt;bean id=\"loginFlowCipherBean\" class=\"org.jasig.cas.web.flow.CasWebflowCipherBean\" c:cipherExecutor-ref=\"webflowCipherExecutor\" /&gt; &lt;bean id=\"webflowCipherExecutor\" class=\"org.jasig.cas.util.BinaryCipherExecutor\" c:encryptionSecretKey=\"${webflow.encryption.key:}\" c:signingSecretKey=\"${webflow.signing.key:}\"/&gt; Re-adjust the beans accordingly, and remove the built-in keystore. Finally Rebuild and redeploy your CAS overlay. CAS 4.2.x Modify your CAS overlay to point to version 4.2.1. A snippet of a pom.xml for a CAS overlay follows: ... &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.jasig.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp&lt;/artifactId&gt; &lt;version&gt;${cas.version}&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;cas.version&gt;4.2.1&lt;/cas.version&gt; &lt;/properties&gt; ... TGC Settings Locate your cas.properties file and find the tgc.* settings. If your CAS deployment is NOT using the default encryption/signing keys provided by CAS and you have regenerated new keys and have replaced the default, you can safely ignore this step and leave your key configuration of signing/encryption in place without any further changes. If your CAS deployment IS using the default encryption/signing keys provided by CAS and you have NOT regenerated new keys to replace the default, you MUST take action to regenerate the keys. You can choose one of the two approaches described below to handle key regeneration. 1) Let CAS Generate Keys Blank/comment out the following tgc settings: # tgc.encryption.key= # tgc.signing.key= Build and deploy your CAS deployment. Upon startup, CAS will notice that no keys are defined, and it will appropriately generate keys for you automatically. Your CAS logs will then show the following snippet: WARN [org.jasig.cas.util.BaseStringCipherExecutor] - &lt;Secret key for encryption is not defined. CAS will attempt to auto-generate the encryption key&gt; WARN [org.jasig.cas.util.BaseStringCipherExecutor] - &lt;Generated encryption key ABC of size ... . The generated key MUST be added to CAS settings.&gt; WARN [org.jasig.cas.util.BaseStringCipherExecutor] - &lt;Secret key for signing is not defined. CAS will attempt to auto-generate the signing key&gt; WARN [org.jasig.cas.util.BaseStringCipherExecutor] - &lt;Generated signing key XYZ of size ... . The generated key MUST be added to CAS settings.&gt; You should then grab each generated key for encryption and signing, and put them inside your cas.properties file for each now-enabled setting: tgc.encryption.key=ABC tgc.signing.key=XYZ Rebuild and redeploy your CAS overlay. 2) Manually Generate Keys Using a git client, clone and build the following project: git clone https://github.com/mitreid-connect/json-web-key-generator.git cd json-web-key-generator mvn clean package cd target # Encryption Key java -jar json-web-key-generator-0.3-SNAPSHOT-jar-with-dependencies.jar -t oct -s 256 # # Full key: # { # \"kty\": \"oct\", # \"k\": \"ABC\" # } # # Signing Key java -jar json-web-key-generator-0.3-SNAPSHOT-jar-with-dependencies.jar -t oct -s 512 # Full key: # { # \"kty\": \"oct\", # \"k\": \"XYZ\" # } You should then grab each generated key for encryption and signing, and put them inside your cas.properties file for each now-enabled setting: tgc.encryption.key=ABC tgc.signing.key=XYZ Webflow Settings Locate your cas.properties file and find the webflow.* settings. If you do not see them in your configuration, go ahead and define them: # webflow.encryption.key= # webflow.signing.key= You can choose one of the two approaches described below to handle key regeneration. 1) Let CAS Generate Keys Blank/comment out the following webflow settings: # webflow.encryption.key= # webflow.signing.key= Build and deploy your CAS deployment once. Upon startup, CAS will notice that no keys are defined, and it will appropriately generate keys for you automatically. Your CAS logs will then show the following snippet: WARN [org.jasig.cas.util.BinaryCipherExecutor] - &lt;Secret key for encryption is not defined. CAS will attempt to auto-generate the encryption key&gt; WARN [org.jasig.cas.util.BinaryCipherExecutor] - &lt;Generated encryption key ABC of size ... . The generated key MUST be added to CAS settings.&gt; WARN [org.jasig.cas.util.BinaryCipherExecutor] - &lt;Secret key for signing is not defined. CAS will attempt to auto-generate the signing key&gt; WARN [org.jasig.cas.util.BinaryCipherExecutor] - &lt;Generated signing key XYZ of size ... . The generated key MUST be added to CAS settings.&gt; You should then grab each generated key for encryption and signing, and put them inside your cas.properties file for each now-enabled setting: webflow.encryption.key=ABC webflow.signing.key=XYZ 2) Manually Generate Keys Using a git client, clone and build the following project: git clone https://github.com/mitreid-connect/json-web-key-generator.git cd json-web-key-generator mvn clean package cd target # Encryption Key java -jar json-web-key-generator-0.3-SNAPSHOT-jar-with-dependencies.jar -t oct -s 96 # # Full key: # { # \"kty\": \"oct\", # \"k\": \"ABC\" # } # # Signing Key java -jar json-web-key-generator-0.3-SNAPSHOT-jar-with-dependencies.jar -t oct -s 512 # Full key: # { # \"kty\": \"oct\", # \"k\": \"XYZ\" # } You should then grab each generated key for encryption and signing, and put them inside your cas.properties file for each now-enabled setting: webflow.encryption.key=ABC webflow.signing.key=XYZ Finally Rebuild and redeploy your CAS overlay. Clustered CAS Deployments If you are running a cluster of CAS nodes, please be advised that the newly generated keys for all settings (regardless of the method of generation, whether CAS or you) MUST be shared with all CAS nodes in form of either a centralized or replicated/shared cas.properties file. Failure to do so will completely break CAS functionality. If you only have a single-node CAS deployment, there is nothing further for you to do. Support If you have questions on the details this vulnerability and how it might be reproduced, please contact security@apereo.org or cas-appsec-public@apereo.org. Resources Apache Commons statement to widespread Java object de-serialisation vulnerability Apache Commons Collections security reports Misagh Moayyed",
    "tags": "CAS",
    "url": "/2016/04/08/commonsvulndisc/"
  },

  
  
  
  {
    "title": "",
    "text": "404 Sorry, we can’t seem to find this page’s pixylls. Home Contact",
    "tags": "",
    "url": "/404.html"
  },

  
  
  
  {
    "title": "About",
    "text": "Formed in 2012, the Apereo Foundation is a vibrant and value-driven organization. Apereo has a noteworthy history celebrating two strong organizations, the Sakai Foundation and Jasig. Apereo is a community built around openness, inclusivity, collaboration and innovation. The mission of Apereo is to help educational organizations “collaborate to foster, develop, and sustain open technologies and innovation to support learning, teaching, and research.” Apereo projects are 100% open. About Blog This is a blog managed and edited by the Apereo project participants and community members. It is typically used to post project updates, announce news, etc. Disclaimer Unless otherwise noted, all authors post here wearing their individual Apereo participant hats. Opinions, statements, and comments expressed via this blog do not necessarily reflect those of the Apereo Foundation.",
    "tags": "about",
    "url": "/about/"
  },

  
  
  
  {
    "title": "Say Hello",
    "text": "Email Content Say Hello",
    "tags": "contact",
    "url": "/contact/"
  },

  
  
  
  {
    "title": "",
    "text": "Friday, Feb 1, 2019 CAS 6.1.0 RC1 Feature Release ...in which I present an overview of CAS 6.1.0 RC1 release. Monday, Dec 24, 2018 Apereo CAS - OohLala Mobile SAML2 Integration Learn how to integrate OohLala Mobile with Apereo CAS running as a SAML2 identity provider. Monday, Dec 24, 2018 Apereo CAS - Cranium Cafe SAML2 Integration Learn how to integrate Cranium Cafe with Apereo CAS running as a SAML2 identity provider. Monday, Dec 24, 2018 Apereo CAS - eLumen SAML2 Integration Learn how to integrate eLumen with Apereo CAS running as a SAML2 identity provider. Sunday, Dec 23, 2018 Apereo CAS - Rave SAML2 Integration Learn how to integrate Rave with Apereo CAS running as a SAML2 identity provider. Saturday, Dec 22, 2018 Apereo CAS - HireTouch SAML2 Integration Learn how to integrate HireTouch with Apereo CAS running as a SAML2 identity provider. Thursday, Dec 6, 2018 Apereo CAS - Microsoft Office 365 SAML2 Integration Learn how to integrate Microsoft Office 365 with Apereo CAS running as a SAML2 identity provider. Tuesday, Dec 4, 2018 Apereo CAS - HappyFox SAML2 Integration Learn how to integrate HappyFox with Apereo CAS running as a SAML2 identity provider. Newer Older Page 1 of 17",
    "tags": "",
    "url": "/"
  },

  
  
  
  {
    "title": "All Posts",
    "text": "Apereo uPortal annual report, June 2018 edition Nominate awesome fits for the Apereo board Feedback on draft Apereo strategy Easier CLA submission September 2016 Apereo Newsletter Blog Why you should choose CAS as your SSO system Effective Software Troubleshooting Tactics Notes from Better by Design 2018 Get Productive with Shell Aliases feat(conventional_commits): signal breaking changes in commit titles One Can Only Hope in Buchistan Do State The Obvious Stop Writing Code Let Your Docker Containers Speak Busting the Myth - GA Release On The Theory of Possibility Guy walks into an Auto Shop Singing \"I Love Bug Reports\" Veresk Software Architecture Hope for GitHub Pages Defining a Product Vision Hello World CAS CAS 6.1.0 RC1 Feature Release Apereo CAS - OohLala Mobile SAML2 Integration Apereo CAS - Cranium Cafe SAML2 Integration Apereo CAS - eLumen SAML2 Integration Apereo CAS - Rave SAML2 Integration Apereo CAS - HireTouch SAML2 Integration Apereo CAS - Microsoft Office 365 SAML2 Integration Apereo CAS - HappyFox SAML2 Integration Apereo CAS - Cisco Webex SAML2 Integration Apereo CAS - VMware Identity Manager SAML2 Integration CAS 6.0.0 RC4 Feature Release Apereo CAS - Scripting Multifactor Authentication Triggers Apereo CAS 6.0.x - Building CAS Feature Modules CAS 6.0.x Deployment - WAR Overlays Apereo CAS - Jib at CAS Docker Images Apereo CAS 6 - Administrative Endpoints & Monitoring Apereo CAS - SAML2 Metadata with MongoDb Apereo CAS - Slurp Configuration with Groovy Apereo CAS - Configuration Management with MongoDb Apereo CAS - Integration with HashiCorp Vault CAS 6.0.0 RC3 Feature Release Why you should choose CAS as your SSO system Apereo CAS - Integration with Spring Cloud Config Server Apereo CAS - Spring Boot Admin Integration Apereo CAS - Fun with HashiCorp Consul Apereo CAS - Multifactor Authentication with RADIUS CAS Vulnerability Disclosure CAS 6.0.0 RC2 Feature Release Apereo CAS - dotCMS SAML2 Integration Apereo CAS - MaxMind Geo2IP ISP Integration Apereo CAS - Authentication Lifecycle Phases CAS 6.0.0 RC1 Feature Release Apereo CAS Delegated Authentication with ADFS Apereo CAS Swag with Swagger Apereo CAS - Extending Webflows Apereo CAS - Administrative Endpoints & Monitoring Apereo CAS - Custom Authentication & Attribute Sources Apereo CAS - User Interface Customizations CAS Multifactor Authentication with Google Authenticator CAS 5.3.x Deployment - WAR Overlays CAS 5.3.0 RC4 Feature Release Apereo CAS - Identity Impersonation Apereo CAS - Customized Settings Apereo CAS - Handling Multiple Logout URLs Apereo CAS - Access Strategy External URL Redirects Apereo CAS - Linking Accounts with Delegated Authentication Apereo CAS - Test-Driving Feature Modules Apereo CAS Best [Mal]Practice - Supercharged Overlays CAS 5.3.0 RC3 Feature Release Apereo CAS - REFEDS MFA Profile with shib-cas-authn3 Forced Authentication with Apereo CAS Apereo CAS - Dances with Protocols Apereo CAS - Attribute-based Application Authorization CAS 5.3.0 RC2 Feature Release CAS 5.2.x Deployment - WAR Overlays Link CAS OIDC user to existing Database user CAS Multifactor Authentication with Duo Security Deploying Apereo CAS Behind a Proxy CAS 5.3.0 RC1 Feature Release Apereo CAS SAML Integration With ADFS Introduction to CAS Commandline Shell Multitenancy With CAS JWT Of All Things With CAS CAS 5.2.0 RC4 Feature Release Extending CAS 5 Webflows CAS 5.1.x Load Tests by Lafayette College CAS 5.2.0 RC3 Feature Release CAS 5.1.x User Swap - Cause and Analysis Interrupt CAS With Class CAS 5.2.0 RC2 Feature Release Apereo CAS - Contribution Guidelines CAS 5.2.0 RC1 Feature Release CAS 5 - Maintaining Protocol Compatibility CAS Codebase Overview CAS 5 Load Tests by Lafayette College Shibbolizing Apereo CAS CAS 5.0.x Integration w/ Apache ZooKeeper CAS 5.1.0 RC4 Feature Release CAS 5.1.0 RC3 Feature Release CAS 5.0.x Deployment - WAR Overlays CAS 5 LDAP AuthN and Jasypt Configuration CAS 5 SAML2 Delegated AuthN Tutorial CAS Vulnerability Disclosure CAS 5.1.0 RC2 Feature Release CAS 5 Database Authentication Tutorial Intro To CAS Auto Configuration Strategy Design CAS-Enabled Custom Protocols Design Authentication Handlers in CAS 5.1.x CAS 5.1.0 RC1 Feature Release CAS Vulnerability Disclosure Activating MFA in CAS 5 Bootiful CAS 5 Overlay CAS 5.0.0-RC3 Released CAS Git Repository Maintenance CAS 5.0.0-RC1 Release CAS EOL Policy Proposal CAS 5.0.0-M3 Released CAS Survey Results CAS Vulnerability Disclosure Licensing Why does uPortal use Apache 2 license? Easier CLA submission MFA Apereo CAS - Scripting Multifactor Authentication Triggers Apereo CAS - Multifactor Authentication with RADIUS CAS Multifactor Authentication with Google Authenticator Apereo CAS - REFEDS MFA Profile with shib-cas-authn3 CAS Multifactor Authentication with Duo Security Activating MFA in CAS 5 Releases CAS 6.1.0 RC1 Feature Release CAS 6.0.0 RC4 Feature Release CAS 6.0.0 RC3 Feature Release CAS 6.0.0 RC2 Feature Release CAS 6.0.0 RC1 Feature Release CAS 5.3.0 RC4 Feature Release CAS 5.3.0 RC3 Feature Release CAS 5.3.0 RC2 Feature Release CAS 5.3.0 RC1 Feature Release CAS 5.2.0 RC4 Feature Release CAS 5.2.0 RC3 Feature Release CAS 5.2.0 RC2 Feature Release CAS 5.2.0 RC1 Feature Release CAS 5.1.0 RC4 Feature Release CAS 5.1.0 RC3 Feature Release CAS 5.1.0 RC2 Feature Release CAS 5.1.0 RC1 Feature Release MyUW 2016-10-25 release CAS 5.0.0-RC3 Released CAS 5.0.0-RC1 Release CAS 5.0.0-M3 Released SAML Apereo CAS - OohLala Mobile SAML2 Integration Apereo CAS - Cranium Cafe SAML2 Integration Apereo CAS - eLumen SAML2 Integration Apereo CAS - Rave SAML2 Integration Apereo CAS - HireTouch SAML2 Integration Apereo CAS - Microsoft Office 365 SAML2 Integration Apereo CAS - HappyFox SAML2 Integration Apereo CAS - Cisco Webex SAML2 Integration Apereo CAS - VMware Identity Manager SAML2 Integration Apereo CAS - SAML2 Metadata with MongoDb Apereo CAS - dotCMS SAML2 Integration Apereo CAS - REFEDS MFA Profile with shib-cas-authn3 Apereo CAS SAML Integration With ADFS Shibbolizing Apereo CAS a11y Better by design 2017: Integrating accessibility across design and development lifecycle uPortal uPortal annual report, June 2018 edition Why does uPortal use Apache 2 license? August 2017 uPortal Slack summary Summer 2017 uPortal Roadmap Update July 2017 uPortal Slack summary June 2017 uPortal Slack summary MyUW in 2016 - by the numbers MyUW in 2016 uPortal 2016-11-14 Webproxy Portlet caching vulnerability MyUW 2016-10-25 release MyUW (University of Wisconsin) Build Process",
    "tags": "about",
    "url": "/tags/"
  },

  
  
  
  {
    "title": "Thanks For Your Message",
    "text": "Thanks for contacting us. We will reply as soon as possible.",
    "tags": "",
    "url": "/thanks/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page2/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page3/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page4/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page5/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page6/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page7/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page8/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page9/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page10/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page11/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page12/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page13/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page14/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page15/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page16/"
  },

  
  
  
  {
    "title": "",
    "text": "{% assign posts_count = paginator.posts | size %} {% if posts_count > 0 %} {% for post in paginator.posts %} {{ post.date | date: site.date_format }} {{ post.title }} {% if post.summary %} {{ post.summary }} {% else %} {{ post.excerpt }} {% endif %} {% endfor %} {% include pagination.html %} {% else %} {{ site.text.index.coming_soon }} {% endif %}",
    "tags": "",
    "url": "/page17/"
  }

]};
